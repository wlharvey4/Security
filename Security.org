# -*- mode:org; fill-column:79; -*-
#+title:Security Information
#+author:Pinecone062
#+date:April 14, 2019
#+macro:version 0.3.3.<2019-05-03 Fri 09:54>
Version {{{version}}} By {{{author}}}

* JSON Web Tokens
** Article---How JWTs Secure Your API
:PROPERTIES:
:source-url:   https://vuejsdevelopers.com/2019/04/15/api-security-jwt-json-web-tokens/?
:source-title: How JSON Web Token (JWT) Secures Your API
:source-author: Anthony Gore
:source-date: April 14, 2019
:END:
*** Introduction From How JWTs Securre Your API
You've probably heard that the JSON Web Token (JWT) is the current
state-of-the-art technology for securing APIs.  Like most security topics, it's
important to understand how it works (at least, somewhat) if you're planning to
use it.  The problem is that most explanations of JWT are technical and
headache-inducing.  Let's see if I can explain how a JWT can secure your API
without crossing your eyes!

*** API Authentication

{{{heading(Need to Authenticate Access)}}}

#+CINDEX:authentication
Certain API resources need restricted access.  We don't want one user to be
able to change the password of another user, for example.  That's why we
protect certain resources---make users supply their ID and password before
allowing access---in other words, we authenticate them.

{{{heading(HTTP Requests are Stateless)}}}

#+CINDEX:stateless, HTTP
The difficulty in securing an HTTP API is that requests are stateless---the API
has no way of knowing whether any two requests were from the same user or not.
So why don't we require users to provide their ID and password on every call to
the API?  Only because that would be a terrible user experience.

*** JSON Web Token
:PROPERTIES:
:article-title: What is a JSON Web Token?
:article-cite: https://robmclarty.com/blog/what-is-a-json-web-token
:article-author: Rob McLarty
:END:
What we need is a way to allow a user to supply their credentials just once,
but then be identified in another way by the server in subsequent requests.
Several systems have been designed for doing this, and the current
state-of-the-art standard is the JSON Web Token.

{{{heading(How JWTs Work)}}}

There's a great [[https://robmclarty.com/blog/what-is-a-json-web-token][article]] on the topic which makes a good analogy about how JSON
web tokens work:
#+begin_quote
Instead of an API, imagine you're checking into a hotel.  The "token" is the
plastic hotel security card that you get that allows you to access your room,
and the hotel facilities, but not anyone else's room.  When you check out of
the hotel, you give the card back.  This is analogous to logging out.
#+end_quote

*** Structure of the Token

{{{heading(What a JWT Looks Like)}}}

#+CINDEX:HTTP request header
#+CINDEX:header, HTTP request
#+CINDEX:request, HTTP header
#+CINDEX:bearer, authorization
#+CINDEX:authorization, bearer
#+CINDEX:token
#+CINDEX:bearer token
Normally a JSON web token is sent via the header of HTTP requests. Here's what
one looks like:
: Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIn0.dozjgNryP4J3jVmNHl0w5N_XgL0n3I9PlFUP0THsR8U
In fact, the token is the part after "Authorization: Bearer", which is just the
HTTP header info.

{{{heading(The Header Payload and Signature)}}}

#+CINDEX:header
#+CINDEX:payload
#+CINDEX:signature
#+CINDEX:Base 64 encode
Before you conclude that it's incomprehensible gibberish, there are a few
things you can easily notice.  Firstly, the token consists of three different
strings, separated by a period.  These three string are base 64
encoded[fn::Base 64 encoding is a way of transforming strings to ensure they
don't get screwed up during transport across the web.  It is not a kind of
encryption and anyone can easily decode it to see the original data.] and
correspond to:
- the /header/,
- the /payload/, and
- the /signature/.


We can decode these strings to get a better understand of the structure of JWT.

{{{subheading(Header)}}}

#+CINDEX:header, dfn
The following is the decoded header from the token.  The @@texinfo:@dfn{header}@@ is
meta information about the token.  It doesn't tell us much to help build our
basic understanding, so we won't get into any detail about it.

#+BEGIN_SRC js
{
  "alg": "HS256",
  "typ": "JWT"
}
#+END_SRC

{{{subheading(Payload)}}}

#+CINDEX:payload, dfn
The payload is of much more interest.  The @@texinfo:@dfn{payload}@@ can include any
data you like, but you might just include a user ID if the purpose of your
token is API access authentication.

#+BEGIN_SRC js
{
  "userId": "1234567890"
}
#+END_SRC

It's important to note that the payload is not secure.  Anyone can decode the
token and see exactly what's in the payload.  For that reason, we usually
include an ID rather than sensitive identifying information like the user's
email.  Even though this payload is all that's needed to identify a user on an
API, it doesn't provide a means of authentication.  Someone could easily find
your user ID and forge a token if that's all that was included.

So this brings us to the signature, which is the key piece for authenticating
the token.

*** Hashing Algorithms
#+CINDEX:hashing algorithm, dfn
#+CINDEX:hashing algorithm, SHA256
#+CINDEX:hash, dfn
#+CINDEX:SHA256 hashing algorithm
Before we explain how the signature works, we need to define what a
@@texinfo:@dfn{hashing algorithm}@@ is.  To begin with, it's a function for
transforming a string into a new string called a @@texinfo:@dfn{hash}@@.  For example,
say we wanted to hash the string "Hello, world".  Here's the output we'd get
using the =SHA256= hashing algorithm:
: 4ae7c3b6ac0beff671efa8cf57386151c06e58ca53a78d83f36107316cec125f
The most important property of the hash is that you can't use the hashing
algorithm to identify the original string by looking at the hash.  In other
words, we can't take the above hash and directly figure out that the original
string was "Hello, world". The hash is complicated enough that guessing the
original string would be infeasible.  There are many different types of hashing
algorithms, but =SHA256= is commonly used with JWT.

{{{heading(JWT Signature)}}}

#+CINDEX:signature, dfn
So coming back to the JWT structure, let's now look at the third piece of the
token, the @@texinfo:@dfn{signature}@@.  This actually needs to be calculated:

#+BEGIN_SRC js
HMACSHA256(
  base64UrlEncode(header) + "." + base64UrlEncode(payload),
  "secret string"
);
#+END_SRC

Here's an explanation of what's going on here:

#+CINDEX:hashing function
- Firstly, =HMACSHA256= is the name of a hashing function and takes two
  arguments:
  - the string to hash, and
  - the "secret" (defined below).
- Secondly, the string we hash is the base 64 encoded /header/, plus the base 64
  encoded /payload/.
- Thirdly, the /secret/ is an arbitrary piece of data that only the server
  knows.


Why include the header and payload in the signature hash?  This ensures the
signature is unique to this particular token.

{{{subheading(The Secret)}}}

#+CINDEX:secret
What's the @@texinfo:@dfn{secret}@@?  To answer this, let's think about how you would
forge a token.  We said before that you can't determine a hash's input from
looking at the output.  However, since we know that the signature includes the
header and payload, as those are public information, if you know the hashing
algorithm (hint: it's usually specified in the header), you could generate the
same hash.  But the secret, which only the server knows, is not public
information.  Including it in the hash prevents someone generating their own
hash to forge the token.  And since the hash obscures the information used to
create it, no one can figure out the secret from the hash, either.

{{{subheading(Salting)}}}

#+CINDEX:salting
The process of adding private data to a hash is called @@texinfo:@dfn{salting}@@ and
makes cracking the token almost impossible.

*** Authentication Process
#+CINDEX:authentication process
So now you have a good idea of how a token is created.  How do you use it to
authenticate your API?

{{{heading(Login)}}}

#+CINDEX:token, generate
#+CINDEX:generate token
A token is generated when a user logs in and is stored in the database with the
user model.  The token then gets attached as the /authorization header/ in the
response to the login request.

#+caption:Generating a Token Upon Login; ~loginController.js~
#+name:generate-token
#+BEGIN_SRC js
if (passwordCorrect) {
  user.token = generateToken(user.id);
  user.save();
  res.headers("authorization", `Bearer ${token}`).send();
}
#+END_SRC

{{{heading(Authenticating requests)}}}

#+CINDEX:requests, authenticate
#+CINDEX:authenticate requests
Now that the client has the token, it can attach it to any future requests to
authenticate the identity of the user.  When the server receives a request with
an authorization token attached, the following happens:

1. It decodes the token and extracts the ID from the payload.
2. It looks up the user in the database with this ID.
3. It compares the request token with the one that's stored with the user's
   model.  If they match, the user is authenticated.

#+caption:The Server authenticates requests from the Client; ~authMiddleware.js~
#+name:authenticate-requests
#+BEGIN_SRC js
const token = req.header.token;
const payload = decodeToken(token);
const user = User.findById(payload.id);
if (user.token = token) {
  // Authorized
} else {
  // Unauthorized
}
#+END_SRC

{{{heading(Logging out)}}}

#+CINDEX:logout
If the user logs out, simply delete the token attached to the user model, and
now the token will no longer work.  A user will need to log in again to generate
a new token.

#+caption:Logging a user out; ~logoutController.js~
#+name:logout
#+BEGIN_SRC js
user.token = null;
user.save();
#+END_SRC

*** Wrapup
So that's a very basic explanation of how you can secure an API using JSON Web
Tokens.  I hope your head doesn't hurt too much.

** Course---JSON Web Token Authentication with Node.js
:PROPERTIES:
:source:   Egghead.io
:author:   Joel Lord
:END:
*** About the Course
In this course, we will build a simple authentication server that will act as a
token issuer, and we will use those tokens to access resources on an API.
Starting from scratch, the participants will learn how easy token based
authentication can be and will understand how to use them on their APIs as well
as on the front end of their web applications.
**** Source Code
[[https://github.com/eggheadio-projects/egghead-auth-course/tree/master][eggheadio-projects/egghead-auth-course]]
**** The Author
- Joel Lord
- [[http://www.javascripteverything.com/about][About the author]]
- [[http://www.javascripteverything.com/about][Javascript Everything]] author's blog
- [[https://github.com/joellord][GitHub]]
**** Author's Introduction
00:00 Hey everyone, welcome to this course on JSON web token authentication
with Node.JS.  The goal of this course is to introduce you to web-based
authentication using JWTs.

00:11 Through these few lessons, we will build a simple application that will
connect to a secured API and we will build an authentication server to provide
us with tokens that we need in order to connect and access those routes.

00:25 We will start slowly by building a simple web server using Express.  We
will then see how to make this API more flexible by introducing environment
variables, and then how to handle post request, and how to parse the body of
those requests.

00:40 At this point, we will be able to start building our authentication
server.  The server will validate the user credentials and provide those users
with a JSON web token.  Using this token, we will be able to go back to our API
and secure one of our routes so that only an authenticated user can access
those resources.

00:59 Finally, what would a back-end be without a good UI? We will build a
quick front-end that will connect to our API.  This UI will also collect user
credentials and send them over to the authentication server to fetch a JWT.

01:13 All this will be done using plain old vanilla JavaScript and none of
those fancy frameworks.  This will give you all the necessary tools to
implement this solution in any application you might build.

01:25 Of course, the examples in this course will be simple, and we will focus
more on the concepts rather than building a real secure API.  For that reason,
we will also show you how to switch your primitive authentication server to use
a proven solution.

01:40 In this lesson, you will be introduced to Auth0 as a solution to provide
secure identity management and federated log in to your users.  Go ahead, watch
this course, and learn how to build more secure applications right now.
*** Lesson 0---Package Setup
The course will be set up in a root directory ~egghead-jwt-auth~, with
~lesson#~ directories for each lesson 1 through 8.  The following shell script
checks for the existence of a ~package.json~ file in the root directory; if one
is found, it simply prints a message.  If one is not found, then it initializes
a new package using the ~yarn init~ command using default values.  The lessons
will add and install prerequisites to this ~package.json~ file.

#+NAME:tangle-files
#+BEGIN_SRC emacs-lisp :results silent :exports results
(org-babel-tangle-file (buffer-file-name))
#+END_SRC

#+name:package-init
#+begin_src sh :dir egghead-jwt-auth :results output :exports both
[ -e package.json ] && \
  echo "package.json has already been created" || \
  yarn --yes init
  cat package.json
#+end_src

*** Lesson 1---Set Up a Web Server in Node.js Using Express
#+CINDEX:Express web server
#+CINDEX:web server, Express
#+CINDEX:server, Express web
#+CINDEX:404 error
In this lesson, we build a very simple Express server.  This server will have a
single route that displays the current date and time and a handler for =404=
pages.

**** Setting Up A Little Express Server
#+CINDEX:Express server, build
00:00 To build your first Express server, the first thing you need to do is to
~require express~.  In order for your code to be able to use it, you need to
install it using ~yarn add express~:

#+name:lesson1-package.json
#+begin_src sh :dir egghead-jwt-auth :results output :exports results
yarn add express
#+end_src

: package.json
: ------------

#+begin_src sh :dir egghead-jwt-auth :results output :exports results
cat package.json
#+end_src

: index.js
: --------

#+name:require-express
#+begin_src js -n
const express = require("express");
#+end_src

{{{heading(Setup Constants)}}}

#+CINDEX:PORT, define
00:16 We'll go back to our code.  We'll declare a new constant ~app~ which will
use the ~express~ library that we've just included.  We'll also declare a new
constant for the =PORT= number.  We'll use =8888= for now.

#+name:app-express
#+begin_src js +n
const app = express();
#+end_src

#+name:port-8888
#+begin_src js +n
const PORT = 8888;
#+end_src

{{{heading(Setup Routes)}}}

{{{subheading(Status Route)}}}

#+CINDEX:route, define
#+CINDEX:@code{app.get}
#+CINDEX:status route
00:30 Then we can do our first route.  We'll use ~app.get~, and we'll specify
the name of the route.  In this case, we're using =status=, and it takes a
callback which has a request and a response as parameters.

#+name:status-route
#+begin_src js +n
app.get("/status", (req, res) => {
    const localTime = (new Date()).toLocaleTimeString();
    res.status(200).send(`Server time is ${localTime}.`);
});
#+end_src
{{{subheading(Catchall Route)}}}

#+CINDEX:catchall route
01:13 Let's also add a catchall route. We'll just use star (=*=), which means
any route that wasn't defined already.  01:19 It also takes a callback with a
request and response.  We can build our response here, and it will simply sense
that as =404=, or 'page not found'.

#+name:catchall-route
#+begin_src js +n
app.get("*", (req, res) => {
    res.sendStatus(404);
});
#+end_src

{{{heading(Start the App Listening)}}}

#+CINDEX:@code{app.listen}
#+CINDEX:app, run
01:30 Finally, we'll use ~app.listen~ to initialize our server.  It'll take a
=PORT=---which we've defined earlier---as a parameter, and a callback for on
success.  01:42 We'll simply say "Server is running on port", and we'll specify
the =PORT= number here.  You now have your first express server.

#+name:app-listen
#+begin_src js +n
app.listen(PORT, () => {
    console.log(`Server is running on port ${PORT}.`);
});
#+end_src

**** Testing the Server

This Makefile sets up some commands to run specific lessons.  Each lesson's
server can be started by moving into the root directory (~egghead-jwt-auth/~)
and typing:
: make lesson# where =#= is one of 1..8.

Thereafter, specific commands can be run from a different terminal, such as:
: make open-browser-status

#+BEGIN_SRC sh :mkdirp yes :tangle egghead-jwt-auth/Makefile
FORCE:

.phony : lesson1
lesson1 : FORCE
	node lesson1

#+END_SRC

01:53 If we go back to our terminal, we can start the server by using Node from
the root directory:
: make lesson1

We've got our server running.

These three Makefile rules provide easy commands to open different routes in
your default browser:

#+BEGIN_SRC sh :tangle egghead-jwt-auth/Makefile
.phony: open-browser
open-browser :
	open http://localhost:8888/

.phony: open-browser-status
open-browser-status :
	open http://localhost:8888/status/

.phony: open-browser-random
open-browser-random :
	open http://localhost:8888/random/

#+END_SRC

#+CINDEX:page not found error
02:02 Now if we go through our browser window, we can type in the
~localhost:8888~.  We'll get a 'page not found' because that route was not
defined.
: make open-browser

#+CINDEX:status route
02:10 We can use =/status= to get the server time, and any other page will give
us a =404= error.
: make open-browser-status
: make open-browser-random

That's it.  You've got your first Express server up and running.
**** Express Server Index.js Code
#+caption:Lesson 1 ~index.js~
#+name:lesson01-index.js
#+begin_src js -n :tangle egghead-jwt-auth/lesson1/index.js :mkdirp yes :noweb yes
<<require-express>>
<<app-express>>
<<port-8888>>

<<status-route>>
<<catchall-route>>

<<app-listen>>
#+end_src

*** Lesson 2---Set the Server Port in Express Using an Environment Variable
#+CINDEX:environment variables
In this lesson we learn how to use an environment variable to set the port of
an express server.

**** Use ~process.env~ to Set the =PORT= Variable
#+CINDEX:@code{process.env}
#+CINDEX:@code{PORT} environment variable, set
00:00 We'll change the =PORT= that this server is using.  We'll use
~process.env~ to access the environment variables from our ~index.js~, and then
we'll create a new variable called =PORT=.  If the =PORT= environment variable
is not defined, we'll still use =8888= as a default.

: index.js
: ----------
#+name:port-env-or-assign
#+begin_src js -n
const PORT = process.env.PORT || 8888;
#+end_src

**** Testing the =PORT= Assignment
00:15 If you run this server, we see that the server is running on =port 8888=.
If we do an ~export~ in our terminal and we set the =PORT= environement
variable for our operating system to say =3000=
: export PORT=3000
{{{noindent}}}and we run this server again, we can see that the server is now
running on ~port 3000~.

00:34 If we open our browser, we go to =localhost:8888=, it can't be
reached.  If we go to =3000=, we're getting a =404= in this case.  If we go to
=localhost:3000/status=, we are getting the server time.

00:48 That's how you set the =PORT= inside an environment variable.

**** Lesson 2 ~index.js~ Code
#+caption:Lesson 2 ~index.js~
#+name:lesson2-index.js
#+begin_src js -n :tangle egghead-jwt-auth/lesson2/index.js :mkdirp yes :noweb yes
<<require-express>>
<<app-express>>
<<port-env-or-assign>>

<<status-route>>
<<catchall-route>>

<<app-listen>>
#+end_src

{{{heading(Adding a Makefile Rule for Lesson 2)}}}

From within the root directory (~egghead-jwt-auth/~) run the command:
: make lesson2
to start the server.  Then type:
: open-browser-3000
: open-browser-status-3000
: open-browser-random-3000
to test.

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson2
lesson2 : FORCE
	(export PORT=3000; node lesson2)
.phony : open-browser-3000
open-browser-3000 :
	open http://localhost:3000/
.phony : open-browser-status-3000
open-browser-status-3000 :
	open http://localhost:3000/status/
.phony : open-browser-random-3000
open-browser-random-3000 :
	open http://localhost:3000/random/
#+end_src

*** Lesson 3---Add a =POST= Route To Express And Parse the Body
#+CINDEX:POST requests
#+CINDEX:@code{body-parser}
In this lesson, we see how to handle =POST= requests on our server and we
extract the data that was passed in the body of the requests using
~body-parser~.

**** Add a =POST= Method to ~index.js~
#+CINDEX:POST method
#+CINDEX:user login
#+CINDEX:login route
00:01 In order to handle our first post request, we will use Express' =POST=
method.  We will create a route that handles user logins.

#+CINDEX:request
#+CINDEX:response
00:08 The first argument is a route, which is =/login= in our case.  The second
argument is a callback with the =request= and =response= arguments.

#+CINDEX:username property
#+CINDEX:JSON object
#+CINDEX:post login route
00:15 Let's now define a constant that will contain the name of the user that
was posted to this route.  The constant name =user= will have the value of the
=username= property that was passed in our =request= as a JSON object.

#+name:post-route
#+begin_src js -n
app.post("/login", (req, res) => {
    const user = req.body.username;

#+end_src

**** Add ~body-parser~ Middleware
#+CINDEX:middleware, body-parser
#+CINDEX:body-parser middleware
00:27 At this point, Express can't read the body of the request.  We will need
to ~require~ an additional middleware called ~body-parser~.

#+name:require-body-parser
#+begin_src js -n
const bodyParser = require("body-parser");
#+end_src

We also go into the terminal to install this new library.

#+name:install-body-parser
#+begin_src sh :dir egghead-jwt-auth :results output :exports both
yarn add body-parser
#+end_src

: package.json
: ------------
#+begin_src sh :dir egghead-jwt-auth :results output :exports results
cat package.json
#+end_src

#+CINDEX:use method, express
#+CINDEX:JSON responses
00:40 Now that it's installed, we can add the middleware to Express using the
=use= method.  We will specify that it will handle JSON responses.

#+name:app-use-body-parser
#+begin_src js -n
app.use(bodyParser.json());
#+end_src

**** Build the =response=
#+CINDEX:response, post request
#+CINDEX:200 status
#+CINDEX:status 200
#+CINDEX:success status 200
00:49 We are now able to read the =request= body, so our constant contains the
=username= that was passed into login route.  We are ready to build our
=response=, which has a status of =200= because this is a success.

01:01 We will send back a simple string that says, "You logged in with
username: ${user}".  It will display the =username= that we just received.

#+name:post-route-res
#+begin_src js -n
    res
    .status(200)
    .send(`You logged in with username: "${user}"`);
});
#+end_src

**** Start the Server
01:08 Let's start our server using ~node~.  From the root directory type:
: make lesson3

#+name:Makefile
#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson3
lesson3 : FORCE
	(export PORT=3000;node lesson3)
#+end_src

The server is now listening on =localhost:3000=, which was defined as an
environment variable previously.

**** Test the Server
#+CINDEX:Postman
#+CINDEX:@command{curl}
01:18 To test this new route, we can use Postman (or ~curl~).  If we try to do
a =GET= request to =/status=, we should get the local time:
: make open-browser-status-3000

#+CINDEX:POST request
#+CINDEX:@code{username} property
#+CINDEX:Content-Type
#+CINDEX:application/json
01:28 Now, we can do a =POST= request to the =/login= route.  Let's start by
specifying the body of our request.  It will be a JSON object with a =username=
property.  Make sure that you change the Content-Type to =application/json=.

#+name:Makefile
#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : post-login
post-login : FORCE
	curl \
	  --header Content-Type:application/json \
	  --data   '{"username":"admin"}' \
	  http://localhost:3000/login \
#+end_src

#+CINDEX:parse POST request
01:43 If we run this, you get a, "You logged in with username: \"admin\""
message.  That is how you parse a =POST= request and handle the =request= data.

**** Lesson 3 ~index.js~ Code
#+caption:Lesson 3 ~index.js~
#+name:lesson3-index.js
#+begin_src js :tangle egghead-jwt-auth/lesson3/index.js :mkdirp yes :noweb yes
<<require-express>>
<<require-body-parser>>

<<app-express>>
<<app-use-body-parser>>

<<status-route>>
<<post-route>>
<<post-route-res>>
<<catchall-route>>

<<port-env-or-assign>>
<<app-listen>>
#+end_src

*** Lesson 4---Provide Users With A JSON Web Token
#+CINDEX:token issuer
#+CINDEX:JSON web token
In this lesson, we will build a token issuer that will return a JSON Web
Token.  This simple server will have a single endpoint for login that queries a
list of users and returns a web token for the matching user.

**** The User Database
#+CINDEX:authentication server
#+CINDEX:user database
#+CINDEX:user array
00:00 Since this lesson is all about creating an authentication server, let's
start by creating a user database.  We will use a user array that contains all
of our users and store the passwords in plain text right now.

#+CINDEX:warning
00:11 Warning, do not do this in production.  You should always encrypt
passwords and ensure that no sensitive information about your users is
accessible to potential hackers.  For the sake of this lesson, let's just do it
this way.

#+name:users-array
#+begin_src js -n
const users = [
    {id: 1, username: "admin", password: "admin"},
    {id: 2, username: "guest", password: "guest"}
];
#+end_src

**** Authentication Route
#+CINDEX:@code{/login} route
#+CINDEX:@code{POST} request
#+CINDEX:user authentication
00:26 We can now start with our =/login= =POST= request.  This is the request
that will handle user authentication.  The first thing to check is if the
request is formatted correctly.  We are expecting both a username and a
password.

#+CINDEX:400 status
#+CINDEX:status 400
#+CINDEX:invalid request, status 400
00:45 If we don't have both, we =return= a status code of =400= for invalid
request, and we =send= a message to the user, saying that "You need a username
and password".  We can then do a ~return~ to stop the execution of this
callback.

#+CINDEX:@code{find} method
01:08 Now, if we have a valid request, we need to check if the user is in our
database.  Using the =find= method, we will check if we have a user that has a
=username= and =password= that matches those in the =request=.

#+CINDEX:401 status
#+CINDEX:status 401
#+CINDEX:unauthorized request
01:20 If we find a matching user, it will be stored in a constant, ~user~.  If
we can't find a matching user, we can send a response with the status of =401=
for =unauthorized=.  We can also ~send~ a message to the user, saying "User not
found".  Once again, we ~return~ to stop the execution of this callback.

#+name:authentication-login
#+begin_src js -n
app.post("/login", (req, res) => {
    if (!req.body.username || !req.body.password) {
        res
        .status(400)
        .send("You need a username and password");
        return;
    }

    const user = users.find((u) => {
        return u.username === req.body.username && u.password === req.body.password;
    });

    if (!user) {
        res
        .status(401)
        .send("User not found");
        return;
    }

#+end_src

**** Create a JWT for a Valid User
#+CINDEX:JSON web token
01:45 If we have a valid user, we will send back a JSON web token as a
response.

#+CINDEX:@code{jsonwebtoken} library
In order to do so, we will need to ~require~ the ~jsonwebtoken~ library.  We will
also need to install it using ~yarn add jsonwebtoken~.

#+name:require-jsonwebtoken
#+begin_src js -n
const jwt = require("jsonwebtoken");
#+end_src

#+begin_src sh :dir egghead-jwt-auth :results output :exports both
yarn add jsonwebtoken
#+end_src

: package.json
: ------------
#+begin_src sh :results output :exports both :dir egghead-jwt-auth
cat package.json
#+end_src

#+CINDEX:@code{sign} method
#+CINDEX:sign token
#+CINDEX:payload
#+CINDEX:secret key
02:13 Now that it's installed, we can use the =sign= method to create a sign
token.  We start by passing the payload we want to attach in the =jwt=.  We
then pass a string which is the =secret key=.  In this case, it's
"mysupersecretkey".

#+CINDEX:options
#+CINDEX:access_token
02:34 Finally, we can pass some options like in how much time this token will
expire, so we'll say expires in three hours for us.  Finally, we can send back
our response with a status of =200= and a JSON object with our =access_token=.

#+name:create-access-token
#+begin_src js -n
      const token = jwt.sign(
        {
          sub: user.id,
          username: user.username
        }, "mysupersecretkey", {expiresIn: "3 hours"}
      );

      res
       .status(200)
       .send({access_token: token});
  });
#+end_src

**** Testing the Lesson 4 Server
#+CINDEX:authentication server, run
03:01 We can now run the authentication server using node and the name of the
file.

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson4
lesson4 : FORCE
	(export PORT=3000;node lesson4)
#+end_src

Let's now open Postman (use ~curl~) to test this out.

03:10 If we try a =GET= request on the server, we're getting a =404= because we
haven't defined any =GET= route on the server.

#+begin_src sh :dir egghead-jwt-auth
make open-browser-status-3000
#+end_src

Let's change that to a =POST= and use the =/login= endpoint that we just
created.  Sending a ~request~ to that URL without a body will give us a =400= with a
message, "You need a username and password."  Let's try to add those.

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : wrong-auth-login
wrong-auth-login :
	curl \
	  --header Content-Type:application/json \
	  --data   '{"username":"Felix","password":"the-cat"}' \
	  http://localhost:3000/login \

.phony : auth-login
auth-login :
	curl \
	  --header Content-Type:application/json \
	  --data   '{"username":"admin","password":"admin"}' \
	  http://localhost:3000/login \

#+end_src

03:29 For the =body=, select =raw= and make sure that the =type= is set to
=application/json=.  You can now type in a =username= and =password= in JSON
format.  If we type a wrong password, we should be getting the "User not found"
message.  If we fix the password to use the right one, we get our JSON object
with an =access_token=.

03:56 You can copy and paste this JSON web token in a website like ~jwt.io~ and
you will be able to see the content.  If you try it with another user like
=guest=, you will get a different =access_token=, and if we go into ~jwt.io~,
we can once again see all of the content and we can see that it's different
this time.

04:28 That's it.  You have now created your first authentication server.

**** Lesson 4 ~index.js~ Code
#+caption:Lesson 4 ~index.js~ Code
#+name:lesson4-index.js
#+begin_src js :tangle egghead-jwt-auth/lesson4/index.js :mkdirp yes :noweb yes
<<require-express>>
<<require-body-parser>>
<<require-jsonwebtoken>>

<<app-express>>
<<app-use-body-parser>>
<<users-array>>

<<status-route>>
<<authentication-login>>
<<create-access-token>>
<<catchall-route>>

<<port-env-or-assign>>
<<app-listen>>
#+end_src

*** Lesson 5---Allow CORS in Node.js and Expres
In this quick lesson, we see how to add the CORS middleware so that our Express
server can handle requests from different origins.

**** The CORS Prohibition
#+CINDEX:CORS prohibition
00:00 If you have an API that runs on a different server or even a different
port than your application, and you try to do a ~fetch~, you should see a
message in your console complaining about
=Access-Control-Allow-Origin=.[fn::Safari allows such a fetch, but Google
Chrome does not.]

[[file:./resources/cors-error-50.png]]

**** The Fix to the CORS Prohibition
00:19 The fix for this in your Express server is very simple.

#+CINDEX:@code{cors} library
First of all, you need to require the CORS library:

#+name:require-cors
#+begin_src js -n
const cors = require("cors");
#+end_src

Secondly, you need to tell your Express server to use this middleware by using
~app.use~ and the library that we've just installed.

#+name:app-use-cors
#+begin_src js +n
app.use(cors());
#+end_src

#+CINDEX:@code{express-jwt} library
Thirdly, use a different JSON web token library, ~express-jwt~, which the author
does not explain here, but explains in the next lesson.

#+name:require-expressjwt
#+begin_src js +n
const expressjwt = require("express-jwt");
#+end_src

#+name:jwtCheck
#+begin_src js +n
const jwtCheck = expressjwt({secret: "mysupersecretkey"});
#+end_src

<<add-express-jwt>>You'll also need to install both using ~yarn add~:

#+begin_src sh :dir egghead-jwt-auth :results output :exports both
yarn add cors express-jwt
#+end_src

Our ~package.json~ now looks like this:

: package.json
: ------------
#+begin_src sh :dir egghead-jwt-auth :results output :exports results
cat package.json
#+end_src

**** Start Lesson 5 Server Running
00:46 Now, if you restart your server and try the same ~fetch~ call in your
browser, you won't have that CORS error any more.

Start the server for this lesson with:
: make lesson5

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson5
lesson5 : FORCE
	(export PORT=3000;node lesson5;)
#+end_src

[[file:./resources/cors-fix-50.png]]

**** Set Up Two New Routes for Public and Private Resources
Two new routes will be added here, and explained in the next lesson.

#+name:public-resource-route
#+begin_src js -n
app.get("/resource", (req, res) => {
    res
    .status(200)
    .send("Public resource; okay to see");
});

#+end_src

#+name:private-resource-route
#+begin_src js +n
app.get("/resource/secret", jwtCheck, (req, res) => {
    res
    .status(200)
    .send("Secret resource; you should be logged in to see this.");
});

#+end_src

**** Lesson 5 ~index.js~ Code
Here is the code for Lesson 5 in ~index.js~.  The two routes will be explained
in the next lesson.

#+name:Lesson5-index.js
#+begin_src js :tangle egghead-jwt-auth/lesson5/index.js :mkdirp yes :noweb yes
<<require-express>>
<<require-body-parser>>
<<require-cors>>
<<require-expressjwt>>
<<jwtCheck>>

<<app-express>>
<<app-use-body-parser>>
<<app-use-cors>>

<<public-resource-route>>
<<private-resource-route>>
<<catchall-route>>

<<port-env-or-assign>>
<<app-listen>>
#+end_src

*** Lesson 6---Authenticate Users With JWT for Access to Protected Resources
In this lesson, we build a simple API with two endpoints, one public and one
secure.  Using JWT and validating with the signature, we ensure that the user is
authorized and has access to a protected resource before serving it.

**** Create Two Resource Routes
00:00 In this lesson, we will create an API with two routes.  The first one for
the ~/resource~ endpoint will be public, and simply return a status of =200=, and
a message saying, "Public resource, you can see this".

#+begin_src js -n :noweb yes
<<public-resource-route>>
#+end_src

00:22 Our second route will be for the ~/resource/secret~ endpoint.  This will
be a secured route.  For this endpoint, we will return a =200=, as well as a
message that says, "Secret resource, you should be logged in to see this."

#+begin_src js +n :noweb yes
<<private-resource-route>>
#+end_src

**** Create an =API_PORT= Environment Variable
00:42 This server will run on the port specified by the environment variable
=API_PORT=.  Let's go into our terminal, set this using ~export~, and set the
=API_PORT= to =5000=.  Now, we can run the server by using ~node~ and the name
of the file.
: make lesson6

#+name:api-port
#+begin_src js -n
const API_PORT = process.env.API_PORT;
#+end_src

#+name:app-listen-api-port
#+begin_src js +n
app.listen(API_PORT, () => console.log(`API Server is running on port ${API_PORT}`))
#+end_src

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson6
lesson6 : FORCE
	(export API_PORT=5000;node lesson6;)
#+end_src

**** Test the Server
01:00 To test our API, we will use Postman.  If we go to ~localhost:5000~,
we're getting a =404=, =page not found=, because that route was not defined.  If we
try ~localhost:5000/resource~, we should see our public resource there.  If we try
~localhost:5000/resource/secret~, we can also see the content of this resource.

**** Block the Secret Resource Route
#+CINDEX:@code{express-jwt}
#+CINDEX:block protected routes
#+CINDEX:middleware
Our next step will be to block those requests by requesting a valid JSON web
token.  To do so, we will require the ~expressjwt~ middleware.

#+begin_src js :noweb yes
<<require-expressjwt>>
#+end_src

01:39 Let's now open a terminal, and install it, using ~yarn~[fn::this was done
in the prior lesson] [[add-express-jwt][express-jwt]].

#+CINDEX:@code{express-jwt} initialization
Good.  Now, let's define this middleware.  We can initialize this middleware by
using ~expressjwt~ and passing it some options.  If you are using a real
authentication server, you'd want to check for the =issuer=, the =audience=,
and more to validate the integrity of the server.

02:01 In our case, we will only check to see if the signature matches the one
from our authentication server, "mysupersecretkey", in this case.

#+begin_src js -n :noweb yes
<<jwtCheck>>
#+end_src

Finally, we can secure our private route by adding the middleware as the second
argument of our =app.get= method.

#+begin_src js -n :noweb yes
<<private-resource-route>>
#+end_src

**** Testing the Server with a Protected Route
We are now ready to restart our server and test it in Postman.

02:24 Now, if we try a protected route again, we see that we're getting an
error message, saying that no authorization token was found.

[[file:./resources/postman-unauthorized-get-40.png]]

Let's go to the Authorization section, and select a =Bearer Token= type of
authentication.

[[file:./resources/bearer-token-authentication-type-50.png]]

02:38 We can take a valid token from ~jwt.io~ in this case[fn::After first
entering the secret key "mysupersecretkey" in the =verify signature= box
[[file:./resources/jwt.io-secret-key-25.png]]], and simply paste that in the token
box in Postman.
: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6Ikp\
: vaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.oGFhqfFFDi9sJMJ1U2dWJZNYEiUQBEtZRVuwKE7Uiak

We can now try to make our call to =/resource/secret= again, and we can now see
the content of this route.  Now, you have an API with a secured endpoint.

[[file:./resources/postman-with-bearer-token-40.png]]

**** Lesson 6 ~index.js~ Code

#+caption:Lesson 6 ~index.js~ Code
#+name:Lesson6-index.js
#+begin_src js :tangle egghead-jwt-auth/lesson6/index.js :noweb yes :mkdirp yes
<<require-express>>
<<require-body-parser>>
<<require-cors>>
<<require-expressjwt>>
<<jwtCheck>>

<<app-express>>
<<app-use-cors>>
<<app-use-body-parser>>

<<public-resource-route>>
<<private-resource-route>>
<<catchall-route>>

<<api-port>>
<<app-listen-api-port>>
#+end_src

*** Lesson 7---Connect a Front-End to a Secure API using JWTs
In this lesson, we add the login form to a single page application and we pass
our tokens to the API.  Should the token be valid, we will have access to the
data from the secure endpoint in the API.

**** The Single Page Application
#+name:index.html
#+begin_src html -n :tangle egghead-jwt-auth/lesson7/index.html :mkdirp yes
<html>
<head>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
</head>

<body>
<div class="container container-fluid">
    <nav class="navbar navbar-expand-lg navbar-light bg-light">
        <a class="navbar-brand" href="#">Secure your SPA</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav mr-auto">
                <li class="nav-item active" data-route="#">
                    <a class="nav-link" href="#">Home</a>
                </li>
            </ul>
            <form class="form-inline">
                <button class="btn btn-outline-success my-2 my-sm-0" data-toggle="modal" data-target="#loginModal" type="button" id="loginModalBtn">Login</button>&nbsp;
                <button class="btn btn-outline-danger d-none" id="logoutBtn">Logout</button>
            </form>
        </div>
    </nav>

    <span id="mainPage">

        <div class="row">
            <div class="col-1"></div>
            <div class="col-10 text-center">
                <p>Welcome to the headline generator application.  Click on the buttons to get a headline</p>
            </div>
            <div class="col-1"></div>
        </div>

        <div class="row">
            <div class="col-12 text-center">
                <button class="btn btn-lg btn-primary" id="headline">Public</button>&nbsp;
                <button class="btn btn-lg btn-secondary" id="secret">Private</button>
            </div>
        </div>

        <div class="row">&nbsp;</div>

        <div class="row">
            <div class="col-2"></div>
            <div class="col-8">
                <div class="alert alert-dark" style="overflow-wrap: break-word">
                    Test the API
                </div>
            </div>
            <div class="col-2"></div>
        </div>

        <div class="row justify-content-center">
            <div class="col-4 text-center">
                <img src="http://http.cat/200" id="httpcat" width="350px"/>
            </div>
        </div>
    </span>

    <span id="secretPage" class="d-none">
        This is a secret area!
    </span>

    <span id="unauthorizedPage" class="d-none">
        You are not authorized to see this page.
    </span>
</div>

<div class="modal fade" id="loginModal" tabindex="-1" role="dialog">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Modal title</h5>
                <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                    <span aria-hidden="true">&times;</span>
                </button>
            </div>
            <div class="modal-body">
                <form>
                    <div class="form-group">
                        <label for="username">Username</label>
                        <input type="text" class="form-control" id="username">
                    </div>
                    <div class="form-group">
                        <label for="password">Password</label>
                        <input type="password" class="form-control" id="password">
                    </div>
                </form>
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                <button type="button" class="btn btn-primary" data-dismiss="modal" id="loginBtn">Login</button>
            </div>
        </div>
    </div>
</div>


<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

<script src="./ui-update.js"></script>
<script src="./index.js"></script>
</body>
</html>
#+end_src

**** The Helper Functions in UI-Update
#+name:ui-update.js
#+begin_src js -n :tangle egghead-jwt-auth/lesson7/ui-update.js :mkdirp yes
let UIUpdate = {};

UIUpdate.loggedIn = function(token) {
  UIUpdate.alertBox(`Just logged in<br>Token:<br>${localStorage.getItem("access_token")}`);
  loginModalBtn.classList.add("d-none");
  logoutBtn.classList.remove("d-none");
};

UIUpdate.loggedOut = function() {
  localStorage.removeItem("access_token");
  loginModalBtn.classList.remove("d-none");
  logoutBtn.classList.add("d-none");
};

UIUpdate.routeChange = function() {
  if (document.querySelector(".navbar-nav li.active")) {
    document.querySelector(".navbar-nav li.active").classList.remove("active");
  }
  document.querySelector(".navbar [data-route='#" + window.location.hash.replace("#", "") + "']").classList.add("active");
};

UIUpdate.updateCat = function(status) {
  const httpCat = document.querySelector("#httpcat");
  httpCat.src = "http://http.cat/" + status;
};

UIUpdate.alertBox = function(message) {
  const alertBox = document.querySelector(".alert");
  alertBox.innerHTML = message;
};

UIUpdate.getUsernamePassword = function() {
  return {
    username: document.querySelector("#username").value,
    password: document.querySelector("#password").value
  }
};

window.addEventListener("hashchange", UIUpdate.routeChange);
#+end_src

**** The Authentication Server
#+name:auth.js
#+begin_src js -n :tangle egghead-jwt-auth/lesson7/auth.js :mkdirp yes :noweb yes
<<require-express>>
<<require-body-parser>>
<<require-jsonwebtoken>>
<<require-cors>>
<<users-array>>

<<app-express>>
<<app-use-body-parser>>
<<app-use-cors>>

<<authentication-login>>
<<create-access-token>>
<<catchall-route>>

<<port-env-or-assign>>
<<app-listen>>
#+end_src

**** The API Server
#+name:api.js
#+begin_src js -n :tangle egghead-jwt-auth/lesson7/api.js :mkdirp yes :noweb yes
<<require-express>>
<<require-body-parser>>
<<require-cors>>
<<require-expressjwt>>
<<jwtCheck>>

<<app-express>>
<<app-use-body-parser>>
<<app-use-cors>>

<<public-resource-route>>
<<private-resource-route>>
<<catchall-route>>

<<api-port>>
<<app-listen-api-port>>
#+end_src

**** Install Static Server ~httpster~
To set up a static file server for the front end, install ~httpster~ from NPM.
To start the server using =PORT 5000=, use
: yarn run httpster -p 5000 -d lesson7
from inside the root directory (~egghead-jwt-auth/~).

To start all of the servers (~auth~, ~api~, and ~frontend~), run the ~make~
command ~make lesson7~.  To terminate all of the servers, run the ~make~
command ~make kill~.  The ~auth~ server will run on =PORT 3000= while the ~api~
server will run on =PORT 3333=.

#+begin_src sh :results output :exports both :dir egghead-jwt-auth
yarn add httpster --dev
#+end_src

: package.json
: ------------
#+begin_src sh :results output :exports both :dir egghead-jwt-auth
cat package.json
#+end_src

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson7
lesson7 : FORCE
	yarn run httpster -d lesson7 -p 5000 &
	export PORT=3000;node lesson7/auth.js &
	export API_PORT=3333;node lesson7/api.js &

.phony : kill
kill :
	pkill node
#+end_src

**** Framework of the Front End Connection
#+name:index.js
#+begin_src js -n :noweb tangle :tangle egghead-jwt-auth/lesson7/index.js
/* To run this file on a server, we are using httpster.
Type `httpster index.html -p 5000` in your console to start the server. */

<<api-url>>
<<auth-url>>

<<access-token>>

const headlineBtn = document.querySelector("#headline");
const secretBtn = document.querySelector("#secret");
const loginBtn = document.querySelector("#loginBtn");
const logoutBtn = document.querySelector("#logoutBtn");

<<headlineBtn.addEventListener>>

<<secretBtn.addEventListener>>

<<loginBtn.addEventListener>>

<<logoutBtn.addEventListener>>

#+end_src
**** Connect the Front End to the API Server
#+CINDEX:api server
00:00 To connect our front-end to our API in our authentication server, we
first need the URL for those.  In this case, I started the API on port 8888, so
we can add that to a constant.

#+name:api-url
#+begin_src js
const API_URL = "http://localhost:3333";
#+end_src

#+CINDEX:authentication server
00:18 The authentication server is also running at =http://localhost:3000=.
Let's add this to the =AUTH_URL= constant.

#+name:auth-url
#+begin_src js
const AUTH_URL = "http://localhost:3000";
#+end_src

#+CINDEX:@code{ACCESS_TOKEN}
We will keep the =ACCESS_TOKEN= from our authentication server stored in
memory.  For now, we can initialize the =ACCESS_TOKEN= constant to =undefined=.

#+name:access-token
#+begin_src js
let ACCESS_TOKEN = undefined;
#+end_src

**** Look at the Prebuilt Front End
#+CINDEX:front end
#+CINDEX:jumbotron
#+CINDEX:AJAX calls
00:36 Let's take a look at the front-end that was pre-built for us.  There is a
button labeled =public=, and another labeled =private=.  They will both update
the jumbotron beneath it with the response that we're getting from our AJAX
calls.

[[file:./resources/prebuilt-frontend-25.png]]

#+CINDEX:helper functions
#+CINDEX:@code{UI_Updates}
00:50 The image of the cat will also be updated with the status code that we
are getting from the server.  For the =UIUpdate= functions, all of the helper
functions are already created.  We will focus on the actual logic in here.

**** Set Up Buttons in Front End

{{{heading(The PUBLIC Button)}}}

#+CINDEX:public button
01:03 For now, none of the buttons do anything.  Let's go back to our code in
~index.js~.

#+CINDEX:@code{/resource} endpoint
#+CINDEX:API server
The variable =headlineBtn= holds a reference to the button labeled =public=.
We will start by doing a ~fetch~ to our public ~/resource~, which is on the API
server at the ~/resource~ endpoint.

#+CINDEX:@code{fetch}
#+CINDEX:promise, from @code{fetch} call
01:23 ~fetch~ returns a promise, so we will use the ~then~ method with the
response and we will return the result of =resp.text=.  This will return the
actual data in text format to the next chained ~.then~ method.

#+CINDEX:jumbotron
#+CINDEX:@code{UI_Update} object
01:40 Finally, we can use the =UIUpdate= object and the ~alertBox~ method to update
the jumbotron with the data from our response.

#+name:headlineBtn.addEventListener
#+begin_src js -n
  headlineBtn.addEventListener("click", () => {
          fetch(`${API_URL}/resource`).then(resp => {
              UIUpdate.updateCat(resp.status);
              return resp.text();
          }).then(data => {
              UIUpdate.alertBox(data);
          });
  });
#+end_src

{{{subheading(Test the PUBLIC Button)}}}

01:51 We are ready to test our first AJAX call.  Clicking on the =public=
button shows the public resource.  You can see this message.  That works.

{{{heading(The PRIVATE Button)}}}

#+CINDEX:private button
02:00 Let's now move on to the second button, the one labeled =private=.  In
here, we will do a very similar code.  We start by doing a ~fetch~ to the
=API_URL= and ~/resource/secret~ URL.  We return the ~.text~ from the response
and we update our jumbotron the same way we did for the public button.

#+begin_src js -n
  secretBtn.addEventListener("click", (event) => {
          fetch(`${API_URL}/resource/secret`).then(resp => {
              UIUpdate.updateCat(resp.status);
              return resp.text();
          }).then(data => {
              UIUpdate.alertBox(data);
          });
  });
#+end_src

{{{subheading(Test the PRIVATE Button)}}}

#+CINDEX:authorization header
02:25 If we go and test this, we will see that we are getting an error message
instead of the actual response that we are expecting.  That is due to the fact
that we have not passed in an authorization header.

#+CINDEX:@code{UIUpdate.updateCat} method
#+CINDEX:@code{resp.status} code
02:35 Now that we know that this URL will sometimes return us an error code,
let's update our =httpCat= with the response that we get from the server.
Before we return the parse body of our response, we can use the
=UIUpdate.updateCat= method with the =resp.status= code.

#+begin_src js
  secretBtn.addEventListener("click", (event) => {
          fetch(`${API_URL}/resource/secret`).then(resp => {
              UIUpdate.updateCat(resp.status);
              return resp.text();
          }).then(data => {
              UIUpdate.alertBox(data);
          });
  });
#+end_src

#+CINDEX:401 error code
#+CINDEX:unauthorized access
02:52 If we try this again, we see that we're getting a =401=, which is the error
code for an =unauthorized access=.

**** Authentication
#+CINDEX:authenticate
#+CINDEX:login
#+CINDEX:@code{LOGIN} button
#+CINDEX:authorization server
03:00 Before we can pass in a token with our request, we will need to
authenticate.  Let's go to the =login= button click event listener and do a
=POST= request to our authorization server.

#+CINDEX:Content-Type
#+CINDEX:application/json
#+CINDEX:request headers
#+CINDEX:headers, request
#+CINDEX:accept header
03:12 In here, we will do a request to the =${AUTH_URL}/login= endpoint.  We
will also specify a few options with our request.  First, this is not a =GET=,
so we will need to add method =POST=; then we need to specify the headers to
tell our server that we are sending =Content-Type:"application/json"=.

#+CINDEX:@code{UIUpdate} helper object
03:31 We need to specify that we are ~accepting~ a response type of
"application/json".  The body of our request will be the =username= and
=password= in JSON format provided by our =UIUpdate= helper object.

#+CINDEX:@code{httpCat}
03:47 We will update our =httpCat= with the ~resp.status~ code.  If we get a
=200=, we will send the JSON object from our response to the next promise.  If
our response was anything else, we will use the text of the response.

#+CINDEX:@code{ACCESS_TOKEN}
04:01 We can then chain with another ~.then~ and verify the presence of an
=ACCESS_TOKEN=.  If we have one, we can store the =ACCESS_TOKEN= in the
=ACCESS_TOKEN= variable that we defined in the beginning.

#+CINDEX:@code{UIUpdate.loggedIn} method
04:22 We can also overwrite the content of data with =ACCESS_TOKEN=: and the
content of the token.  If we have an =ACCESS_TOKEN=, this means that we are
logged in, so we can use the ~UIUpdate.loggedIn~ method to update our UI.

#+CINDEX:jumbotron
04:43 Finally, we will update our jumbotron with our data variable.

#+name:loginBtn.addEventListener
#+begin_src js -n
  loginBtn.addEventListener("click", (event) => {
      fetch(`${AUTH_URL}/login`, {
          method: "POST",
          headers: {
              "Content-Type": "application/json",
              "accept": "application/json",
          },
          body: JSON.stringify(UIUpdate.getUsernamePassword())
      }).then(resp => {
          UIUpdate.updateCat(resp.status);
          if (resp.status == 200) {
              return resp.json();
          } else {
              return resp.text();
          }
      }).then(data => {
          if (data.access_token) {
              ACCESS_TOKEN = data.access_token;
              data = `Access Token: ${data.access_token}`;
              UIUpdate.loggedIn();
          }
          UIUpdate.alertBox(data);
      });
  });
#+end_src

**** Test the Authentication Login
Let's try this out.

#+CINDEX:400 status
#+CINDEX:bad request, 400
04:54 If we click on =login=, we have a modal asking for our credentials.  If we
enter nothing, we are getting a =400= bad request error with the message, "You
need a username and password."

#+CINDEX:401 status
#+CINDEX:unauthorized error
05:05 Let's try to enter =username= "admin", and an invalid password.  This
time, we are getting a =401= =unauthorized= with the message, "User not found."

#+CINDEX:access token, receive
Now, if we use the right =username= and =password= combination, we are getting
an access token.

#+CINDEX:@url{jwt.io}
05:20 If we copy and paste the access token in ~jwt.io~, we can see the content
of the token.  It has the right username.

05:30 Back to our application, if we click on =private=, we are still getting a
"No authorization token was found" error message.  That's because we are still
not passing a token with our request.

**** Set Up Authentication to the Private Route
#+CINDEX:headers, request
#+CINDEX:@code{secretBtn}
05:43 Back to the =secretBtn=, let's start by defining our headers.  We can
start by initializing with an empty object, then we test to see if =ACCESS_TOKEN=
is still =undefined= or if we have an =ACCESS_TOKEN= stored there.

#+CINDEX:bearer token
05:58 If we do, we can specify the headers.  We will add an "Authorization" with
the value of =Bearer= followed by a space, and then =${ACCESS_TOKEN}=.

06:13 Now, we can add those through our request as a second argument to our
~fetch~.

#+name:secretBtn.addEventListener
#+begin_src js -n
secretBtn.addEventListener("click", (event) => {
	let headers = {};
	if (ACCESS_TOKEN) {
		headers = {
			"Authorization": `Bearer ${ACCESS_TOKEN}`
		};
	}
	fetch(`${API_URL}/resource/secret`, { headers }).then(resp => {
		UIUpdate.updateCat(resp.status);
		return resp.text();
	}).then(data => {
		UIUpdate.alertBox(data);
	});
});
#+end_src

**** Test Authentication to Private Resource Route
Let's test this out.  Start by refreshing the app, and then log in using =admin=
and the valid password.

#+CINDEX:secret resource
06:27 Now, if you click on =private=, you'll get the secret resource.  You should
be logged in to see this message.  We now have access to our secret resource.

**** Log Out Procedure
#+CINDEX:@code{logoutBtn}
#+CINDEX:@code{UIUpdate.loggedout} method
06:36 Finally, we will need a way to log out.  If we go to the =logoutBtn= "click"
event handler, we can simply reset our =ACCESS_TOKEN= to =undefined= and use the
~UIUpdate.loggedout~ method.

#+name:logoutBtn.addEventListener
#+begin_src js -n
logoutBtn.addEventListener("click", (event) => {
	ACCESS_TOKEN = undefined;
	UIUpdate.loggedOut();
});
#+end_src

06:51 One last time to our application, and we can now ~login~ using a valid
credential and get access to the =private= button.  Now, if you log out and try
the =private= button again, you're getting the =401= error with the "No
authorization token found" error message again.

07:09 That's it.  You now have a front-end that access both public and private
data from an API using a JSON web token.

*** Lesson 8---Authenticate Users in a Single Page Application with Auth0
In this lesson, we take the previous API and front-end and we convert them to
use Auth0 to replace our custom authentication server built in the previous
lessons.

00:00 Since this lesson is aimed at using Auth0 for authentication, the first
thing we'll need to do is to go to the [[https://auth0.com/][auth0.com]] website and create a free
account.

00:09 The sign-up process is fairly straightforward.  You can use an email and
password or you can use any of the social connections here.  This free account
will give you access to most of the Auth0 API for up to 7,000 users, which is
more than enough for the purpose of this lesson.

00:24 Once you're signed up, you can log into your account, and you will land
on this dashboard.  This shows you your active users and the number of logins
in the last few days.

00:34 From here, we'll want to go to the API section to create a new
entry.  This is what will be used to protect our API.

00:42 You can pick anything for the name.  Let's just use =egghead-demo=.  For
the identifier, you can use anything, but it is recommended that you use the
URL of your application.  In this case, we don't have a URL, so we'll just use
=egghead-demo= as well.

00:58 Finally, you will want to use =HS256= for the signing algorithm, because
this is what we used in the previous lesson.

Once you have this, you click on =create=, and the modal is closed, and you get
redirected to the quick start page.

01:11 If you look at this page, you get code examples on how to implement this
with your API.  As you can see, it uses the same middleware as we currently use,
the main difference being the settings for the middleware itself.

01:24 We will have a secret key, but we also check who is the token meant for,
the audience, and who created this token, the issuer.  Those are additional
checks that will make your API even more secure.

Let's now go back at our code editor and open ~api.js~.

01:41 You can simply change the settings of the middleware by pasting the
values you copied from the Auth0 website.  Note that those values will need to
be the ones from your Auth0 account.  If you try to copy the values that I just
pasted in, this won't work for you.

#+begin_src js -n
const jwtCheck = expressjwt({
  secret: 't2ABNgm7aB8YrMrnsutSB0bPNtLZbC7P',
  audience: 'secure-spa-auth0',
  issuer: "https://joel-1.auth0.com/"
});
#+end_src

01:56 We can now head to our terminal window and start our API server by
running ~node api~.  Your server is now running on port 8888.

If you try this now, nothing will work.  Your front end also needs to get a
token from Auth0.  Let's get back to our code and do those changes.

02:13 Because we won't be using our authorization server anymore, we can go
ahead and remove the ~auth.js~ file from this folder altogether.

It's now time to edit our ~index.html~ page to use Auth0's authentication server
instead of ours.

02:28 The first thing that we'll want to do is to remove the login modal.  We
will be using Auth0's login screen, so let's go to line 21 and remove those
data tags that were used to open the modal.

02:40 We can also rename this button to be =loginBtn= instead.

Since we won't be using the modal anymore, we can go down here and delete all
of the markup for our login modal.

02:55 We will use Auth0's library, which we will get from their CDN.  We can
add a script tag.  The source will be =https://cdn.auth0.com/js/auth0/=, the
version number, which is =9.5.1=, the latest at this moment, and finally
=/auth0.min.js=.
: <script src="https://cdn.auth0.com/js/auth0/9.5.1/auth0.min.js"></script>

03:21 Our ~index.html~ file is not ready, but to finish the UI changes, we will
need to go to the ~ui-update.js~ file and do a few minor changes in
there.  Instead of showing and hiding the login modal button, we will do that on
the =loginBtn=.  Let's change line 5 to use =loginBtn=, and same thing on
line 11.  We're almost done.

: ui-update.js
: ------------

#+begin_src js -n
UIUpdate.loggedIn = function(token) {
  UIUpdate.alertBox(`Just logged in<br>Token:<br>${ACCESS_TOKEN}`);
  loginBtn.classList.add("d-none");
  logoutBtn.classList.remove("d-none");
};

UIUpdate.loggedOut = function() {
  localStorage.removeItem("access_token");
  loginBtn.classList.remove("d-none");
  logoutBtn.classList.add("d-none");
};
#+end_src

03:44 Let's open our ~index.js~ file to change our code to use Auth0's
authentication server instead of the one we built.  In here, we will need to
use Auth0's =webAuth= object.  First, we need to get the settings for this
object.  Let's go back to Auth0's website and go into the =Applications=
section.

04:03 In here, we choose to create a new application.  We can name it whatever,
but we will use =egghead-demo= for consistency.  This application is of type
=single-page application=, so we can select this and click on create.

04:17 Similar to when we created the API, we get a screen that suggests us
various quick starts.  In here, you can find for most major JavaScript
frameworks, but we are going to use plain vanilla JavaScript here.

04:30 If you scroll down, you will find a section which has all of your
settings for your application.  Once again, make sure that you copy those from
your Auth0 account, and not those from this video.  Let's copy that and go back
to our code.

04:44 Now we can create a =webAuth= object using a new =auth0.WebAuth=, and we
can paste the settings we got from the quick start.

: index.js
: --------

#+begin_src js -n
let webAuth = new auth0.WebAuth({
  domain: 'joel-1.auth0.com',
  clientID: '8vXPduLlATyDg69DF13J7JY4xN2vveOG',
  responseType: 'token id_token',
  audience: 'https://joel-sandbox.auth0.com/userinfo',
  scope: 'openid',
  redirectUri: window.location.href
});
#+end_src

04:52 If you use Auth0's application with a default setting, it is =OpenID
Connect-enabled=, which is outside the scope of this lesson.  We will need to
tweak the settings of this application in order to be able to use it.

05:04 Going back to Auth0 and into the settings of our application, the first
thing that we will need to change is the Callback URL.

This is the page where users are redirected after they're logged in on
Auth0.  You can go to your application, get the URL from there, and simply paste
it in the settings.

05:22 We will also need to go all the way down to the =Advanced= settings.  This
is not an OIDC conformant application, so we can uncheck this.  We can change
our JWT signature to also use =HS256=.  We're good.  Just save this, and we can
head back to our code editor.

05:42 We need to tweak our settings just a little bit here.  Our domain is the
issuer of the token.  It's what is referred to as =tenant= in Auth0's website.  The
=clientID= is found in your settings.  This should be good.

05:54 In =responseType=, we won't need the =id_token=, so we can remove
this.  The =audience= is the API that we want to connect to.  Let's change this to
=egghead-demo=.  Finally, the scope is irrelevant in this case, so we can simply
remove this.

** Reference
*** RFC 7797
- https://tools.ietf.org/html/rfc7519

**** Abstract
JSON Web Token (JWT) is a compact, URL-safe means of representing /claims/ to
be transferred between two parties.  The /claims/ in a JWT are encoded as a
JSON object that is used as the /payload/ of a JSON Web Signature (JWS)
structure or as the plaintext of a JSON Web Encryption (JWE) structure,
enabling the claims to be digitally signed or integrity protected with a
Message Authentication Code (MAC) and/or encrypted.

- claims
- payload
- JSON Web Signature structure (JWS) [[https://www.rfc-editor.org/info/rfc7515][RFC 7515]]
- JSON Web Encryption structure (JWE) [[https://tools.ietf.org/html/rfc7516][RFC 7516]]
- digital signature
- integrity protected
- Message Authentication Code (MAC)
- Base64url Encoding

The terms "JSON Web Signature (JWS)", "Base64url Encoding", "Header Parameter",
"JOSE Header", "JWS Compact Serialization", "JWS Payload", "JWS Signature", and
"Unsecured JWS" are defined by the JWS specification:
- https://tools.ietf.org/html/rfc7519#ref-JWS

*JSON Web Signature (JWS)* represents content secured with digital signatures
or Message Authentication Codes (MACs) using JSON-based data structures.
Related encryption capabilities are described in the separate JSON Web
Encryption (JWE) specification.  The JWS cryptographic mechanisms provide
integrity protection for an arbitrary sequence of octets.
- https://www.rfc-editor.org/rfc/rfc7515.txt


*JSON Web Encryption (JWE)* represents encrypted content using JSON-based data
structures.  Cryptographic algorithms and identifiers for use with this
specification are described in the separate JSON Web Algorithms (JWA)
specification and IANA registries defined by that specification.  The JWE
cryptographic mechanisms encrypt and provide integrity protection for an
arbitrary sequence of octets.
- https://tools.ietf.org/html/rfc7516

Two closely related serializations for JWEs are defined.  The JWE Compact
Serialization is a compact, URL-safe representation intended for space
constrained environments such as HTTP Authorization headers and URI query
parameters.  The JWE JSON Serialization represents JWEs as JSON objects and
enables the same content to be encrypted to multiple parties.  Both share the
same cryptographic underpinnings.
- https://tools.ietf.org/html/rfc7516

**** Introduction
JSON Web Token (JWT) is a compact /claims representation format/ intended for
space constrained environments such as HTTP Authorization headers and URI query
parameters.

JWTs encode /claims/ to be transmitted as a JSON [RFC7159] object that is used
as the payload of a JSON Web Signature (JWS) [JWS] structure or as the
plaintext of a JSON Web Encryption (JWE) [JWE] structure, enabling the /claims/
to be digitally signed or integrity protected with a Message Authentication
Code (MAC) and/or encrypted.

 The suggested pronunciation of JWT is the same as the English word "jot".

**** Definitions

- JSON Web Token (JWT) ::

     A string representing a set of claims as a JSON object that is encoded in
     a JWS or JWE, enabling the claims to be digitally signed or MACed and/or
     encrypted.

- JSON Web Signature (JWS) ::

     A data structure representing a digitally signed or MACed message.

- JOSE Header ::

                 JSON object containing the parameters describing the
                 cryptographic operations and parameters employed.  The JOSE
                 (JSON Object Signing and Encryption) Header is comprised of a
                 set of Header Parameters.

- JWS Payload ::
                 The sequence of octets to be secured -- a.k.a. the message.
                 The payload can contain an arbitrary sequence of octets.

- JWS Signature ::

                   Digital signature or MAC over the JWS Protected Header and
                   the JWS Payload.

- Base64url Encoding ::

     Base64 encoding using the URL- and filename-safe character set defined in
     Section 5 of RFC 4648 [RFC4648], with all trailing '=' characters omitted
     (as permitted by Section 3.2) and without the inclusion of any line
     breaks, whitespace, or other additional characters.

- JSON Web Encryption (JWE) ::

     A data structure representing an encrypted and integrity-protected
     message.  JWE represents encrypted content using JSON data structures and
     base64url encoding.

- JWT Claims Set ::

                    A JSON object that contains the claims conveyed by the JWT.

- Claim ::

           A piece of information asserted about a subject.  A claim is
           represented as a name/value pair consisting of a Claim Name and a
           Claim Value.

- Claim Name ::

                The name portion of a claim representation.  A Claim Name is
                always a string.

- Claim Value ::

                 The value portion of a claim representation.  A Claim Value
                 can be any JSON value.

- Nested JWT ::

                A JWT in which nested signing and/or encryption are employed.
                In Nested JWTs, a JWT is used as the payload or plaintext value
                of an enclosing JWS or JWE structure, respectively.

- Unsecured JWT ::

                   A JWT whose claims are not integrity protected or encrypted.

- Collision-Resistant Name ::

     A name in a namespace that enables names to be allocated in a manner such
     that they are highly unlikely to collide with other names.

- StringOrURI ::

                 A JSON string value, with the additional requirement that
                 while arbitrary string values MAY be used, any value
                 containing a ":" character MUST be a URI [RFC3986].
                 StringOrURI values are compared as case-sensitive strings with
                 no transformations or canonicalizations applied.

- NumericDate ::

                 A JSON numeric value representing the number of seconds from
                 1970-01-01T00:00:00Z UTC until the specified UTC date/time,
                 ignoring leap seconds.  This is equivalent to the IEEE Std
                 1003.1, 2013 Edition [POSIX.1] definition "Seconds Since the
                 Epoch", in which each day is accounted for by exactly 86400
                 seconds, other than that non-integer values can be
                 represented.  See RFC 3339 [RFC3339] for details regarding
                 date/times in general and UTC in particular.

- MAC ::

         *Message Authentication Code* ("tag") is a short piece of information
         used to /authenticate/ a message---in other words, to confirm that the
         message came from the stated sender (its authenticity) and has not
         been changed.  The MAC value protects both a message's 
  - data integrity as well as its
  - authenticity,

  by allowing verifiers (who also possess the secret key) to detect any changes
          to the message content.

          Informally, a message authentication code consists of three
          algorithms:
    - A key generation algorithm selects a key from the key space uniformly at
      random.
    - A signing algorithm efficiently returns a tag given the key and the
      message.
    - A verifying algorithm efficiently verifies the authenticity of the
      message given the key and the tag.  That is, return /accepted/ when the
      message and tag are not tampered with or forged, and otherwise return
      /rejected/.

      MACs differ from digital signatures as MAC values are both generated and
      verified using the same secret key. This implies that the sender and
      receiver of a message must agree on the same key before initiating
      communications.  In contrast, a digital signature is generated using the
      private key of a key pair, which is public-key cryptography.  Since this
      private key is only accessible to its holder, a digital signature proves
      that a document was signed by none other than that holder.

- HMAC ::

          Hash-Based Message Authentication Code is a specific type of message
          authentication code (MAC) involving a cryptographic hash function and
          a secret cryptographic key.  Any cryptographic hash function, such as
          SHA-256 or SHA-3, may be used in the calculation of an HMAC; the
          resulting MAC algorithm is termed HMAC-X, where X is the hash
          function used (e.g. HMAC-SHA256 or HMAC-SHA3).

          HMAC uses two passes of hash computation. The secret key is first
          used to derive two keys  inner and outer. The first pass of the
          algorithm produces an internal hash derived from the message and the
          inner key. The second pass produces the final HMAC code derived from
          the inner hash result and the outer key.

**** Overview
JWTs represent a set of /claims/ as a JSON object that is encoded in a JWS
and/or JWE structure.  This JSON object is the JWT Claims Set.

As per Section 4 of RFC 7159 [RFC7159], the JSON object consists of zero or
more /name/value pairs/ (or /members/), where the names are strings and the
values are arbitrary JSON values.  These members are the /claims/ represented
by the JWT.

This JSON object MAY contain whitespace and/or line breaks before or after any
JSON values or structural characters, in accordance with Section 2 of RFC 7159
[RFC7159].

The member names within the JWT Claims Set are referred to as /Claim Names/.
The corresponding values are referred to as /Claim Values/.

The contents of the *JOSE Header* describe the cryptographic operations applied
to the JWT Claims Set.

If the JOSE Header is for a *JWS*, the JWT is represented as a JWS and the claims
are digitally signed or MACed, with the JWT Claims Set being the JWS Payload.

If the JOSE Header is for a *JWE*, the JWT is represented as a JWE and the
claims are encrypted, with the JWT Claims Set being the plaintext encrypted by
the JWE.

A JWT may be enclosed in another JWE or JWS structure to create a *Nested JWT*,
enabling nested signing and encryption to be performed.

A JWT is represented as a sequence of URL-safe parts separated by period ('.')
characters.  Each part contains a /base64url-encoded value/.  The number of parts
in the JWT is dependent upon the representation of the resulting JWS using the
JWS Compact Serialization or JWE using the JWE Compact Serialization.

**** Example JWT
The following example *JOSE Header* declares that:
- the encoded object is a *JWT*, and
- the JWT is a *JWS* that is *MAC*ed using the =HMAC SHA-256= algorithm:

#+begin_src js
  {"typ":"JWT",
   "alg":"HS256"}
#+end_src

To remove potential ambiguities in the representation of the JSON object above,
the /octet sequence/ for the actual UTF-8 representation used in this example for
the JOSE Header above is also included below.  The octets representing the
UTF-8 representation of the JOSE Header in this example (using JSON array
notation) are:

: [123, 34, 116, 121, 112, 34, 58, 34, 74, 87, 84, 34, 44, 13, 10, 32,
:  34, 97, 108, 103, 34, 58, 34, 72, 83, 50, 53, 54, 34, 125]

*Base64url* encoding the octets of the UTF-8 representation of the JOSE Header
yields this *encoded JOSE Header* value:

{{{subheading(Encoded JOSE Header Value)}}}

: eyJ0eXAiOiJKV1QiLA0KICJhbGciOiJIUzI1NiJ9

The following is an example of a *JWT Claims Set*:

#+begin_src js
  {"iss":"joe",
   "exp":1300819380,
   "http://example.com/is_root":true}
#+end_src

The following octet sequence, which is the UTF-8 representation used in this
example for the JWT Claims Set above, is the JWS Payload:

#+begin_src js
  [123, 34, 105, 115, 115, 34, 58, 34, 106, 111, 101, 34, 44, 13, 10,
   32, 34, 101, 120, 112, 34, 58, 49, 51, 48, 48, 56, 49, 57, 51, 56,
   48, 44, 13, 10, 32, 34, 104, 116, 116, 112, 58, 47, 47, 101, 120, 97,
   109, 112, 108, 101, 46, 99, 111, 109, 47, 105, 115, 95, 114, 111,
   111, 116, 34, 58, 116, 114, 117, 101, 125]
#+end_src

*Base64url encoding* the *JWS Payload* yields this *encoded JWS Payload* (with
line breaks for display purposes only):

{{{subheading(Encoded JWS Payload)}}}

: eyJpc3MiOiJqb2UiLA0KICJleHAiOjEzMDA4MTkzODAsDQogImh0dHA6Ly
: 9leGFtcGxlLmNvbS9pc19yb290Ijp0cnVlfQ

Computing the *MAC*:
- of the encoded JOSE Header and
- encoded JWS Payload with the
- HMAC SHA-256 algorithm and
- base64url encoding the HMAC value
- in the manner specified in [JWS] yields
- this *encoded JWS Signature*:


{{{subheading(Encoded JWS Signature)}}}

: dBjftJeZ4CVP-mB92K27uhbUJU1p1r_wW1gFWFOEjXk

/Concatenating/ these encoded parts in this order with period ('.')  characters
between the parts yields this *complete JWT* (with line breaks for display
purposes only):

{{{subheading(Complete JWT)}}}

#+begin_src js
eyJ0eXAiOiJKV1QiLA0KICJhbGciOiJIUzI1NiJ9
.
eyJpc3MiOiJqb2UiLA0KICJleHAiOjEzMDA4MTkzODAsDQogImh0dHA6Ly9leGFt
cGxlLmNvbS9pc19yb290Ijp0cnVlfQ
.
dBjftJeZ4CVP-mB92K27uhbUJU1p1r_wW1gFWFOEjXk
#+end_src

**** Example Encrypted JWT
This example encrypts the same claims as used in the previous example to the
recipient using =RSAES-PKCS1-v1_5= and =AES_128_CBC_HMAC_SHA_256=.

The following example JOSE Header declares that:
- The Content Encryption Key is encrypted to the recipient using the
  =RSAES-PKCS1-v1_5= algorithm to produce the JWE Encrypted Key.
- Authenticated encryption is performed on the plaintext using the
  =AES_128_CBC_HMAC_SHA_256= algorithm to produce the JWE Ciphertext and the
  JWE Authentication Tag.


: {"alg":"RSA1_5","enc":"A128CBC-HS256"}

Other than using the octets of the UTF-8 representation of the JWT Claims Set
from [[https://tools.ietf.org/html/rfc7519#section-3.1][Section 3.1]] as the plaintext value, the computation of this JWT is
identical to the computation of the JWE in [[https://tools.ietf.org/html/rfc7519#appendix-A.2][Appendix A.2]] of [[[https://tools.ietf.org/html/rfc7519#ref-JWE][JWE]]], including the
keys used.

The final result in this example (with line breaks for display purposes only)
is:

#+begin_example
eyJhbGciOiJSU0ExXzUiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0.
QR1Owv2ug2WyPBnbQrRARTeEk9kDO2w8qDcjiHnSJflSdv1iNqhWXaKH4MqAkQtM
oNfABIPJaZm0HaA415sv3aeuBWnD8J-Ui7Ah6cWafs3ZwwFKDFUUsWHSK-IPKxLG
TkND09XyjORj_CHAgOPJ-Sd8ONQRnJvWn_hXV1BNMHzUjPyYwEsRhDhzjAD26ima
sOTsgruobpYGoQcXUwFDn7moXPRfDE8-NoQX7N7ZYMmpUDkR-Cx9obNGwJQ3nM52
YCitxoQVPzjbl7WBuB7AohdBoZOdZ24WlN1lVIeh8v1K4krB8xgKvRU8kgFrEn_a
1rZgN5TiysnmzTROF869lQ.
AxY8DCtDaGlsbGljb3RoZQ.
MKOle7UQrG6nSxTLX6Mqwt0orbHvAKeWnDYvpIAeZ72deHxz3roJDXQyhxx0wKaM
HDjUEOKIwrtkHthpqEanSBNYHZgmNOV7sln1Eu9g3J8.
fiK51VwhsxJ-siBMR-YFiA
#+end_example

**** Relationship of JWTs to SAML Assertions
Security Assertion Markup Language (SAML) 2.0 provides a standard for creating
security tokens with greater expressivity and more security options than
supported by JWTs.  However, the cost of this flexibility and expressiveness is
both size and complexity.  SAML's use of XML and XML Digital Signature (DSIG)
contributes to the size of SAML Assertions; its use of XML and especially XML
Canonicalization contributes to their complexity.

JWTs are intended to provide a simple security token format that is small
enough to fit into HTTP headers and query arguments in URIs.  It does this by
supporting a much simpler token model than SAML and using the JSON [RFC7159]
object encoding syntax.  It also supports securing tokens using Message
Authentication Codes (MACs) and digital signatures using a smaller (and less
flexible) format than XML DSIG.

Therefore, while JWTs can do some of the things SAML Assertions do, JWTs are
not intended as a full replacement for SAML Assertions, but rather as a token
format to be used when ease of implementation or compactness are
considerations.

SAML Assertions are always statements made by an entity about a subject.  JWTs
are often used in the same manner, with the entity making the statements being
represented by the "iss" (issuer) claim, and the subject being represented by
the "sub" (subject) claim.  However, with these claims being optional, other
uses of the JWT format are also permitted.

**** Relationship of JWTs to Simple Web Tokens (SWTs)
Both JWTs and SWTs [[[https://docs.microsoft.com/en-us/previous-versions/azure/azure-services/hh781551(v=azure.100)][SWT]]], at their core, enable sets of claims to be
communicated between applications.  For SWTs, both the claim names and claim
values are strings.  For JWTs, while claim names are strings, claim values can
be any JSON type.  Both token types offer cryptographic protection of their
content: SWTs with HMAC SHA-256 and JWTs with a choice of algorithms, including
signature, MAC, and encryption algorithms.

* MACs and HMACs
[[*%5B%5Bhttps://www.jscape.com/blog/what-is-hmac-and-how-does-it-secure-file-transfers%5D%5BWhat Is HMAC And How Does It Secure File Transfers?%5D%5D][What Is HMAC And How Does It Secure File Transfers?]]

* OAuth 2.0
- [[https://tools.ietf.org/html/rfc6749][RFC 6749]] The OAuth 2.0 Authorization Framework

  The OAuth 2.0 authorization framework enables a third-party application to
  obtain limited access to an HTTP service, either on behalf of a resource
  owner by orchestrating an approval interaction between the resource owner and
  the HTTP service, or by allowing the third-party application to obtain access
  on its own behalf.  This specification replaces and obsoletes the OAuth 1.0
  protocol described in RFC 5849.
- [[https://tools.ietf.org/html/rfc8252][RFC 8252]] OAuth 2.0 for Native Apps

  OAuth 2.0 authorization requests from native apps should only be made through
  external user-agents, primarily the user's browser.  This specification
  details the security and usability reasons why this is the case and how
  native apps and authorization servers can implement this best practice.
- https://www.oauth.com
- https://oauth.net
- https://www.okta.com
- https://www.tutorialspoint.com/oauth2.0/

** Books About OAuth 2.0
- [[https://oauth.net/books/]]

** Article---Understanding OAuth2 and Building a Basic Authorization Server of Your Own-A Beginner's Guide
:PROPERTIES:
:author:   Ratros Y.
:url:      https://medium.com/google-cloud/understanding-oauth2-and-building-a-basic-authorization-server-of-your-own-a-beginners-guide-cf7451a16f66
:date:     May 25, 2018
:END:
This Beginners Guide provides a basic overview of OAuth2 and discusses how to
build a simple OAuth2 authorization server.

For a step-by-step tutorial on deploying a basic OAuth2 authentication service
on Google Cloud Platform, see the Understanding OAuth2 and Deploying a Basic
OAuth2 Authorization Service to Cloud Functions tutorial.
- =https://medium.com/@ratrosy/understanding-oauth2-and-deploying-a-basic-oauth2-authorization-service-to-cloud-functions-812e3643f94d=

*** Background
Many authorization processes involve credentials provided by the user, most
commonly in the form of username/password combination. Early websites usually
ask for credentials via an HTML form, which the browser will send to the
server. The server authenticates the information and writes a session value in
the cookie; as long as the session is still marked active, user can access
protected features and resources. Thanks to its simplicity and effectiveness,
this process is still used by many web applications and services at the present
day.

Popular as it might be, cookie-based authorization has several drawbacks:

- Cookie-based authorization are usually stateful. The server has to keep a
  record of active sessions and check with the database every time a request
  arrives, which requires some overhead on the server-side. It is also
  difficult to decouple the authorization process from the application server.

- Cookies are usually bundled with domains. If your application interacts with
  multiple domains, additional configuration may be required.

- Cookie-based authorization does not play well with mobile clients.

- Cookie-based authorization does not accommodate well the use case where users
  of one product or service would like to grant third-party clients access to
  their information on the platform.


OAuth addresses these concerns.  As an authorization framework enabling
applications to access resources from all kinds of services, it is widely used
on the web.  Currently OAuth has two versions of protocols, OAuth 1.0 ([[https://tools.ietf.org/html/rfc5849][RFC 5849]])
and OAuth 2.0 [[https://tools.ietf.org/html/rfc6749][(RFC 6749]]).  This guide focuses on the 2.0 version.  Essentially,
OAuth 2.0 allows arbitrary clients (for example, a first-party iOS application
or a third-party web application) to access users (resource owners) resources
on resource servers via authorization servers in a secure, reliable, and
efficient manner.

OAuth 2.0 is not backwards compatible with the previous version.  Advantages and
disadvantages regarding choosing OAuth 2.0 over OAuth 1.0 remain a [[https://hueniverse.com/oauth-2-0-and-the-road-to-hell-8eec45921529][topic of
debate]].

OAuth 2.0 specification defines 4 types of authorization flows:

- Authorization Code

- Resource Owner Password Credentials

- Implicit

- Client Credentials


Implicit and Client Credentials are flows typically reserved for special types
of clients. More specifically,

| Client Type                                                         | Flow              |
|---------------------------------------------------------------------+-------------------|
| Single-page Javascript Web Applications (for example, Google Fonts) | Implicit          |
| Non-interactive programs for machine-to-machine communications      | Client Credentals |
| (for example, background services and daemons)                      |                   |
|---------------------------------------------------------------------+-------------------|

As for other clients, depending on their trustworthiness, they can use the
following flows:

| Client Type                                                             | Flow                                                      |
|-------------------------------------------------------------------------+-----------------------------------------------------------|
| Highly trusted apps (first-party apps)                                  | Authorization Code or Resource Owner Password Credentials |
| Less trusted apps (third-party apps requesting access to your platform) | Authorization Code                                        |
|-------------------------------------------------------------------------+-----------------------------------------------------------|

Loosely speaking, if you plan to build a platform where third-party
applications and services can access its resources, go with the authorization
code flow; on the other hand, you can use the resource owner password
credentials flow to build a client (a web/mobile application) for your own
service.

Tokens play an important part in OAuth 2.0. There are two types of tokens:
access tokens and refresh tokens. Anyone with a valid access token can access
protected resources; usually it is short-lived so that even if there is a
security breach and the access token is leaked, the damage can be quickly
controlled. When an access token expires, developers can use an optional
refresh token to request a new access token without having to ask the user to
enter their credentials again.

*** Authorization Flows

**** Resource Owner Password Credentials
Resource Owner Password Credentials flow has the following requirements:

- The client must be highly trusted, as it directly handles user
  credentials. In most cases, the client should be a first-party app.


The flow includes the following steps:

1. The client prompts user to enter their credentials (for instance, a
   username/password combination).

2. The client sends the credentials and its own identification to the
   authorization server. The authorization server validates the information,
   then returns an access token and optionally a refresh token.

3. The client uses the access token to access resources on the resource server.


[[file:resources/oauth2_password_credentials_flow-50.png]]

**** Authorization Code
Authorization Code flow has the following requirements:

- The client must be able to interact with an user agent (browser) in the
  environment.


The flow includes the following steps:

1. The client prepares a link to the authorization server and opens the link
   for user in an user agent (browser). The link includes information that
   allows the authorization server to identify and respond to the client.

2. User enters their credentials on the new page.

3. Credentials are sent to authorization server via the user agent (browser).

4. The authorization server validates the credentials and redirects user back
   to the client with an authorization code.

5. The client talks with the authorization server, confirms its identify and
   exchanges the authorization code for an access token and optionally a
   refresh token.

6. The client uses the access token to access resources on the resource server.


Note that due to security concerns, even though both mobile app clients and web
app clients can use the authorization code flow, their approaches to identify
themselves in the flow are different. Web app clients usually use client IDs
and client secrets, while mobile app clients need to adopt the Proof Key for
Code Exchange (PKCE) technique and utilize code challenges and code verifiers.

[[file:./resources/oauth2_authorization_code_flow-50.png]]

**** Implicit and Client Credentials
Implicit flow, as said earlier, is designed for single-page Javascript
apps. This flow is vastly similar to the Authorization Code flow, except for
the part involving authorization code. Due to security concerns, in this flow
the client no longer receives an authorization code from the authorization
server; instead, after the user agent successfully transfers credentials, the
authorization server returns access tokens directly to the client. Refresh
tokens are not allowed in the Implicit flow.

[[file:./resources/oauth2_implicit_flow-50.png]]

Client Credentials flow, on the other hand, is closer to the Resource Owner
Password Credentials flow. Clients in this flow use client IDs and secrets to
identify themselves, and exchange them for access tokens with the authorization
server. You should not use refresh tokens in this flow either.

[[file:./resources/oauth2_client_credentials_flow-50.png]]

*** JWT (JSON Web Tokens)
You may have realized that even though tokens are frequently referenced in
OAuth 2.0, so far few has been said about their generation and usage. The truth
is, OAuth 2.0 framework does not specify what format access tokens and refresh
tokens should take and it is up to developers themselves to integrate tokens in
the their choice of authorization flows. Theoretically speaking, you may very
well use a predefined string that never expires as the access token, even
though it is obviously not very secure; in reality, however, many developers
choose to use the JWT ([[https://tools.ietf.org/html/rfc7519][JSON Web Token]]) format. JWT is self-contained, allowing
servers to validate tokens without having to inquire a data source.

A JWT includes three parts:

- A header describing the type of the token and the hashing algorithm it uses

- A payload containing the data

- A signature for verifying the token


All the three parts should be Base64URL encoded so that they can be safely
transferred in a query string.

You can use many hashing algorithms with JWT and the payload has a variety of
pre-defined fields (also known as [[https://tools.ietf.org/html/rfc7519#section-4.1][registered claim names]]).  This Beginners
Guide uses the =RS256=(RSA Signature with SHA-256) algorithm and specifies two
registered claims in the payload: =exp=(when does the token expire), and
=iss=(who issues the token). Aside from the supported claims, you can also
define your own claims in the payload, such as the scopes of the token.

Every time a JWT arrives at a server, the system first parses the JWT, and
verifies if the algorithm specified in the header is supported; then it checks
the signature to make sure that the JWT is valid, and at last, confirms that
registered claims (if exist) are valid. In the case of this guide, it means
making sure that the JWT hasnt expired (=exp=), and comes from an expected
origin (=iss=). Custom claims, such as scopes, can be extracted from the token
and manually validated.

**** Expiration Date and Refresh Token
Additionally, developers have control over the lifespan of access tokens and
the usage of refresh tokens. Generally speaking, if you are building an
authorization server protecting critical resources, it might be better to stay
away from refresh tokens and keep access tokens short-lived. For less critical
resources though, it is OK to enable refresh tokens and let the access tokens
live a little bit longer. Resist the temptation to create evergreen tokens
though; long-lived access tokens do make development easier, however there is
always a trade-off between security and convenience.

*** Whats Next
This Beginners Guide includes examples for explaining how each of the
authorizations flows work in detail:

- Resource Owner Password Credentials
  : https://medium.com/@ratrosy/building-a-basic-authorization-server-using-resource-owner-password-credentials-flow-a666d06900fb

- Authorization Code flow
  : https://medium.com/@ratrosy/building-a-basic-authorization-server-using-authorization-code-flow-c06866859fb1

- Authorization Code flow (PKCE)
  : https://medium.com/@ratrosy/building-a-basic-authorization-server-using-authorization-code-flow-pkce-3155e843466

- Implicit flow
  : https://medium.com/@ratrosy/building-a-basic-authorization-server-with-implicit-flow-3f474eb2a306

- Client Credentials flow
  : https://medium.com/@ratrosy/building-a-basic-authorization-server-using-client-credentials-flow-db353d6debdf


These documents are largely independent of each other. If you have decided
which authorization flow to use, feel free to start with the example of your
choice. For a general understanding of OAuth 2.0 in action, it is recommended
to begin with Authorization Code flow.

Additionally, the
- Understanding OAuth2 and Building a Basic OAuth2 Authorization Server with
  Cloud Functions
  : https://medium.com/@ratrosy/understanding-oauth2-and-deploying-a-basic-oauth2-authorization-service-to-cloud-functions-812e3643f94d

  tutorial showcases how to use a Serverless solution

- [[https://cloud.google.com/functions/][Google Cloud Functions]]

  to deploy a custom OAuth 2.0 authorization service to the cloud.

** Article---Building a Basic Authorization Server using Authorization Code Flow
:PROPERTIES:
:url:      https://medium.com/@ratrosy/building-a-basic-authorization-server-using-authorization-code-flow-c06866859fb1
:author:   Ratros Y.
:date:     May 25, 2018
:END:
This document is part of the Understanding OAuth2 and Building a Basic
Authorization Server of Your Own guide. It discusses in detail how
Authorization Code flow works.

*** Before you begin
The sample code in this document uses Python 3 and the [[http://flask.pocoo.org/][flask]] framework. It is
for demonstration purposes only. The code is designed to demonstrate the
authorization process in an easy-to-understand manner; it does not necessarily
represent the best practices in development.

**** Setting up your environment
1. Install the latest version of Python 3. See [[https://cloud.google.com/python/setup][Setting Up a Python Development
   Environment]] for instructions.

2. Install the following Python packages:
   - flask,
   - pyopenssl
   - cryptography
   - pyjwt

   : pip install --upgrade flask pyopenssl cryptography pyjwt

3. Generate a private/public key pair (~private.pem~ and ~public.pem~):

   - Install the latest version of ~openssl~:

     | OS                    | Instructions                                           |
     |-----------------------+--------------------------------------------------------|
     | Linux (Debian/Ubuntu) | =sudo apt-get install openssl=                         |
     | macOS                 | (with Homebrew package manager) =brew install openssl= |
     | Windows               | See [[https://wiki.openssl.org/index.php/Binaries][here]] for instructions.                             |
     |-----------------------+--------------------------------------------------------|

   - Prepare the private key: =openssl genrsa -out private.pem 2048=. Do not
     specify a passphrase.

   - Prepare the public key: =openssl rsa -in private.pem -pubout -outform PEM
     -out public.pem=

**** Downloading the code
Download the source code [[https://github.com/michaelawyu/auth-server-sample][here]].

The sample includes the following files:

| Path                                         | Notes                                                                                              |
|----------------------------------------------+----------------------------------------------------------------------------------------------------|
| =client/AC_client.py=                        | A client web application using the Authorization Code flow to access a list of users.              |
| =client/public.pem=                          | A public key for verifying access tokens. You should replace this key file with one of your own.   |
| =client/templates/AC_login.html=             | An HTML template for preparing the login page.                                                     |
| =client/templates/users.html=                | An HTML template for preparing the results of user queries.                                        |
| =auth_server/AC_auth_server.py=              | An authorization server responsible for issuing access tokens in the Authorization Code flow.      |
| =auth_server/private.pem=                    | A private key for generating access tokens. You should replace this key file with one of your own. |
| =auth_server/auth.py=                        | Includes method(s) for generating access tokens and more.                                          |
| =auth_server/templates/AC_grant_access.html= | An HTML template for preparing the access request page.                                            |
| =API_server/API_server.py=                   | A simple API server offering access to a list of users.                                            |
| =API_server/public.pem=                      | A public key for verifying access tokens. You should replace this key file with one of your own.   |
| =API_server/auth.py=                         | Includes method(s) for verifying access tokens and more.                                           |
|----------------------------------------------+----------------------------------------------------------------------------------------------------|

**** Running the code
Run the code separately as follows:

#+begin_example
python AC_client.py
python AC_auth_server.py
python API_server.py
#+end_example

Visit the client at http://127.0.0.1:5000. The authorization server listens at
=127.0.0.1:5001= and the API server is available at =127.0.0.1:5002=.

*** How the Authorization Code flow works

**** Redirecting users to the sign-in page provided by the authorization server
The flows starts with users visiting the path =/login=. The following code in
=client/AC_client.py= presents a simple page at =/login= showing a button
prompting users to sign in with the authorization server:

#+begin_src python
@app.route('/login')
def login():
  # Presents the login page
  return render_template('AC_login.html', 
                         dest = AUTH_PATH,
                         client_id = CLIENT_ID,
                         redirect_url = REDIRECT_URL)
#+end_src

Parameters =dest=, =response_type=, =client_id= and =redirect_url= are passed
to build the full redirect URL. When the page is ready, pressing the buttons
will redirect users to:
: http://localhost:5001/auth?response_type=code&client_id=sample-client-id&redirect_url=http://localhost:5000/callback

The value of =response_type=, =code=, indicates the initialization of the
authorization code flow. Since the authorization server in this sample only
supports one flow, the value is not used; however, if you plan to build an
authorization server supporting multiple flows, use this value to determine
which flow to initiate. Additionally, =client_id= uniquely identifies the
client, and =redirect_url= is where the authorization code is sent.

The =auth= method of the authorization server accepts these parameters, and
renders a page describing what the client is requesting access to:

#+begin_src python
@app.route('/auth')
def auth():
  # Describe the access request of the client and ask user for approval
  client_id = request.args.get('client_id')
  redirect_url = request.args.get('redirect_url')

  if None in [ client_id, redirect_url ]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not verify_client_info(client_id, redirect_url):
    return json.dumps({
      "error": "invalid_client"
    })

  return render_template('AC_grant_access.html',
                         client_id = client_id,
                         redirect_url = redirect_url)
#+end_src

If users are OK with the requirements, they can sign in with their
credentials. Sensitive information, such as the user credentials, is handled
solely by the authorization server, thus protects the users (resource
owners). Note that in this step the authorization server also verifies if the
request from the client (redirect URL) matches its claims during the
registration.

**** Returning an authorization code
The authorization server processes the credentials user provided with the
signin method; if the credentials are all correct, this method generates an
authorization code and redirects user back to the client with the code
attached:

#+begin_src python
@app.route('/signin', methods = ['POST'])
def signin():
  # Issues authorization code
  username = request.form.get('username')
  password = request.form.get('password')
  client_id = request.form.get('client_id')
  redirect_url = request.form.get('redirect_url')

  if None in [ username, password, client_id, redirect_url ]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not verify_client_info(client_id, redirect_url):
    return json.dumps({
      "error": "invalid_client"
    })

  if not authenticate_user_credentials(username, password):
    return json.dumps({
      'error': 'access_denied'
    }), 401

  authorization_code = generate_authorization_code(client_id, redirect_url)

  url = process_redirect_url(redirect_url, authorization_code)

  return redirect(url, code = 303)
#+end_src

Authorization code is generated with the =generate_authorization_code= method:

#+begin_src python
def generate_authorization_code(client_id, redirect_url):
  #f = Fernet(KEY)
  authorization_code = f.encrypt(json.dumps({
    "client_id": client_id,
    "redirect_url": redirect_url,
  }).encode())

  authorization_code = base64.b64encode(authorization_code, b'-_').decode().replace('=', '')

  expiration_date = time.time() + CODE_LIFE_SPAN

  authorization_codes[authorization_code] = {
    "client_id": client_id,
    "redirect_url": redirect_url,
    "exp": expiration_date
  }

  return authorization_code
#+end_src

For authorization codes, this sample encrypts a JSON string containing the
fields =client_id=, and =redirect_url= with Fernet, a symmetric encryption
method. It is also OK to produce authorization codes of other formats, as long
as it fits the following criteria:

- Expires after a period of time (10 minutes, for instance)
- Bounds to =client_id= and =redirect_url=


Additionally, one authorization code can only be used once, which implies that
you need to keep a record of authorization codes issued. The code snippet above
stores them, along with their respective expiration dates, in memory with a
dictionary, to keep the sample as simple as possible; in your implementation,
however, you should switch to other data storage solutions, such as [[https://memcached.org/][memcached]]
or [[https://redis.io/][Redis]].

After the authorization code is generated, users are redirected back to the
client with the code embedded in the request.

**** Exchanging the authorization code for an access token
The client receives the authorization code at the callback/ path. The code is
then sent back to the authorization server, along with =client_id=,
=client_secret= and =redirect_url=, in exchange for the access token:

#+begin_src python
@app.route('/callback')
def callback():
  # Accepts the authorization code and exchanges it for access token
  authorization_code = request.args.get('authorization_code')

  if not authorization_code:
    return json.dumps({
      'error': 'No authorization code is received.'
    }), 500

  r = requests.post(TOKEN_PATH, data = {
    "grant_type": "authorization_code",
    "authorization_code": authorization_code,
    "client_id" : CLIENT_ID,
    "client_secret" : CLIENT_SECRET,
    "redirect_url": REDIRECT_URL
  })

  if r.status_code != 200:
    return json.dumps({
      'error': 'The authorization server returns an error: \n{}'.format(
        r.text)
    }), 500

  access_token = json.loads(r.text).get('access_token')

  response = make_response(redirect(url_for('main')))
  response.set_cookie('access_token', access_token)
  return response
#+end_src

For simplicity reasons, at the end of the method the access token is written to
the cookie when it is returned by the authorization server. In real world,
however, most developers prefer storing access token in [[https://developer.mozilla.org/en-US/docs/Web/API/Web_Storage_API][HTML Web Storage]] (for
web applications) or local storage (for mobile applications) instead. It is
worth pointing out that saving access tokens to cookies does not make OAuth 2.0
flows a variant of cookie-based authorization: tokens, though reside in
cookies, are never transferred via cookies; furthermore, components in the flow
can still verify the token independently without having to consult a data
source.

**** Validating the credentials and return an access token
The =exchange_for_token= method of the authorization server
(=auth_server/AC_auth_server.py=) listens for incoming authorization codes,
validates them and replies with an access token:

#+begin_src python
@app.route('/token', methods = ['POST'])
def exchange_for_token():
  # Issues access token
  authorization_code = request.form.get('authorization_code')
  client_id = request.form.get('client_id')
  client_secret = request.form.get('client_secret')
  redirect_url = request.form.get('redirect_url')

  if None in [ authorization_code, client_id, client_secret, redirect_url ]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not authenticate_client(client_id, client_secret):
    return json.dumps({
      "error": "invalid_client"
    }), 400

  if not verify_authorization_code(authorization_code, client_id, redirect_url):
    return json.dumps({
      "error": "access_denied"
    }), 400

  access_token = generate_access_token()

  return json.dumps({
    "access_token": access_token.decode(),
    "token_type": "JWT",
    "expires_in": JWT_LIFE_SPAN
  })
#+end_src

=authenticate_client= method, as its name implies, checks if =client_id= and
=client_secret= match. =verify_authorization_code= method, on the other hand,
confirms that the authorization code is valid. The former method is dummy in
the sample; it always returns True. You should replace them with verification
logic of your own. The latter method, however, is defined in
=auth_server/auth.py=:

#+begin_src python
def verify_authorization_code(authorization_code, client_id, redirect_url):
  #f = Fernet(KEY)
  record = authorization_codes.get(authorization_code)
  if not record:
    return False

  client_id_in_record = record.get('client_id')
  redirect_url_in_record = record.get('redirect_url')
  exp = record.get('exp')

  if client_id != client_id_in_record or \
     redirect_url != redirect_url_in_record:
    return False

  if exp < time.time():
    return False

  del authorization_codes[authorization_code]

  return True
#+end_src

Additionally, =generate_access_token= method is defined as follows:

#+begin_src python
def generate_access_token():
  payload = {
    "iss": ISSUER,
    "exp": time.time() + LIFE_SPAN,
  }

  access_token = jwt.encode(payload, private_key, algorithm = 'RS256')

  return access_token.decode()
#+end_src

This sample uses ~pyjwt~ package to generate JWTs. =iss= is the issuer of this
access token (=sample-auth-server=). =exp= is the expiration date of the access
token, which is set to 1800 seconds (=JWT_LIFE_SPAN=) . Every access token in this
sample is encrypted by a private key and can be decrypted by the corresponding
public key; in other words, every one can check the validity of your access
tokens, yet no one else can issue access tokens on your behalf, as long as the
private key is kept private.

**** Using the access token to access resources
After the access token is received and written to the cookie, the client can
use it to access the API server:

#+begin_src python
@app.route('/')
def main():
  # Retrieves a list of users
  access_token = request.cookies.get('access_token')

  r = requests.get(RES_PATH, headers = {
    'Authorization': 'Bearer {}'.format(access_token)
  })

  if r.status_code != 200:
    return json.dumps({
      'error': 'The resource server returns an error: \n{}'.format(
        r.text)
    }), 500

  users = json.loads(r.text).get('results')

  return render_template('users.html', users = users)
#+end_src

As said earlier, instead of being embedded in the cookie, the access token is
transferred as a part of the Authorization header of the HTTP request.

The =get_user= method from =API_server/API_server.py= extracts the access token
from the header and verifies it with the =verify_access_token= method:

#+begin_src python
def verify_access_token(access_token):
  try:
    decoded_token = jwt.decode(access_token.encode(), public_key,
                               issuer = ISSUER,
                               algorithm = 'RS256')
  except (jwt.exceptions.InvalidTokenError,
          jwt.exceptions.InvalidSignatureError,
          jwt.exceptions.InvalidIssuerError,
          jwt.exceptions.ExpiredSignatureError):
    return False

  return True
#+end_src

We use the ~pyjwt~ package to verify JWTs as well. It checks the signature of
the JWT and makes sure that values of the =iss= and =exp= fields are
valid. Custom fields (if any) are included in the decoded token and can be
manually verified.

*** Important notes
- For simplicity reasons, this sample uses HTTP connection. In your
  implementation though, you should always use HTTPS. The commented out code in
  the sample,

  #+begin_example
  #context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
  #context.load_cert_chain(domain.crt, domain.key)
  #app.run(port = 5000, debug = True, ssl_context = context)
  #+end_example

  allows applications to serve contents via HTTPS with a private key and a
  self-signed certificate when running locally. It is likely that your browser
  will issue a warning using this approach though, as, obviously, self-signed
  certificates cannot be trusted.

- OAuth2 requires that clients register with the authorization server before
  using the authorization flow. Registration process itself is not considered a
  part of the OAuth 2.0 flow and is up to developers to design and implement
  it. This sample makes the following assumptions:

  1. The client has registered with the authorization server.

  2. The client has received its client ID and client secret provided by the
     authorization server.

- Access tokens in this sample only contains information regarding its issuer
  and expiration date. Depending on your use case, it might be necessary to
  pose more restrictions. Common fields to implement in the access token
  include audience (destinations where access token can reach) and scopes
  (level of access that the token grants).

- When an error occurred, as you can see from the code, OAuth2 regulated that
  authorization server should respond with =HTTP 400 Bad Request= (unless
  specified otherwise) with the following parameters: =error=,
  =error_description= (optional) and =error_uri= (optional). See the
  specification for more information regarding error messages.

- This sample uses client ID and client secret to verify clients and transfers
  them in the body of HTTP requests. OAuth2 specification does not have a set
  method for client verifications though, you may switch to a different
  approach in your authorization flow.

** Article---Understanding OAuth2 and Deploying a Basic OAuth2 Authorization Service to Cloud Functions
This tutorial explains the basics of OAuth 2.0 and how to deploy an OAuth2
authorization service in Node.js to [[https://cloud.google.com/functions/][Google Cloud Functions]].

Google Cloud Functions is an event-driven serverless compute platform. It
offers one of the simplest ways to run code in the cloud and provides
developers with automatic scaling, high availability and fault tolerance. As a
part of the computing solutions on Google Cloud Platform, your Cloud Functions
can easily integrate with other Google Cloud services.

*** Objectives
- Understand the basics of OAuth 2 and the architecture of the project

- Deploy the code to Cloud Functions

*** Costs
This tutorial uses billable components of Google Cloud Platform, including
- Google Cloud Functions

- Google Cloud Datastore


Use the [[https://cloud.google.com/products/calculator/][Pricing Calculator]] to generate a cost estimate based on your projected
usage. Depending on the actual usage, you might be eligible for [[https://cloud.google.com/free/][Google Cloud
Free Tier]].

*** Before You Begin
1. Select a project from [[https://console.cloud.google.com/][Google Cloud Console]]. If you have never used Google
   Cloud Platform before, sign up or log in with your existing Google account,
   then follow the on-screen instructions to start using Google Cloud Platform.

2. [[https://cloud.google.com/billing/docs/how-to/modify-project#enable_billing_for_a_project][Enable billing]] for your account.

3. [[https://console.cloud.google.com/flows/enableapi?apiid=cloudfunctions&redirect=https://cloud.google.com/functions/quickstart][Enable the Cloud Functions API.]]

4. [[https://cloud.google.com/sdk/][Install the Google Cloud SDK]].

5. Windows Developers Only: Install cURL.

6. Create the following entities in Cloud Datastore:

   - Go to [[https://console.cloud.google.com/datastore][Cloud Datastore Entities Page]] in Google Cloud Console.

   - Click =Create Entity=. Cloud Datastore may ask you to pick a location to
     store your data; select one of the locations and click =Next=.

   - Type =user= for Kind.

   - Click =Add Property=.

   - Add a property =username= of the =String= type with the value
     =sample-user=. Click =Done=.

   - Add a property =password= of the =String= type with the value
     =sample-password=. Click =Done=.

   - Click =Create=.

   - Repeat the steps above and create 5 =client= kind entities, with the
     following properties:

*** Concepts

**** OAuth 2.0
OAuth 2.0 ([[https://tools.ietf.org/html/rfc6479][RFC 6479]]) is a widely used authorization framework enabling
applications to access resources in all kinds of services. More specifically,
OAuth 2.0 allows arbitrary clients (for example, a highly trusted first-party
mobile app or a less trusted third-party web app) to access users (resource
owners) resources on resource servers via authorization servers in a secure,
reliable, and efficient manner.

**** Authorization Flows
OAuth 2.0 specification defines 4 types of authorization flows:

- Authorization Code

- Resource Owner Password Credentials

- Implicit

- Client Credentials


Implicit and Client Credentials are flows typically reserved for special types
of clients:

| Client Type                                                         | Flow        |
|---------------------------------------------------------------------+-------------|
| Single-page Javascript Web Applications (for example, Google Fonts) | Implicit    |
| Non-interactive programs for machine-to-machine communications      | Client      |
| (for example, background services and daemons)                      | Credentials |
|---------------------------------------------------------------------+-------------|

As for other clients, depending on their trustworthiness, they can use the
following flows:

| Client Type                                           | Flow                                |
|-------------------------------------------------------+-------------------------------------|
| Highly trusted apps (first-party apps)                | Authorization Code or               |
|                                                       | Resource Owner Password Credentials |
| Less trusted apps                                     | Authorization Code                  |
| (third-party apps requesting access to your platform) |                                     |
|-------------------------------------------------------+-------------------------------------|

This tutorial deploys a basic authorization server supporting all of the four
flows; you can, however, tailor the code and drop the support for some of them
based on your use case.

***** Authorization Code

[[file:./resources/oauth2_authorization_code_flow-50.png]]

The Authorization Code flow includes the following steps:

1. The client prepares a link to the authorization server and opens the link
   for user in a user agent (browser). The link includes information that
   allows the authorization server to identify and respond to the client.

2. User enters their credentials on the new page.

3. Credentials are sent to authorization server via the user agent (browser).

4. The authorization server validates the credentials and redirects user back
   to the client with an authorization code.

5. The client talks with the authorization server, confirms its identify and
   exchanges the authorization code for an access token and optionally a
   refresh token.

6. The client uses the access token to access resources on the resource server.


Note that due to security concerns, even though both mobile app clients and web
app clients can use the authorization code flow, their approaches to identify
themselves in the flow are different. Web app clients use client IDs and client
secrets, while mobile app clients need to adopt the [[https://tools.ietf.org/html/rfc7636][Proof Key for Code Exchange
(PKCE)]] technique and utilize code challenges and code verifiers.

PKCE specification requires client generate a code verifier first, then prepare
a code challenge based on the code verifier. Usually, code verifier is a
cryptographically strong random long string (43128 characters) and code
challenge should be its SHA-256 hash. Both should be Base64URL encoded. Client
first sends code challenge to the authorization server; after the authorization
code is issued, client uses code verifier together with authorization code to
request access token from authorization server. The authorization server then
verifies the code challenge using the code verifier and decides if an access
token can be granted.

Authorization Code flow requires that clients be able to interact with a user
agent (browser) in the environment.

***** Resource Owner Password Credentials

[[file:./resources/oauth2_password_credentials_flow-50.png]]

The Resource Owner Password Credentials flow includes the following steps:

1. The client prompts user to enter their credentials (for instance, a
   username/password combination).

2. The client sends the credentials and its own identification to the
   authorization server. The authorization server validates the information,
   then returns an access token and optionally a refresh token.

3. The client uses the access token to access resources on the resource server.


Resource Owner Password Credentials flow requires that clients be highly
trustworthy. In most cases, the client should be a first-party app.

***** Implicit
Implicit flow, as said earlier, is designed for single-page Javascript
apps. This flow is vastly similar to the Authorization Code flow, except for
the part involving authorization code. Due to security concerns, in this flow
the client no longer receives an authorization code from the authorization
server; instead, after the user agent successfully transfers credentials, the
authorization server returns access tokens directly to the client. Refresh
tokens are not allowed in the Implicit flow.

[[file:./resources/oauth2_implicit_flow-50.png]]

***** Client Credentials
Client Credentials flow, on the other hand, is closer to the Resource Owner
Password Credentials flow. Clients in this flow use client IDs and secrets to
identify themselves, and exchange them for access tokens with the authorization
server. You should not use refresh tokens in this flow either.

[[file:./resources/oauth2_client_credentials_flow-50.png]]

**** JWT
Tokens play an important part in OAuth 2.0. There are two types of tokens:
access tokens and refresh tokens. Anyone with a valid access token can access
protected resources; usually it is short-lived so that even if there is a
security breach and the access token is leaked, the damage can be quickly
controlled. When an access token expires, developers can use an optional
refresh token to request a new access token without having to ask the user to
enter their credentials again.

It is up to developers themselves to choose the format of token for their OAuth
2.0 authorization service. This tutorial uses [[https://tools.ietf.org/html/rfc7519][JWT (JSON Web Token)]], a
self-contained format allowing servers to validate tokens without having to
inquire a data source.

A JWT includes three parts:

- A header describing the type of the token and the hashing algorithm it uses

- A payload containing the data

- A signature for verifying the token


You can use many hashing algorithms with JWT and the payload offers a variety
of pre-defined fields (also known as [[https://tools.ietf.org/html/rfc7519#section-4.1][registered claim names]]). This Beginners
Guide uses the [[https://en.wikipedia.org/wiki/RSA_%2528cryptosystem%2529][RS256]] (RSA Signature with SHA-256) algorithm and specifies two
registered claims in the payload: =exp= (when does the token expire), and =iss=
(who issues the token). Aside from the supported claims, you can also define
your own claims in the payload, such as the scope of the token.

Every time a JWT arrives at a server, the system first parses the JWT, and
verifies if the algorithm specified in the header is supported; then it checks
the signature to make sure that the JWT is valid, and at last, confirms that
registered claims (if exist) are valid. In the case of this guide, it means
making sure that the JWT hasnt expired (=exp=), and comes from an expected
origin (=iss=). Custom claims, such as scopes, can be extracted from the token
and manually validated.

**** Client Registration
OAuth 2.0 requires that clients register with the authorization server
beforehand. The registration process is not considered as a part of the
authorization flow and developers can implement it as they see
fit. Additionally, your OAuth 2.0 authorization service must be able to verify
the identity of clients. This tutorial uses client IDs and client secrets for
client authentication.

*** Understanding the Architecture

[[file:./resources/oauth2_architecture-50.png]]

This tutorial deploys 3 Cloud Functions. The token function is responsible for
issuing access tokens while the auth function and the signin function work
together to grant authorization codes. More specifically,

- Clients in the Resource Owner Password Credentials flow exchange user
  credentials for access token with the token function

- Clients in the Authorization Code flow first request an authorization code
  from function auth and signin, then exchange it for access token with the
  token function

- Clients in the Implicit flow directly request access token from function auth
  and signin

- Clients in the Client Credentials flow exchange client credentials for access
  token with the token function

*** Downloading the Code
Download the code [[https://github.com/michaelawyu/auth-server-sample/tree/master/GCF/code][here]].

The sample includes the following files:

| File         | Notes                                                                                              |
|--------------+----------------------------------------------------------------------------------------------------|
| auth.pug     | A [[https://github.com/pugjs/pug][pug]] HTML template for preparing the access request page.                                         |
| function.js  | Functions to deploy.                                                                               |
| package.json | [[https://docs.npmjs.com/files/package.json][Project metadata]].                                                                                  |
| private.pem  | A private key for generating access tokens. You should replace this key file with one of your own. |
| public.pem   | A public key for verifying access tokens. You should replace this key file with one of your own.   |
|--------------+----------------------------------------------------------------------------------------------------|

**** Deploying the Code
Deploy the functions using the following commands. It may take a few minutes to
finish.

#+begin_example
gcloud beta functions deploy token - trigger-http
gcloud beta functions deploy auth - trigger-http
gcloud beta functions deploy signin - trigger-http
#+end_example

Your functions are available at

#+begin_example
https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/token
https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/auth
https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/signin
#+end_example

Replace =[GCP_REGION]= and =[PROJECT_ID]= with values of your own. Your
function addresses are also available in the output of the =gcloud beta
functions deploy= command.

You can always view the details of deployed functions via [[https://console.cloud.google.com/functions][Cloud Console]].

*** Testing the Code

**** Authorization Code
1. Open your browser and visit
   #+begin_example
   https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/auth?
   response_type=code&
   client_id=sample-ac-client&
   redirect_url=https://www.google.com
   #+end_example

   Replace =[GCP_REGION]= and =[PROJECT_ID]= with values of your own. Note that
   parameters =response_type=, =client_id=, and =redirect_url= are added to the
   address.

2. Sign in with =sample-username= and =sample-password=. You will be redirected to
   =google.com=. The address should look like:
   : https://www.google.com/?authorization_code=[YOUR_AUTHORIZATION_CODE]

   Write down the returned authorization code.

3. Run command

   #+begin_example
   curl -d grant_type=authorization_code&
   client_id=sample-ac-client&
   client_secret=sample-client-secret&
   authorization_code=[AUTHORIZATION_CODE]&
   redirect_url=https://www.google.com"
   -X POST https://us-central1-testbed-195403.cloudfunctions.net/token'
   #+end_example

   Replace =[AUTHORIZATION_CODE]= with the value of your own. Note that this
   request includes parameters =grant_type=, =client_id=, =client_secret=,
   =authorization_code= and =redirect_url=.

   The output should look like:

   #+begin_example
   {"access_token":"[YOUR_ACCESS_TOKEN]",
    "token_type:"JWT","expires_in":1800000}
   #+end_example

   The =access_token= attribute in the returned JSON file is the issued access
   token.

**** Authorization Code (PKCE)
1. Generate a code verifier and its code challenge. Open the node interactive
   shell (node) and run the following code:

   #+begin_src js
   // You might need to install package crypto with npm i -g crypto first
   const crypto = require('crypto');
   var code_verifier = crypto.randomBytes(64)
                         .toString('base64')
                         .replace(/\+/g, '-')
                         .replace(/\//g, '_')
                         .replace(/=/g, '');
   var code_challenge = crypto.createHash('sha256')
                         .update(code_verifier)
                         .digest()
                         .toString('base64')
                         .replace(/\+/g, '-')
                         .replace(/\//g, '_')
                         .replace(/=/g, '');
   #+end_src

   Write down the values of =code_verifier= and =code_challenge=.

2. Open your browser and visit:

   #+begin_example
   https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/auth?
   response_type=code&
   client_id=sample-acpkce-client&
   redirect_url=https://www.google.com&code_challenge=[CODE_CHALLENGE]&code_challenge_method=S256
   #+end_example

   Replace =[GCP_REGION]=, =[PROJECT_ID]= and =[CODE_CHALLENGE]= with values of your
   own. Note that parameters =response_type=, =client_id=, =redirect_url=, =code_challenge=
   and =code_verifier= are added to the address.

3. Sign in with =sample-username= and =sample-password=. You will be redirected to
   =google.com=. The address should look like:

   : https://www.google.com/?authorization_code=[YOUR_AUTHORIZATION_CODE]

   Write down the returned authorization code.

4. Run command:

   #+begin_example
   curl -d "grant_type=authorization_code&
   client_id=sample-acpkce-clientauthorization_code=[AUTHORIZATION_CODE]&
   code_verfier=[CODE_VERIFIER]&
   redirect_url=https://www.google.com"
   -X POST 'https://us-central1-testbed-195403.cloudfunctions.net/token'
   #+end_example

   Replace =[AUTHORIZATION_CODE]= and =[CODE_VERIFIER]= with values of your
   own. Note that this request includes parameters =grant_type=, =client_id=,
   =code_verifier=, =authorization_code= and =redirect_url=.

   The output should like:

   #+begin_src js
   {"access_token":"[YOUR_ACCESS_TOKEN]",
    "token_type":"JWT","expires_in":1800000}
   #+end_src

   The =access_token= attribute in the returned JSON file is the issued access
   token.

**** Implicit
1. Open your browser and visit:

   #+begin_example
   https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/auth?
   response_type=token&
   client_id=sample-implicit-client&
   redirect_url=https://www.google.com
   #+end_example

   Replace =[GCP_REGION]= and =[PROJECT_ID]= with values of your own. Note that
   parameters =response_type=, =client_id=, and =redirect_url= are added to the
   address.

2. Sign in with =sample-username= and =sample-password=. You will be redirected to
   =google.com=. The address should look like:
   : https://www.google.com/?access_token=[YOUR_ACCESS_TOKEN]&token_type=JWT&expires_in=1800000

   The value of =access_token= is the issued access token.

**** Resource Owner Password Credentials
1. Run command

   #+begin_example
   curl -d grant_type=password&
   client_id=sample-ropc-client&
   username=sample-username&
   password=sample-password&
   client_secret=sample-client-secret
   -X POST https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/token'
   #+end_example

   Replace =[GCP_REGION]= and =[PROJECT_ID]= with values of your own. Note that
   this request includes parameters =grant_type=, =client_id=, =client_secret=,
   username, and password.

   The output should like:

   #+begin_src js
   {"access_token":"[YOUR_ACCESS_TOKEN]",
    "token_type":"JWT","expires_in":1800000}
   #+end_src

   The =access_token= attribute in the returned JSON file is the issued access
   token.

**** Client Credentials
1. Run command

   #+begin_example
   curl -d "grant_type=client_credentials&
   client_id=sample-cc-client&
   client_secret=sample-client-secret"
   -X POST 'https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/token'
   #+end_example

   The output should like:

   #+begin_src js
   {"access_token":"[YOUR_ACCESS_TOKEN]",
    "token_type":"JWT","expires_in":1800000}
   #+end_src

   The =access_token= attribute in the returned JSON file is the issued access
   token.

*** Understanding the Code

**** =auth= Function
The =auth= function is responsible for presenting a page where users can
authorize clients to access their information:

#+begin_src js
exports.auth = (req, res) => {
  console.log(req.query)
  switch (req.query.response_type) {
    case ('code'):
      if (req.query.code_challenge && req.query.code_challenge_method) {
        handleACPKCEAuthRequest(req, res);
      } else if (!req.query.code_challenge &&
                 !req.query.code_challenge_method) {
        handleACAuthRequest(req, res);
      } else {
        res.status(400).send(JSON.stringify({
          'error': 'invalid_request',
          'error_description': 'Required parameters are missing in the request.'
        }))
      }
      break;

    case ('token'):
      handleImplicitAuthRequest(req, res);
      break;

    default:
      res.status(400).send(JSON.stringify({
        'error': 'invalid_request',
        'error_description': 'Grant type is invalid or missing.'
      }));
      break;
  }
}
#+end_src

Requests with =response_type= set to code and have parameter =code_challenge= and
=code_challenge_method= present initiate the Authorization Code (PKCE) flow and are
processed by function =handleACPKCEAuthRequest=:

#+begin_src js
function handleACPKCEAuthRequest (req, res) {
  if (req.query.client_id      === undefined ||
      req.query.redirect_url   === undefined ||
      req.query.code_challenge === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('redirect-url', '=', req.body.redirect_url)
    .filter('acpkce-enabled', '=', true)

  datastore
    .runQuery(clientQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client/redirect URL.')
      }
    })
    .then(() => {
      const html = pug.renderFile(path.join(__dirname, 'auth.pug'), {
        response_type: 'code',
        client_id: req.query.client_id,
        redirect_url: req.query.redirect_url,
        code_challenge: req.query.code_challenge
      });
      res.status(200).send(html);
    })
    .catch(msg => {
      if (msg === 'Invalid client/redirect URL.') {
        res.status(400).send(JSON.stringify({
          'error': 'access_denied',
          'error_description': msg
        }))
      } else {
        throw msg
      }
    })
}
#+end_src

This function first checks if all the required parameters (=client_id=,
=redirect_url=, =code_challenge=) are present, then makes sure that the client
ID and the redirect URL exist in the database and the client is allowed to
initiate the flow, and at last renders a page where user can sign in with their
account. The user credentials, along with other information, are POST to
=/signin=. Note that in this sample parameter =code_challenge_method=, though
required, is not used, as it is assumed that all code challenges are hashed
using SHA-256.

Requests with =response_type= set to code but do not have parameters
=code_challenge= and =code_challenge_method= initiate the Authorization Code
flow and are processed by function =handleACAuthRequest=; and requests with the
=token= response type are sent to function =handleImplicitAuthRequest=. These
two functions are largely the same as =handleACPKCEAuthRequest=:

#+begin_src js
function handleACAuthRequest (req, res) {
  if (req.query.client_id      === undefined ||
      req.query.redirect_url   === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('redirect-url', '=', req.body.redirect_url)
    .filter('ac-enabled', '=', true)

  datastore
    .runQuery(clientQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client/redirect URL.')
      }
    })
    .then(() => {
      const html = pug.renderFile(path.join(__dirname, 'auth.pug'), {
        response_type: 'code',
        client_id: req.query.client_id,
        redirect_url: req.query.redirect_url,
        code_challenge: req.query.code_challenge
      });
      res.status(200).send(html);
    })
    .catch(msg => {
      if (msg === 'Invalid client/redirect URL.') {
        res.status(400).send(JSON.stringify({
          'error': 'access_denied',
          'error_description': msg
        }))
      } else {
        throw msg
      }
    })
}
#+end_src

#+begin_src js
function handleImplicitAuthRequest (req, res) {
  if (req.query.client_id      === undefined ||
      req.query.redirect_url   === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('redirect-url', '=', req.body.redirect_url)
    .filter('implicit-enabled', '=', true)

  datastore
    .runQuery(clientQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client/redirect URL.')
      }
    })
    .then(() => {
      const html = pug.renderFile(path.join(__dirname, 'auth.pug'), {
        response_type: 'code',
        client_id: req.query.client_id,
        redirect_url: req.query.redirect_url,
        code_challenge: req.query.code_challenge
      });
      res.status(200).send(html);
    })
    .catch(msg => {
      if (msg === 'Invalid client/redirect URL.') {
        res.status(400).send(JSON.stringify({
          'error': 'access_denied',
          'error_description': msg
        }))
      } else {
        throw msg
      }
    })
}
#+end_src

**** =signin= Function
The =signin= function receives user credentials and redirects user back to the
client with an authorization code (or an access token, in the case of Implicit
flow):

#+begin_src js
exports.signin = (req, res) => {
  switch (req.body.response_type) {
    case ('code'):
      if (!req.body.code_challenge) {
        handleACSigninRequest(req, res);
      } else {
        handleACPKCESigninRequest(req, res);
      }
      break;

    case ('token'):
      handleImplictSigninRequest(req, res);
      break;

    default:
      res.status(400).send(JSON.stringify({
        'error': 'invalid_request',
        'error_description': 'Grant type is invalid or missing.'
      }));
      break;
  }
}
#+end_src

Similar to the =auth= function, =signin= uses functions
=handleACPKCESigninRequest=, =handleACSigninRequest= and
=handleImplictSigninRequest= to process requests from the Authorization Code
with PKCE flow, the Authorization Code flow and the Implicit flow respectively.

The first two functions are similar to each other; both of them issue an
authorization code after all the security checks are passed:

#+begin_src js
function handleACPKCESigninRequest (req, res) {
  if (req.body.username       === undefined ||
      req.body.password       === undefined ||
      req.body.client_id      === undefined ||
      req.body.redirect_url   === undefined ||
      req.body.code_challenge === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const userQuery = datastore
    .createQuery('user')
    .filter('username', '=', req.body.username)
    .filter('password', '=', req.body.password)

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('redirect-url', '=', req.body.redirect_url)
    .filter('acpkce-enabled', '=', true)

  datastore
    .runQuery(userQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid user credentials.')
      }
    })
    .then(() => {
      return datastore.runQuery(clientQuery)
    })
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client and/or redirect URL.')
      }
    })
    .then(() => {
      const authorizationCode = fernetToken
        .encode(JSON.stringify({
          'client_id': req.body.client_id,
          'redirect_url': req.body.redirect_url
        }))
        .toString('base64')
        .replace(/\+/g, '-')
        .replace(/\//g, '_')
        .replace(/=/g, '');

      const exp = Date.now() + CODE_LIFE_SPAN;

      const codeKey = datastore.key(['authorization_code', authorizationCode])
      const data = {
        'client_id': req.body.client_id,
        'redirect_url': req.body.redirect_url,
        'exp': exp,
        'code_challenge': req.body.code_challenge
      }

      return Promise.all([
        datastore.upsert({ key: codeKey, data: data }),
        Promise.resolve(authorizationCode)
      ])
    })
    .then(results => {
      res.redirect(appendQuery(req.body.redirect_url, {
        authorization_code: results[1]
      }))
    })
}
#+end_src

#+begin_src js
function handleACSigninRequest (req, res) {
  if (req.body.username       === undefined ||
      req.body.password       === undefined ||
      req.body.client_id      === undefined ||
      req.body.redirect_url   === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const userQuery = datastore
    .createQuery('user')
    .filter('username', '=', req.body.username)
    .filter('password', '=', req.body.password)

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('redirect-url', '=', req.body.redirect_url)
    .filter('ac-enabled', '=', true)

  datastore
    .runQuery(userQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid user credentials.')
      }
    })
    .then(() => {
      return datastore.runQuery(clientQuery)
    })
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client and/or redirect URL.')
      }
    })
    .then(() => {
      const authorizationCode = fernetToken
        .encode(JSON.stringify({
          'client_id': req.body.client_id,
          'redirect_url': req.body.redirect_url
        }))
        .toString('base64')
        .replace(/\+/g, '-')
        .replace(/\//g, '_')
        .replace(/=/g, '');

      const exp = Date.now() + CODE_LIFE_SPAN;

      const key = datastore.key(['authorization_code', authorizationCode])
      const data = {
        'client_id': req.body.client_id,
        'redirect_url': req.body.redirect_url,
        'exp': exp
      }

      return Promise.all([
        datastore.upsert({ key: key, data: data }),
        Promise.resolve(authorizationCode)
      ])
    })
    .then(results => {
      res.redirect(appendQuery(req.body.redirect_url, {
        authorization_code: results[1]
      }))
    })
}
#+end_src

Note that the generated authorization code is stored in the database with
=client_id=, =redirect_url= and =exp=; those values are used in later steps.

=handleImplictSigninRequest=, on the other hand, returns an access token if
everything looks alright:

#+begin_src js
function handleImplictSigninRequest (req, res) {
  if (req.body.username       === undefined ||
      req.body.password       === undefined ||
      req.body.client_id      === undefined ||
      req.body.redirect_url   === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const userQuery = datastore
    .createQuery('user')
    .filter('username', '=', req.body.username)
    .filter('password', '=', req.body.password)

   const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('redirect-url', '=', req.body.redirect_url)
    .filter('implicit-enabled', '=', true)

  datastore
    .runQuery(userQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid user credentials.')
      }
    })
    .then(() => {
      return datastore.runQuery(clientQuery)
    })
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client and/or redirect URL.')
      }
    })
    .then(() => {
      const token = jwt.sign({}, privateKey, {
          algorithm: 'RS256',
          expiresIn: JWT_LIFE_SPAN,
          issuer: ISSUER
        })
      res.redirect(appendQuery(req.body.redirect_url, {
        access_token: token,
        token_type: 'JWT',
        expires_in: JWT_LIFE_SPAN
      }))
    })
}
#+end_src

This sample uses the
=[[https://www.npmjs.com/package/jsonwebtoken%2529][jsonwebtoken]]= library to
prepare JWTs. The JWT is built using the RS256 algorithm, which involves a
private/public key pair. The token itself is protected by the private key; as
long as the private key is safe, no one else can issue access tokens on your
behalf. However, anyone can use the public key to decrypt the JWT and verify
its validity, without having to request your authorization server for help.

**** =token= Function
The =token= function, as its name implies, is responsible for issuing tokens:

#+begin_src js
exports.token = (req, res) => {
  switch (req.body.grant_type) {
    case 'password':
      handleROPCTokenRequest(req, res);
      break;

    case 'authorization_code':
      if (req.body.client_secret && !req.body.code_verifier) {
        handleACTokenRequest(req, res);
        break;
      }
      if (req.body.code_verifier) {
        handleACPKCETokenRequest(req, res);
        break;
      }
      res.status(400).send(JSON.stringify({
        'error': 'invalid_request',
        'error_description': 'Client secret and code verifier are exclusive' +
                             'to each other.'
      }));
      break;

    case 'client_credentials':
      handleCCTokenRequest(req, res);
      break;

    default:
      res.status(400).send(JSON.stringify({
        'error': 'invalid_request',
        'error_description': 'Grant type is invalid or missing.'
      }));
      break;
  }
};
#+end_src

Parameter =grant_type= determines how the access token is granted. Requests
with grant type =password= come from clients in the Resource Owner Password
Credentials flow and are processed by function =handleROPCTokenRequest=:

#+begin_src js
function handleROPCTokenRequest (req, res) {
  if (req.body.username      === undefined ||
      req.body.password      === undefined ||
      req.body.client_id     === undefined ||
      req.body.client_secret === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('client-secret', '=', req.body.client_secret)
    .filter('ropc-enabled', '=', true)

  const userQuery = datastore
    .createQuery('user')
    .filter('username', '=', req.body.username)
    .filter('password', '=', req.body.password)

  datastore
    .runQuery(clientQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client credentials.');
      }
    })
    .then(() => datastore.runQuery(userQuery))
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid user credentials.')
      }
    })
    .then(() => {
      const token = jwt.sign({}, privateKey, {
          algorithm: 'RS256',
          expiresIn: JWT_LIFE_SPAN,
          issuer: ISSUER
        })
      res.status(200).send(JSON.stringify({
          access_token: token,
          token_type: 'JWT',
          expires_in: JWT_LIFE_SPAN
        }))
    })
    .catch(msg => {
      if (msg === 'Invalid client credentials.' ||
          msg === 'Invalid user credentials.') {
        res.status(400).send(JSON.stringify({
          'error': 'access_denied',
          'error_description': msg
        }))
      } else {
        throw msg
      }
    })
}
#+end_src

Grant type =client_credentials= are reserved for clients in the Client
Credentials flow. Function =handleCCTokenRequest= handles these requests:

#+begin_src js
function handleCCTokenRequest (req, res) {
  if (req.body.client_id     === undefined ||
      req.body.client_secret === undefined) {
    return res.status(400).send(JSON.stringify({
      error: 'invalid_request',
      error_description: 'Required parameters are missing in the request.'
    }))
  }

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('client-secret', '=', req.body.client_secret)
    .filter('cc-enabled', '=', true)

  datastore
    .runQuery(clientQuery)
    .then(result => {
      if (result[0].length === 0) {
        return res.status(400).send(JSON.stringify({
          error: 'access_denied',
          error_description: 'Invalid client credentials.'
        }));
      } else {
        const token = jwt.sign({}, privateKey, {
          algorithm: 'RS256',
          expiresIn: JWT_LIFE_SPAN,
          issuer: ISSUER
        })
        res.status(200).send(JSON.stringify({
          access_token: token,
          token_type: 'JWT',
          expires_in: JWT_LIFE_SPAN
        }))
      }
    });
}
#+end_src

Last but not least, both Authorization Code flow and Authorization Code with
PKCE flow use the grant type =authorization_code=, with the former handled by
=handleACTokenRequest= and the latter =handleACPKCETokenRequest=:

#+begin_src js
function handleACTokenRequest (req, res) {
  if (req.body.client_id          === undefined ||
      req.body.client_secret      === undefined ||
      req.body.authorization_code === undefined ||
      req.body.redirect_url       === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const clientQuery = datastore
      .createQuery('client')
      .filter('client-id', '=', req.body.client_id)
      .filter('client-secret', '=', req.body.client_secret)
      .filter('ac-enabled', '=', true)
  
  datastore
    .runQuery(clientQuery)
    .then(clientQueryResult => {
      if (clientQueryResult[0].length === 0) {
        return Promise.reject('Invalid client credentials.')
      }
    })
    .then(() => {
      return verifyAuthorizationCode(req.body.authorization_code, 
                                     req.body.client_id,
                                     req.body.redirect_url)
    })
    .then(() => {
      const token = jwt.sign({}, privateKey, {
          algorithm: 'RS256',
          expiresIn: JWT_LIFE_SPAN,
          issuer: ISSUER
        })
      res.status(200).send(JSON.stringify({
          access_token: token,
          token_type: 'JWT',
          expires_in: JWT_LIFE_SPAN
        }))
    })
    .catch(msg => {
      if (msg === 'Invalid client credentials.'             ||
          msg === 'Invalid authorization code.'             ||
          msg === 'Client ID does not match the record.'    ||
          msg === 'Redirect URL does not match the record.' ||
          msg === 'Authorization code expired.') {
        res.status(400).send(JSON.stringify({
          'error': 'access_denied',
          'error_description': msg
        }))
      } else {
        throw msg
      }
    })
}
#+end_src

#+begin_src js
function handleACPKCETokenRequest (req, res) {
  if (req.body.client_id          === undefined ||
      req.body.authorization_code === undefined ||
      req.body.redirect_url       === undefined ||
      req.body.code_verifier      === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  verifyAuthorizationCode(req.body.authorization_code,
                          req.body.client_id,
                          req.body.redirect_url, 
                          req.body.code_verifier)
    .then(() => {
      const token = jwt.sign({}, privateKey, {
          algorithm: 'RS256',
          expiresIn: JWT_LIFE_SPAN,
          issuer: ISSUER
        })
      res.status(200).send(JSON.stringify({
          access_token: token,
          token_type: 'JWT',
          expires_in: JWT_LIFE_SPAN
        }))
    })
    .catch(msg => {
      if (msg === 'Invalid authorization code.'             ||
          msg === 'Client ID does not match the record.'    ||
          msg === 'Redirect URL does not match the record.' ||
          msg === 'Authorization code expired.'             ||
          msg === 'Code verifier does not match code challenge.') {
        res.status(400).send(JSON.stringify({
          'error': 'access_denied',
          'error_description': msg
        }))
      } else if (msg === 'Code challenge does not exist.') {
        res.status(400).send(JSON.stringify({
          'error': 'invalid_request',
          'error_description': msg
        }))
      } else {
        throw msg
      }
    })
}
#+end_src

Authorization code is verified with =verifyAuthorizationCode=. Note that you do
not have to decrypt the authorization code; verifying the values of =client_id=
and =redirect_url= from the request against the values on the record should
suffice.

#+begin_src js
function verifyAuthorizationCode(authorizationCode, clientId, redirectUrl,
                                 codeVerifier = undefined) {
  const transaction = datastore.transaction();
  const key = datastore.key(['authorization_code', authorizationCode])

  return transaction
    .run()
    .then(() => transaction.get(key))
    .then(result => {
      const entry = result[0]
      if (entry === undefined ) {
        return Promise.reject('Invalid authorization code.')
      }

      if (entry.client_id !== clientId) {
        return Promise.reject('Client ID does not match the record.')
      }

      if (entry.redirect_url !== redirectUrl) {
        return Promise.reject('Redirect URL does not match the record.')
      }

      if (entry.exp <= Date.now()) {
        return Promise.reject('Authorization code expired.')
      }

      if (codeVerifier         !== undefined &&
          entry.code_challenge !== undefined) {

        let codeVerifierBuffer = new Buffer(codeVerifier);
        let codeChallenge = crypto
                              .createHash('sha256')
                              .update(codeVerifierBuffer)
                              .digest()
                              .toString('base64')
                              .replace(/\+/g, '-')
                              .replace(/\//g, '_')
                              .replace(/=/g, '');
        if (codeChallenge !== entry.code_challenge) {
          return Promise.reject('Code verifier does not match code challenge.');
        }
      } else if (codeVerifier         === undefined ||
                 entry.code_challenge === undefined) {
        // Pass
      } else {
        return Promise.reject(
          'Code challenge or code verifier does not exist.');
      }

      return transaction.delete(key)
    })
    .then(() => transaction.commit())
    .catch(msg => {
      transaction.rollback()
      throw msg
    })
}
#+end_src

*** Sidenotes
- This tutorial uses Cloud Datastore, a highly scalable NoSQL database, to
  store user credentials, client information and authorization codes. It is
  also possible to use other data storage solutions, such as memcached, Redis,
  and Cloud SQL; however, you should not store any important information
  in-memory with Cloud Functions.

- This tutorial assumes that client has registered with your service and
  provided its redirect URL. Additionally, the authorization service requires a
  full match between the redirect URL in the request and the redirect URL on
  the record. In reality, however, it is common for developers to add
  additional values in the redirect URL to keep states during transition; if
  your use case requires variable redirect URLs, you should drop the full match
  restriction.

- Access tokens in this sample only contains information regarding its issuer
  and expiration date. Depending on your use case, it might be necessary to
  pose more restrictions. Common fields to implement in the access token
  include =audience= (destinations where access token is allowed to arrive) and
  =scopes= (level of access that the token grants).

- You can also use the =jsonwebtoken= library to verify JWTs. See its
  documentation for more information.

*** Cleaning Up
After you have finished this tutorial, you can clean up the resources you
created on Google Cloud Platform so that you will not be billed for them in the
future. To clean up, you can delete the whole project or delete the Cloud
Functions you deployed.

**** Deleting the Project
Visit the [[https://console.cloud.google.com/cloud-resource-manager][Manage resources menu]]. Select the project you used for this tutorial
and click =Delete=. Note that once the project is deleted, the project ID
cannot be reused.

If you have Cloud SDK installed in the system, you can also [[https://cloud.google.com/sdk/gcloud/reference/projects/delete][use the gcloud
command-line to delete a project]].

**** Deleting the Functions
Go to the [[https://console.cloud.google.com/functions][Cloud Functions Overview]] page. Select the functions you would like to
remove and click =Delete=.

* SECURITY Articles
** [[https://www.jscape.com/blog/what-is-hmac-and-how-does-it-secure-file-transfers][What Is HMAC And How Does It Secure File Transfers?]]

  #+CINDEX:integrity
  #+CINDEX:authenticity
  #+CINDEX:HMAC
Data integrity checks are vital to secure communications.  They enable
communicating parties to verify the integrity and authenticity of the messages
they receive.  In secure file transfer protocols like FTPS, SFTP, and HTTPS,
data integrity/message authentication is usually achieved through a mechanism
known as HMAC.  In this post, we explain what HMAC is, its basic inner
workings, and how it secures data transfers.

*** Importance of data integrity checks in secure file transfers
Business decisions and processes are highly dependent on accurate and reliable
data. If data gets tampered and the alterations go unnoticed, it could affect
decisions and processes down the line. So if your data has to be transmitted
over a network, especially one as perilous as the Internet, you have to take
precautionary measures to preserve its integrity or at least know if it
underwent unauthorized alterations.

This is precisely the reason why secure file transfer protocols like FTPS,
SFTP, and HTTPS are equipped with mechanisms for countering threats to data
integrity. The most commonly used mechanism today is HMAC. Let me explain what
it is.

*** What is HMAC?
HMAC stands for Keyed-Hashing for Message Authentication. It's a message
authentication code obtained by running a cryptographic hash function (like
MD5, SHA1, and SHA256) over the data (to be authenticated) and a shared secret
key. HMAC is specified in RFC 2104.

HMACs are almost similar to digital signatures. They both enforce integrity and
authenticity. They both use cryptographic keys. And they both employ hash
functions. The main difference is that digital signatures use asymmetric keys,
while HMACs use symmetric keys.

*** How HMAC works
To understand how HMAC works, let's first examine how a hash function (on its
own) could be used for conducting a data integrity check on a file
transfer. Let's say a client application downloads a file from a remote
server. It's assumed that the client and server have already agreed on a common
hash function, say SHA2.

Before the server sends out the file, it first obtains a hash of that file
using the SHA2 hash function. It then sends that hash (a.k.a. message digest)
along with the file itself. Upon receiving the two items (i.e. the downloaded
file and the hash), the client obtains the SHA2 hash of the downloaded file and
then compares it with the downloaded hash. If the two match, then that would
mean the file was not tampered along the way.

If an attacker manages to intercept the downloaded file, alter the file's
contents, and then forward the tampered file to the recipient, that malicious
act won't go unnoticed. That's because, once the client runs the tampered file
through the agreed hash algorithm, the resulting hash won't match the
downloaded hash. This will let the receiver know the file was tampered along he
way.

So a hash function should do the trick then? Not so fast. While a hash function
can establish *data integrity*, i.e. that the file or message wasn't altered
along the way, it can't establish *authenticity*. How would the client know the
message it received came from the legitimate source?

That's why secure file transfer protocols like FTPS, SFTP, and HTTPS use HMACs
instead of just hash functions.  When two parties exchange messages through
those secure file transfer protocols, those messages will be accompanied by
HMACs instead of plain hashes. An HMAC employs both a hash function and a
shared secret key.

A shared secret key provides exchanging parties a way to establish the
authenticity of the message. That is, it provides the two parties a way of
verifying whether both the message and MAC (more specifically, an HMAC) they
receive really came from the party they're supposed to be transacting with.

The secret key enables this capability because it's generated during key
exchange, a preliminary process that requires the participation of the two
parties. Only those two parties who participated in the key exchange would know
what the shared secret key is. In turn, they would be the only ones who would
be able to arrive at the same result if they compute the message's
corresponding MAC using the shared secret key.

*** Why is HMAC suitable for file transfers?
Aside from its ability to enable data integrity and message authentication,
another reason why HMAC is an excellent file transfer data integrity-checking
mechanism is its efficiency. As discussed in the article Understanding Hashing,
hash functions can take a message of arbitrary length and transform it into a
fixed-length digest. That means, even if you have relatively long messages,
their corresponding message digests can remain short, thereby allowing you to
maximize bandwidth.

** [[https://www.jscape.com/blog/bid/84422/Symmetric-vs-Asymmetric-Encryption][Symmetric vs Asymmetric Encryption]]

Secure file transfer protocols generally employ a combination of symmetric and
asymmetric encryption to preserve the confidentiality of data while in
transit. So why the need for two kinds of encryption? In this post, we take a
closer look at the main functions of symmetric and asymmetric encryption, their
strengths, their weaknesses, and why we'd prefer having both.

*** Symmetric key encryption
Symmetric key encryption is a type of encryption that makes use of a single key
for both the encryption and decryption process. Some of the encryption
algorithms that use symmetric keys include: AES (Advanced Encryption Standard),
Blowfish, DES (Data Encryption Standard), Triple DES, Serpent, and Twofish.

If you want to apply symmetric key encryption to a file transfer environment,
both the sender and receiver should have a copy of the same key. The sender
will use his copy of the key for encrypting the file, while the receiver will
use his copy for decrypting it.

So if you manage a secure file transfer server that only supports symmetric
encryption and one of your users wants to encrypt a file first before uploading
it, one of you (either the user or you, the server admin) should first generate
a key and then send the other person a copy of that key.

*** Asymmetric key encryption
Asymmetric key encryption, on the other hand, makes use of two keys. A private
key and a public key. The public key is used for encrypting, while the private
key is used for decrypting. Two of the most widely used asymmetric key
algorithms are: RSA and DSA.

If you're going to use asymmetric key encryption in a file transfer
environment, the sender would need to hold the public key, while the receiver
would need to hold the corresponding private key.

So, going back to the scenario given in the previous section, if you manage a
file transfer server and one of your users wants to encrypt a file first before
uploading it, it would typically be your duty to generate the key pair. You
should then send the public key to your user and leave the private key on the
server.

*** Which is stronger?
Actually, it's difficult to compare the cryptographic strengths of symmetric
and asymmetric key encryptions. Even though asymmetric key lengths are
generally much longer (e.g. 1024 and 2048) than symmetric key lengths (e.g. 128
and 256), it doesn't, for example, necessarily follow that a file encrypted
with a 2048-bit RSA key (an asymmetric key) is already tougher to crack than a
file encrypted with a 256-bit AES key (a symmetric key).

Instead, it would be more appropriate to compare asymmetric and symmetric
encryptions on the basis of two properties:
- Their computational requirements, and
- Their ease of distribution


Symmetric key encryption doesn't require as many CPU cycles as asymmetric key
encryption, so you can say it's generally faster. Thus, when it comes to speed,
symmetric trumps asymmetric. However, symmetric keys have a major disadvantage
especially if you're going to use them for securing file transfers.

Because the same key has to be used for encryption and decryption, you will
need to find a way to get the key to your recipient if he doesn't have it
yet. Otherwise, your recipient won't be able to decrypt the files you send
him. However way you do it, it has to be done in a secure manner or else anyone
who gets a hold of that key can simply intercept your encrypted file and
decrypt it with the key.

The issue of key distribution becomes even more pronounced in a file transfer
environment, which can involve a large number of users and likely distributed
over a vast geographical area. Some users, most of whom you may never have met,
might even be located halfway around the world. Distributing a symmetric key in
a secure manner to each of these users would be nearly impossible.

Asymmetric key encryption doesn't have this problem. For as long as you keep
your private key secret, no one would be able to decrypt your encrypted
file. So you can easily distribute the corresponding public key without
worrying about who gets a hold of it (well, actually, there are spoofing
attacks on public keys but that's for another story). Anyone who holds a copy
of that public key can encrypt a file prior to uploading to your server. Then
once the file gets uploaded, you can decrypt it with your private key.

*** Getting the best of both worlds with hybrid cryptosystems
Because both symmetric and asymmetric key cryptography have their own
advantages, modern file transfer systems typically employ a hybrid of the
two. Some hybrid cryptosystems are:
- SSL (used in FTPS and HTTPS)
- SSH (used in SFTP)
- OpenPGP


Hybrid cryptosystems employed in an SFTP or FTPS server use asymmetric keys to
initially encrypt symmetric keys known as session keys. The session keys are
then the ones used to encrypt the actual data. As its name implies, a session
key is only used in one session. After the session, the key is simply
discarded. That's a good thing because even if a session key is compromised,
only data sent within that particular session will be at risk.

Here's a simplified outline of the steps taken by a typical hybrid cryptosystem
used in secure file transfer protocols like SFTP and FTPS.

1. File transfer server sends its public key to an end user's file transfer
   client.

2. Client generates a session key, encrypts a copy of the session key using the
   public key, and sends that copy to the server.

3. Server receives its copy of the session key and both of them use that
   session key to encrypt/decrypt files exchanged within that session.


[[file:./resources/hybrid_cryptosystem.png]]

*** Summary
File transfer systems normally use hybrid cryptosystems, i.e. a combination of
symmetric and asymmetric key encryption, to provide secure file
transfers. Symmetric keys facilitate faster file encryptions, while asymmetric
keys simplify the key distribution process.

** [[https://www.jscape.com/blog/understanding-hashing][Understanding Hashing]]
Hashes are essential to secure file transfers. You can find them in operations
involving passwords, file integrity checks, digital signatures, digital
certificate thumbprints or fingerprints, and others. But what are hashes? In
this post, we'll introduce you to hashes, the concept of hashing, and its
applications in various areas of security.

*** What is hashing?
Hashing is an operation that takes any string of text, regardless of length or
size, as input and then provides a fixed-length string of characters as output.

*** Encryption vs Hashing
A hash looks pretty much like the output of an encryption operation
(a.k.a. ciphertext) does it? Well, encryption and hashing operations do have
similarities. However, they also have a couple of differences. First of all,
unlike encryption, hashing is always one way. In fact, hashing is often called
"one way encryption". So, while you can decrypt an encrypted text, you cannot
"de-hash" a hashed text. We'll see why this can be a useful feature when we
explain how hashes are used, e.g. in password authentication systems.

*** Properties of secure cryptographic hash functions
When hash functions (the underlying functions responsible for mapping the
original text into a hash) are used in information security, they must adhere
to certain properties. These three are the most important:

1. *They must be efficient.* The cryptographic hash function must not consume a
   lot of CPU cycles even if it's made to operate on a huge file.

2. *They must be one way functions.* Meaning, it should be virtually impossible
   to obtain the original text (a.k.a. the pre-image of the hash) from the
   hash.

3. *They must have collision resistance.* This means that it should be
   virtually impossible to find two different text or documents that would
   yield the same hash.


*** Commonly used hash algorithms
Some of the commonly used hashing algorithms include:

- MD5 ::

         Message Digest 5 or MD5 was developed by Ron Rivest, whose name is
         immortalised as the R in RSA (a public key cryptosystem common in
         various secure FTP protocols ). MD5 uses multiples of 512 bits as
         input and produces a 128-bit message digest (or the hash) as
         output. It is one of the older hashing algorithms but is now known to
         have certain vulnerabilities in its collision resistance properties.

- SHA1 ::

          Like the MD5 hash, SHA1 (secure hash algorithm) also takes 512 bits
          of input at a time. However, its output is 160 bits. SHA-1 was the
          result of a joint project between the NSA and the NIST. Like MD5,
          this cryptographic hash function has been proven to be relatively
          vulnerable to certain collision attacks.

- CRC ::

         CRC or Cyclic Redundancy Check is an example of a non-cryptographic
         hash function. Compared to cryptographic hash functions, CRC hash
         functions can be easily reversed. Hence, it isn't ideal for
         applications (e.g. digital signatures) that require functions with
         strong irreversibility properties. It's more suitable for detecting
         accidental changes in stored or transmitted files. In other words,
         it's used for data integrity checks.

- SHA-2 ::

           Once the SHA1 hash function was found to have potential
           vulnerabilities, the NSA decided to design a set of stronger hash
           functions. The resulting product was SHA-2, a family of hash
           functions that had 224, 256 and 384, and 512 bits. These were known
           respectively as SHA224, SHA256, SHA384, and SHA512.


*** Hashing passwords
Secure systems never store passwords in the clear. That is, if you look at a
password file, the list of usernames and their corresponding passwords wouldn't
look like this:

#+begin_example
peter: password1234

james: mac@pRoS

sharon: shadowfax
#+end_example

Instead, it would likely look like this:

#+begin_example
peter: uclQZA4bN0DpisuT5mnGV2b2Zw3RYJupH/QQUrpIxvM=

james: xw5UIGACzaNtYyZZjkaRY4a6uoVKhriy7NGLlW+COeM=

sharon: VgGAZRvmCKHoedevnDP2fUHMfuUNTcTL2XqFJGK7/qg=
#+end_example

The strings of characters you see after the equal signs are actually hashes
(actually, base-64 equivalents of hashes if you want to be more accurate) of
each password. When a user logs in, the system first grabs whatever is entered
into the password field and converts that into a password hash. It's that hash
that's used when looking up the username/password pair in the password file. If
a match is found, the user is allowed entry.

That way, even if an attacker gets a hold of the password hash file, he
wouldn't be able to use that file to login to the system.

Hashing is better than encryption in this case because it eliminates the
possibility of the hashed password being converted back to its plaintext
equivalent. If you use encryption, it would be possible for an attacker to
acquire all passwords (in plaintext) if he were somehow able to acquire the
decryption key.

*** Integrity checking
Remember the second characteristic we were able to observe in the section "What
is hashing?"? If you recall, we noticed that even the slightest change in the
original text can result in an entirely different hash. This characteristic can
be put to good use in data integrity checks. Let me give you a simple example.

Let's say a user wants to download an important electronic document from a
server. Because the integrity of the data in that document is important to him,
he would like to know if the document is altered along the way. One way to do
achieve this is by using a client and a server that supports the same hash
function.

Before sending the file, the server must first obtain a hash value of the file
using that hash function. Once the client receives the file, it too must use
the same hash function to generate a hash value. The two hash values must then
be compared. If the two values are equal, then it would be safe to conclude
that the file has been unchanged.

*** Digital signatures
Most data integrity checks are only carried out by the client. When a file is
downloaded, it's usually already accompanied by the file's hash a.k.a. message
digest. The client then generates its own hash from the file it downloaded and
compares it with the message digest that came along with the download. This
method has a flaw.

What's to stop an attacker from intercepting the file, altering it, generating
its own message digest using the same hash function, and then forwarding the
altered file (along with the new message digest) to the client? Once the client
receives the downloaded file and compares its locally-generated hash with the
downloaded hash, they will naturally appear equal. No way will this qualify for
a HIPAA compliant file transfer. It's therefore important for the client to
*make sure that both the downloaded file and the downloaded hash came from the
original source*.

This can be done using *asymmetric encryption keys*. Assuming the client has
the corresponding public key, the server can generate a "digital signature"
using its private key and the message digest. Its this digital signature that
will then be sent together with the file. So, when the client receives them, it
can then use the public key to verify the authenticity of the signature and
retrieve the message digest. Only then can the client compare the message
digest with its locally-generated hash of the file.

[[file:./resources/hashing-digital-signature.png]]

A failure to authenticate could only mean that the private key that was used to
generate the digital signature is not the pair of the public key used by the
client. Digital signatures are common in SSL-secured protocols like FTPS.

** [[https://www.jscape.com/blog/what-is-a-digital-signature][What is a Digital Signature?]]
Digital signatures help enforce security during data transfers. They're mainly
responsible for establishing authentication, data integrity, and
non-repudiation. Today, we'll be talking about the basic concepts behind
digital signatures, where they're used, how they work, and why they're always
an integral part of highly secure file transfers.

*** Uses of digital signatures
#+CINDEX:digital signatures
Digital signatures are used to meet three important goals of information
security: integrity, authentication, and non-repudiation.

**** Data integrity
#+CINDEX:integrity, data
#+CINDEX:data integrity
Message or Data integrity is particularly crucial during data transfers. Data
integrity ensures that the message received by the recipient is exactly the
same message sent by the sender. In wide area networks like the Internet, where
messages have to hop from one node or network device to another before arriving
at their intended final destination, there's always that risk of messages
getting altered along the way whether deliberately or accidentally. Data
integrity mechanisms help mitigate those risks. Through a data integrity check,
you'll know if the message you received has been tampered.

**** Authentication
#+CINDEX:authentication
When you receive a sensitive file, it's sometimes not enough to know that the
information in that file has been unaltered. You would also want to be sure
whether it really came from the person who you think sent it. In other words,
you would need a mechanism that would enable you to authenticate the source.

**** Non-repudiation
#+CINDEX:non-repudiation
Lastly, there may be data exchanges where you wouldn't want senders to disown
transmissions they actually sent some time in the past. For example, if someone
submits a report and the report is later found to be fraudulent, you wouldn't
want the sender to deny the fact that he sent it.

*** How digital signatures work
So how do digital signatures help you achieve these information security goals?
Perhaps it would be best to start by explaining how they work.

#+CINDEX:asymmetric encryption keys
#+CINDEX:public, private keys
#+CINDEX:private, public keys
#+CINDEX:secret keys
#+CINDEX:verify digital signature
#+CINDEX:key pair
Cryptographic digital signatures make use of asymmetric encryption keys,
i.e. public keys and their corresponding private keys (a.k.a. secret keys). The
private key is used to create a digital signature (in other words, for
"signing"), while the public encryption key is used for verifying the digital
signature. What makes this work is the fact that a pair of public and private
keys are so closely linked with one another that it would be virtually
impossible for a public key to authenticate a signature generated by a private
key that it isn't associated with.

#+CINDEX:digital signature, create
#+CINDEX:create digital signature
So how does one create a digital signature?

#+CINDEX:signing algorithm
#+CINDEX:RSA, DSA, signing algorithms
#+CINDEX:DSA, RSA, signing algorithms
#+CINDEX:hash function, digital signature
#+CINDEX:message digest, digital signature
To create a digital signature, you would take the message or file you would
like to sign and run it through a hash function. After that, you take the
resulting message digest or hash, combine it with your private key, and then
run them through a signing algorithm like RSA or DSA. The final result is that
message's digital signature. Of course, in applications like a secure file
transfer server, these things happen behind the scenes.

Theoretically, you could skip that hash function part and simply run the file
and the private key through some "signing algorithm" and still produce a
"digital signature". However, if the file is so large, this would take a great
deal of time. Besides, the resulting "signature" would also consume an
impractically huge amount of space.

#+CINDEX:verification process, digital signature
#+CINDEX:digital signature verification process
How about the digital signature verification process? This process now involves
the secret key's public key pair. While the secret key is used to sign
documents, its corresponding public key is used for verifying their
authenticity. Remember when I told you that the public key is tightly linked to
its private key?

If you have a public key and the key fails to authenticate a document you just
received, that would mean the secret key used for signing wasn't this public
key's pair. Consequently, it would also mean that the document's source isn't
who you expected it to be. That's how digital signatures are used for
authentication.

#+CINDEX:message digest, verification process
During the same verification process, the public key is also used to extract
the message digest that was originally combined with the private key to produce
the digital signature. The retrieved message digest is then compared with the
recipient's own locally-generated hash value of the received message. The
recipient must know what hash function was used by the sender. If the
locally-generated hash value and the extracted message digest are equal, then
it would mean that integrity of the message has been preserved.

Here's a simplified illustration of what we just discussed:

[[file:./resources/hashing-digital-signature.png]]

*** Summary of Digital Signature Creation

#+CINDEX:hash function, SHA2 hashing algorithm
#+CINDEX:SHA2 hashing algorithm
#+CINDEX:message digest (hash)
#+CINDEX:private key, digital signature
1. At the source (in this case, a server), the document is run through a hash
   function (e.g. SHA2 hashing algorithm) to produce a hash a.k.a. message
   digest. The message digest is combined with the source's private key to
   produce the document's digital signature.

2. The digital signature is affixed to the document and both are sent to the
   recipient (in this case, a client application).

   #+CINDEX:public key, digital signature
   #+CINDEX:message digest, decrypting
3. At the client side, the message digest is extracted from the digital
   signature using a copy of the server's public key that's in the client's
   possession. Note that the client wouldn't be able to extract the message
   digest if the public key in its possession doesn't match the private key
   used to generate the digital signature.

   #+CINDEX:hash function, identical to sender
   #+CINDEX:locally-generated hash
4. The client runs the document through the same hash function used by the
   sender to produce its own locally-generated hash.

5. The two hashes are compared.


*** Goals of Digital Signatures
If the two hashes are equal, it would prove two things:

{{{subheading(Data Integrity and Authenticity)}}}

#+CINDEX:integrity
#+CINDEX:authenticity
1. that the document was unaltered (thereby achieving *integrity*) and
2. that the source is who the recipient expected it to be (thereby achieving
   *authentication*).


{{{subheading(Non-Repudiation)}}}

#+CINDEX:non-repudiation
If both are achieved, then there is no way the sender can later on deny that he
sent the document. That's because none of these would be achieved if the wrong
private key was used in step 1. Since only the source could (theoretically)
have a hold of the private key, only the source could have initiated this
particular transaction. And that is how digital signatures help establish
*non-repudiation*.

Its ability to help enforce *authentication*, *data integrity*, and
*non-repudiation* can be very useful in automated business transactions and is
the reason why digital signatures are integral to secure data transfer
protocols like SFTP, FTPS, OFTP, and AS2.

*** When digital signatures alone are not enough
Notice how digital signatures are very dependent on the integrity of the
encryption keys. What if the public key in your possession actually belongs to
an impostor? It's possible for an attacker to pose as someone else and then
dupe you into obtaining his (the attacker's) public key. Once that happens, the
entire process illustrated earlier (from step 1 through 5) will proceed as
normal even if (in actuality) it has already been compromised.

In our next post, you'll learn how to mitigate this particular risk by using
- digital certificates,
- certificate authorities, and
- other trust models.
** [[https://www.jscape.com/blog/what-is-a-digital-certificate][What Is A Digital Certificate?]]
When users come to your website, they have a way of telling whether your site
is safe to connect with or not. It comes in the form of something called a
digital certificate. Today, we'll help you understand what a digital
certificate is, its key components, the role it plays in Web security, and
other concepts associated with it.
*** What a digital certificate is in a nutshell
#+CINDEX:digital certificate
#+CINDEX:cert
A digital certificate primarily acts like an identification card; something
like a driver's license, a passport, a company ID, or a school ID. It basically
tells other people who you are. So that, for example, when a user arrives at
your site looking for =yourdomain.com=, your site's digital certificate
(a.k.a. "cert") will help that user confirm whether he actually landed at
=yourdomain.com=.

#+CINDEX:public key, digital certificate
In addition, a cert also holds a copy of your site's public key, which is used
in encrypting data transmitted between your site and the user's web client (in
most cases, a web browser).

Not all websites offer digital certificates. In the past, the use of digital
certificates were mostly limited to sites with whom users had to engage in
secure transactions or share sensitive information. For instance, you normally
encountered certs on online banking websites, secure file transfer servers,
major e-commerce sites, or EDI servers. But because users are now becoming more
conscious about web security, more and more sites are employing digital
certificates to gain users' trust.

You won't actually see the entire digital certificate as you connect to a
site. However, you'll easily know it's there. Websites protected by certs
usually display a lock icon followed by "https" on the leftmost part of that
site's URL when viewed on your browser's URL bar. To view the contents of the
cert, just click on the lock icon.

#+CINDEX:X.509 standard, digital certificates
Most digital certificates in use today follow what is known as the X.509
standard. X.509 is used in SSL (Secure Sockets Layer) and TLS (Transport Layer
Security), so yes, it's what's being used in HTTPS, FTPS, WebDAVS and other
secure data transfer protocols. Let's now take a look at the kind of
information you'll find in this kind of certificate.

*** Contents of a X.509 certificate
The contents of a digital certificate typically include the following:

- Information about the subject a.k.a. Subject Name ::

     "subject" refers to the site represented by the cert.

- Information about the certificate issuer/certificate authority (CA) ::

     The CA is the body that issued and signed the certificate. More about this
     shortly

- Serial number ::

                   This is the serial number assigned by the issuer to this
                   certificate. Each issuer must make sure each certificate it
                   issues has a unique serial number.

- Version ::

             The X.509 version used by a given certificate. These days, you'll
             usually find version 3.

- Validity period ::

     Certs aren't meant to last forever. The validity period defines the period
     over which the cert can still be deemed trustworthy.

- Signature ::

               This is the digital signature of the entire digital certificate,
               generated using the certificate issuer's private key.

- Signature algorithm ::

     The cryptographic signature algorithm used to generate the digital
     signature (e.g. SHA-1 with RSA Encryption)

- Public key information ::

     Information about the subject's public key. This includes:
  - the algorithm (e.g. Elliptic Curve Public Key),
  - the key size (e.g. 256 bits),
  - the key usage (e.g. can encrypt, verify, derive), and
  - the public key itself

*** Certificate Key
#+CINDEX:public key, digital certificates
While most of the contents of a digital certificate are there for providing
information regarding the subject, the issuer, or the certificate itself, the
certificate key or public key has a special purpose. It's a vital component in
the encryption of data exchanged between the server and the client.

*** Certificate Authorities
#+CINDEX:certificate authorities
Another element of a digital certificate that does more than provide
information is the certificate's digital signature. As mentioned earlier, the
certificate's digital signature is generated using the certificate issuer's
private key. If you've read the article on digital signatures, you know that a
cert's digital signature can be used in authentication. But in order for a web
client to verify/authenticate a digital signature, it will need a copy of the
issuer's public key.

If the issuer happens to be a widely recognized certificate authority (CA),
that won't be a problem. A copy of that CA's public key will likely be
pre-installed in the user's web browser. Popular Web browser's like Chrome,
Firefox, Safari, and Internet Explorer all come with the certificates of
recognized CAs. That means, they already contain copies of those certificate
authorities' public keys and can therefore be used for verifying certificates
issued/signed by them.

#+CINDEX:signed certificates
#+CINDEX:self-signed certificate
Certificates signed by widely recognized CAs are called {{{dfn(signed
certificates)}}}. There are also certificates that are simply signed by issuers
who aren't widely recognized certificate authorities. For example, when you
create your own digital certificate using JSCAPE MFT Server but don't bother
processing a Certificate Signing Request (CSR), you will end up with what is
known as a {{{dfn(self-signed certificate)}}}.

If you want to see how a digital certificate is created, read the article [[HTTPS File Transfer][How
To Set Up A HTTPS File Transfer]], especially the section entitled Preparing
Server Keys.

*** Signed vs Self-signed certificates
#+CINDEX:certificate authorities
#+CINDEX:due diligence
In theory, certificate authorities are supposed to exercise due diligence
before signing digital certificates submitted to them through CSRs. They need
to verify first whether the information placed on the digital certificates are
in fact true. This is important because their attestation would later on serve
as the sole basis that certain websites who are able to present certs signed by
them can really be trusted.

So, assuming due diligence is really exercised, it would be safe to assume that
signed certificates are more reliable and trustworthy than self-signed
certificates. In fact, when a user attempts to connect to your site and your
site only has a self-signed certificate, the user's browser will display
a warning message.

#+CINDEX:self-signed certificates, when safe
Self-signed certificates are relatively safe to use internally, i.e., within
your organization, where you have more control over the servers that operate in
the network. So, for instance, you can use it to add security to a web file
transfer that takes place behind your corporate firewall.

** [[https://www.jscape.com/blog/an-overview-of-how-digital-certificates-work][An Overview of How Digital Certificates Work]]
In our previous post, we discussed what a digital certificate is. Today, we're
going to give you an overview of the basic process involving the creation,
signing, deployment, and use of digital certificates.

*** Server Certificates
#+CINDEX:server certificates
There are different types of digital certificates but we'll be focusing on the
server certificates used in secure web servers since they're the most
common. You come across these kinds of certificates on the Web everyday,
particularly when you connect to sites that support HTTPS. A CA-signed server
certificate is the kind of certificate you would need to deploy if you don't
want Web browsers to display a warning when users attempt to connect to your
secure file transfer server.

*** CA Certificates - the certificates in your browser
#+CINDEX:CA certificates
#+CINDEX:Certificate Authority certificates
Before any major Web browser like Chrome, Firefox, Safari or Internet Explorer
connects to your server via HTTPS, it already has in its possession a set of
certificates that can be used to verify the digital signature that will be
found on your server certificate. These certificates are called {{{dfn(CA
(Certificate Authority) certificates)}}}. On these certificates is a copy of
the public key of the CA who might issue (sign) your server certificate.

CA certificates of widely accepted certificate authorities are already
pre-installed on popular Web browsers, so we don't worry about installing them
anymore. This explains how CA certificates can verify the digital signature on
server certificates (more about this process later). The private keys that are
used for signing the server certificates already have their corresponding
public key pairs on our users' Web browsers.

*** Generating CSRs and having your cert signed by a CA
You can create your own digital certificate if you want. You can use free tools
like OpenSSL. Alternatively, you can also use built-in tools that come with
secure file transfer software like JSCAPE MFT Server.

#+CINDEX:CSR
#+CINDEX:Certificate Signing Request (CSR)
#+CINDEX:generate key pair
You usually start by generating a private key / public key pair, followed by a
CSR (Certificate Signing Request). The CSR would contain a copy of the public
key and some basic information about the subject. Once you've generated a CSR,
you would then submit that CSR to a CA.

Once the CA is done signing the cert, the CA would then return the cert to you
and you would then import that signed certificate to your server.

If we recall our discussion on digital certificates, the signed cert would
contain some basic information regarding the subject (your site), the issuer,
the validity period, the public key (of your site), and a digital signature of
the cert signed using the CA's private key.

In summary,

1. You generate a private key / public key pair and submit a CSR to a
   Certificate Authority. The contents of the CSR will form part of the final
   server certificate.

2. The CA verifies whether the information on the certificate is correct and
   then signs it using its (the CA's) private key. It then returns the signed
   server certificate to you.

3. You import the signed server certificate unto your server.

*** Sending of server certificate during SSL Handshake
Before a browser and an HTTPS server can exchange data over an encrypted
connection, they first engage in a process known as the SSL handshake. One
important part in the SSL handshake is the sending of the server certificate to
the web browser. It's here when the Web browser is able to authenticate the
identity of the server it's connecting to.

As soon as the browser receives a copy of the server certificate, it checks
which CA signed the server cert and then retrieves the CA certificate of that
particular Certificate Authority. It then uses the public key on that CA
certificate to verify the digital signature on the server cert.

Once the digital signature has been authenticated, the browser and server can
proceed with the rest of the SSL process.

** [[https://www.jscape.com/blog/how-to-set-up-https-file-transfer][How To Set Up A HTTPS File Transfer]] (on JSCAPE MFT Server)
#+CINDEX:HTTPS file transfer
<<HTTPS File Transfer>> In this post, you'll learn how to set up a HTTPS file
transfer. We'll begin with a "quickstart", where you'll use the default
settings in order to get a HTTPS file transfer service up and running with just
a few clicks. After that, we'll tackle some of the more advanced settings so
you can choose your desired set of SSL/TLS cipher suites and server key. Your
choice of cipher suites and keys will have an effect on the security of your
HTTPS service and its compatibility with your users' web browsers.

#+CINDEX:RFC 2818
*Note*: The HTTPS or HTTP Secure protocol is defined in [[https://tools.ietf.org/html/rfc2818][RFC 2818]], so if you
want a really technical discussion on HTTPS alone, feel free to read that.

[[https://youtu.be/PeN4mhFSbjc][Video of Article]]

** [[https://www.jscape.com/blog/bid/105104/how-to-set-up-a-web-file-transfer][How to Set Up a Web File Transfer]] (on JSCAPE MFT Server)
In this post, you'll learn how to set up a web-based file transfer service
using JSCAPE MFT Server. A web file transfer will allow your users to perform
file transfers without having to install a file transfer client. To upload or
download files, they'll just need to fire up their favorite Web browser like
Firefox, Chrome, Safari, Internet Explorer, or Edge, enter the web server's
URL, and login to the interface.
** [[https://www.jscape.com/blog/bid/82339/What-is-an-SSL-File-Transfer][What is an SSL File Transfer?]]
#+CINDEX:FTPS
#+CINDEX:FTP-SSL
#+CINDEX:SSL file transfer
SSL file transfer is a term sometimes used in referring to a secure file
transfer protocol known as FTPS or FTP-SSL. FTP is a network protocol used for
transferring files, while SSL is a protocol for encrypting information sent
over a network. This post is meant to help users understand what FTPS is and
what it is capable of doing, particularly in terms of enhancing the security of
your file transfers.

The term "SSL file transfer" is also used to refer to file transfers using
HTTPS, another secure network protocol. However, to keep this post concise,
we'll just focus on FTPS.

*** SSL Certificates
#+CINDEX:SSL certificates
At the heart of SSL (Secure Sockets Layer) file transfers are special files
called SSL certificates. These files contain information that is vital to
achieving security during file transfers. The two most common security
functions of an SSL certificate is to help in authenticating the identity of a
server and in facilitating encryption.

#+CINDEX:digital certificate, SSL
#+CINDEX:SSL certificate
Some of the information found in an SSL certificate (a.k.a. digital
certificate) include:

- The dates over which the certificate could be considered valid;

- Information regarding the subject (usually the organization/company who owns
  the server or the server itself);

- The subject's public key (this is what is used for encryption);

- Information regarding the issuer of the certificate; and

- The digital signature of the issuer


#+CINDEX:X.509 standard
All the information that should go into an SSL certificate is outlined by what
is known as the X.509 standard.

#+CINDEX:digital signature, SSL
The digital signature (which is virtually impossible to forge) is an
attestation of the issuer that the public key belongs to the "subject" whose
identity is being described in the certificate.

When used internally in an organization, SSL certificates are mostly
self-signed. The person in charge of generating the certificates would use the
company's certificate-generating program to issue the certificates. The program
would then automatically affix the company's signature to each generated
certificate.

#+CINDEX:Certificate Signing Request (CSR)
#+CINDEX:CSR
#+CINDEX:Certificate Authority (CA)
#+CINDEX:CA
In the case of companies who offer file transfer services to a large number of
external users, these companies normally issue what is known as a Certificate
Signing Request (CSR) and submit it to a Certificate Authority or CA. The CA
then puts the company under a vetting process to verify the company's true
identity before issuing the requested digital certificate.

Certificate Authorities are independent, trusted bodies whose digital signature
on a certificate is meant to assure end users that the bearer of the
certificate is really who he claims to be.

*** How authentication is done in SSL File Transfers
When a user attempts to connect to your managed file transfer server via FTPS,
the server will send the user an SSL certificate. The user (or the user's file
transfer client) should then review the contents of that certificate to verify
whether the server he is about to establish a connection with is in fact the
server he wants to connect to.

You see, it is possible for an attacker to go between a user and your managed
file transfer server and then pretend to be your server. If that attacker
succeeds in impersonating your server, the user can be duped into sending vital
information to him instead. SSL certificates can prevent that from happening.

When a user does not recognize the SSL certificate coming from a server, that
user can opt to cancel the connection. This would prevent any confidential
information from falling into the wrong hands.

But how can you be sure a certificate itself is legit? Can't an attacker simply
issue a fake certificate and use that to trick your users?

#+CINDEX:AnyClient service
If your file transfer client is designed to identify certificates signed by
CAs, it would prompt the user the moment it receives a certificate that hasn't
been signed by one. If a CA's signature is found, the session will be allowed
to proceed. The client ([[https://www.jscape.com/products/file-transfer-clients/anyclient/][AnyClient]] is used in figure below) would also prompt
the user if it receives a self-signed certificate. In this case, the user may
contact the server admin to verify the certificate.

Prompting is mostly only done at the start of the first session. After
verifying the certificate, the user can opt to save the certificate details
into the client to avoid getting prompted again in future sessions.

*** How SSL certificates facilitate encryption
As mentioned earlier, one of the items in an SSL certificate is the server's
public key. This public key has a corresponding private key, which is stored on
the server. This pair of keys is responsible for encrypting the session key,
which in turn is responsible for encrypting data exchanged over the FTPS
connection.

Because encryption renders information unreadable, any attacker who manages to
get hold of data during transmission would not be able to read, tamper with, or
make unauthorized alterations to the contents. Therefore, even if files have to
go through highly insecure networks like the Internet, their contents can be
kept safe when sent through an SSL file transfer.

** [[https://www.jscape.com/blog/ssl-vs-tls-know-the-difference][SSL vs. TLS | Knowing the Difference Between SSL and TLS]]
#+CINDEX:SSL
#+CINDEX:TLS
#+CINDEX:SSL/TLS
SSL and TLS have many similarities. That's why, in most software applications,
they're configured together as "SSL/TLS". However, there are several
differences between SSL and TLS well, which is what we're going to talk about
now.

*** A brief discussion on the similarities
#+CINDEX:Secure Socket Layer (SSL)
#+CINDEX:Transport Layer Security (TLS)
SSL (Secure Socket Layer) and TLS (Transport Layer Security) are very similar
in many aspects. They both:

- protect data privacy through data-in-motion encryption;
- provide server and (optionally) client authentication;
- check for message integrity using message authentication codes; and
- perform a preliminary handshake process wherein the two communicating parties
  negotiate for a common cipher suite.


The similarities are closest between the first version of TLS (TLS 1.0) and the
last version of SSL (SSL 3.0). In fact, TLS v 1.0 is often considered SSL v
3.1. The former even had the ability to downgrade an ongoing connection to
SSL 3.

So how does TLS differ from SSL? What we have below is by no means an
exhaustive list but here are some of the key differences:

*Note*: All of our comparisons will be between TLS and SSLv3.0 because version
3 is the only SSL version that's still (relatively) widely used.

*** Absence of a =no_certificate= error alert in TLS
In SSLv3.0 (refer to RFC 6101), a client would typically respond with a
=no_certificate= alert message whenever the server requested a certificate for
authentication but it (the client) had none to give. In TLS, this alert is no
longer necessary. However, the client must (especially in TLS 1.2 - RFC 5246)
send a certificate message containing no certificates.

*** TLS has more Alert descriptions
Whenever a problem is encountered during the course of a SSL or TLS connection,
the party who discovers the problem would send out an alert message.

SSLv3 had 12 of these messages.

{{{subheading(SSL Alert Descriptions)}}}

- Close Notify,
- Unexpected Message,
- Bad Record MAC,
- Decompression Failure,
- Handshake Failure,
- No Certificate,
- Bad Certificate,
- Unsupported Certificate,
- Certificate Revoked,
- Certificate Expired,
- Certificate Unknown, and
- Illegal Parameter.


TLS added 19 more to that (although "No Certificate" was removed). 

{{{subheading(Additional Alert Descriptions only found in TLS)}}}

- Decryption Failed,
- Record Overflow,
- Unknown CA (Certificate Authority),
- Access Denied,
- Decode Error,
- Decrypt Error,
- Export Restriction,
- Protocol Version,
- Insufficient Security,
- Internal Error,
- User Canceled,
- No Renegotiation,
- Unsupported Extension,
- Certificate Unobtainable,
- Unrecognized Name,
- Bad Certificate Status Response,
- Bad Certificate Hash Value,
- Unkown PSK, and
- No Application Protocol.

*** TLS uses HMAC for message authentication
#+CINDEX:integrity checks
#+CINDEX:MAC
#+CINDEX:HMAC
SSL performs message integrity checks (to determine whether a message has been
altered) through Message Authentication Codes (MACs) that use either MD5 or
SHA. TLS, on the other hand, uses HMAC, allowing it to work with a wider
variety of hash functions; not just MD5 and SHA.

*** TLS uses a pseudorandom function to generate the key material
#+CINDEX:pseudorandom function
To generate the key material, TLS uses an HMAC-based pseudorandom function
(PRF). SSL doesn't.

*** TLS has a simpler way of arriving at the CertificateVerify message
In cases wherein the server requests for a client certificate (to authenticate
the client), the client is supposed to send a follow-up message some time after
sending the Certificate message (the message that contains the client
certificate). In TLSv1.2, this message must be sent right after the
ClientKeyExchange message.

This follow-up message, known as the CertificateVerify message, would enable
the server to verify that the client certificate in fact originated from the
actual client and not an impostor.

This CertificateVerify message is actually a signature of the previous
handhsake messages signed using the client certificate's corresponding private
key. Because the server would have already had the corresponding public key
(which accompanied the client certificate sent earlier) in its possession, it
would be able to verify the signature.

In TLS, everything that's needed to construct the CertificateVerify message can
be found in the previous handshake messages. It wasn't the same in SSL, which,
in addition to the handshake messages, also required the master secret and a
couple of other values known as =pad_1= and =pad_2= (see RFC 6101, section
5.6.8)

*** Different set of cipher suites
Another difference between TLS and SSL are their collection of cipher
suites. SSL cipher suites typically begin with SSL_, while TLS cipher suites
begin with TLS_. Notably missing in TLS are the FORTEZZA cipher suites, which
are supported in SSLv3. On the other hand, notably present in the later
versions of TLS (more specifically, starting at TLSv1.1) are the AES cipher
suites. The Advanced Encryption Standard (AES) ciphersuites were integrated
into TLS by virtue of RFC 3268.

** [[https://www.jscape.com/blog/bid/81215/Roles-of-Server-and-Client-Keys-in-Secure-File-Transfers-Part-1][Roles of Server and Client Keys in Secure File Transfers - Part 1]]
[Last updated on Feb 2019] Secure file transfers typically employ public key
cryptography. This cryptographic system involves the use of two different keys:
a public key and a private key. In JSCAPE MFT Server, such keys can be easily
generated, imported, and exported in the Key Manager. But some first-time users
find it hard to even start using the Key Manager. One reason for that is
because they fail to see the difference between server keys and client keys.

You see, both of them deal with public keys and private keys. Also, whether you
generate server keys or client keys, the user interface and the fields you're
asked to complete are quite identical.

So what exactly is the difference between these two?

Actually, server keys are primarily used for preserving the confidentiality of
information contained in your file transfers and for authenticating a server's
identity, while client keys are used for authenticating a client's identity.

Perhaps we should start by defining what authentication and confidentiality
exactly are.

*** Authentication and Confidentiality
Authentication and confidentiality are both vital ingredients for achieving
information security; in our case, the security of our file transfers. But
they're two different things.

{{{subheading(Authentication)}}}

Authentication allows you to verify the identity of anyone or even anything (as
in the case of servers, workstations, and other machines) trying to gain access
to your system. For instance, let's say you only want your trusted assistant,
George, to download files from a certain directory in your managed file
transfer server.

If someone logs in to that directory as George, you would want to make sure
that guy is really George and not someone just trying to impersonate him. The
most common way of applying authentication is by requiring the person to login
using George's username and password. This is known as {{{dfn(password
authentication)}}}. Ideally, George's username and password are things only
George would know.

Another way to authenticate a user would be to require the user to submit
something that only he should *have*. One example of this "something" is a
/private key/, which is used in public key authentication. This is what we're
interested in here.

Here's a file transfer client ([[https://www.jscape.com/products/file-transfer-clients/anyclient/][AnyClient]]) requiring both password
authentication and public key authentication:

[[file:./resources/password_and_public_key_authentication-resized-600.png]]

Once you are able to authenticate the identity of a person or machine, you
would then be able to enforce other vital elements of information security such
as authorization, accountability, and non-repudiation. But these terms are for
another post. The next term we would like to define now is "confidentiality".

{{{subheading(Confidentiality)}}}

Authentication is usually applied at the start of a secure file transfer. Once
identities have been verified, file transfers can be allowed to proceed. The
next security objective would then be to preserve the confidentiality of
whatever information is being transferred. That is, to keep the information
private between the sender and the recipient.

In most IT systems, confidentiality is enforced through encryption. Encryption
renders normal text (known as plaintext) into something unreadable (known as
ciphertext). This can be very useful especially if your file transfers go
through highly unprotected networks like the Internet. Once the ciphertext
reaches its intended recipient, it can then be transformed back to plaintext by
'decrypting' it.

Encryption and decryption are usually done through the use of keys. Some
cryptographic systems use just one key for both encryption and
decryption. Other systems use two; one key for encrypting and another key for
decrypting.

The most widely accepted kind of strong encryption is public key encryption and
it uses two keys - a private key and a public key.

*** How public key cryptography implements authentication and confidentiality
Having learned about authentication and confidentiality, you're probably now in
the position to understand how JSCAPE MFT Server uses public key cryptography
(a.k.a. asymmetric key cryptography) to implement these two important elements
of information security. Let's start by discussing how public key cryptography
is able to uphold file transfer confidentiality.

{{{subheading(Public keys and private keys for encryption)}}}

Public key cryptography makes use of a pair of keys. One key in the key pair is
called a private key, while the other one is called a public key. Public keys
are used for encrypting files, while private keys are used for decrypting them.

A private key is kept by the key's owner and, as its name implies, is supposed
to be kept private. Meaning, only the owner should know what it is or where it
is. A public key, on the other hand, is generally shared with others
(sometimes, even to the general public).

Proceed to [[Server-Client-Keys-Part 2][Part 2]].

** [[https://www.jscape.com/blog/bid/82332/Roles-of-Server-and-Client-Keys-in-Secure-File-Transfers-Part-2][Roles of Server and Client Keys in Secure File Transfers - Part 2]]
<<Server-Client-Keys-Part 2>>This is a continuation of Part 1. To preserve
confidentiality in secure file transfers, public keys are given to end users
while the private key is kept inside the managed file transfer server.

When a user wants to do a secure file transfer, he simply encrypts his
plaintext file using the public key in his possession. Because the file is
encrypted, it is kept safe from prying eyes during transmission and the
confidentiality of its contents is preserved. As soon as the encrypted file
reaches the managed file transfer server, the server decrypts it using the
public key's corresponding private key.

So how does a user get a hold of the public key? Sometimes, a public key is
sent by the server to the user's file transfer client at the start of a secure
file transfer. For example, at the start of an FTPS session, the server sends a
digital certificate that already contains a public key.

{{{subheading(Public keys and private keys for authentication)}}}

Public keys and private keys aren't only used for encryption. Because a
particular private key and its corresponding public key are related, the public
key can be used to verify that a certain private key is in fact its
partner. This explains why they are also often used in authenticating clients
at the start of a secure file transfer session.

For example, in setting up SFTP, private keys are generated and then are each
assigned to authorized end users. If the system is applied correctly, no two
end users would have the same private key and each user would keep his/her own
private key private. Also, the private keys' corresponding public keys would be
kept in the server.

So when a user logs in by submitting his private key to the server for
verification, the server can verify the user's identity by using the private
key's corresponding public key.

*** Nailing down the difference between server keys and client keys
After all that discussion about private keys, public keys, confidentiality and
authentication, we're finally ready to differentiate server keys and client
keys.

{{{subheading(How server keys are used)}}}

Whenever you generate a server key via the JSCAPE MFT Server's Key Manager,
you're actually creating a public/private key pair that would later on be used
primarily for encrypting files in secure file transfer protocols like SFTP,
FTPS, or HTTPS. In other words, they would be used by your server to preserve
the confidentiality of your file transfers.

As mentioned earlier, the public key of this particular key pair is normally
sent (sometimes as part of a digital certificate) to the client at the start of
a secure file transfer session. The client then uses that public key to encrypt
whatever file it sends to the server.

*Note*: In some cases, server keys can also be used for server authentication
(as in the case of HTTPS) or both server authentication and client
authentication (as in the case of AS2).

{{{subheading(How client keys are used)}}}

On the other hand, whenever you generate a client key via the JSCAPE MFT
Server's Key Manager, the resulting public/private key pairs would be used for
authentication purposes.

In the course of generating a client key, you would be asked to export that
client key's private key.  It is that private key which you would send to an
end user and, in turn, which the end user would load up to his file transfer
client to do say [[SFTP public key authentication][SFTP public key authentication]] (see screenshot in Part 1).

*** Summary
Whenever you generate either a server key or a client key, you are actually
creating a key pair consisting of a private key and a public key. However, the
pair that's created when you generate a server key is mainly used for
encrypting the session (with a few instances wherein they're used for
authentication), while the pair that's created when you generate a client key
is used for authenticating clients.

** [[https://www.jscape.com/blog/setting-up-sftp-public-key-authentication-command-line][Setting Up SFTP Public Key Authentication On The Command Line]]
<<SFTP public key authentication>> SFTP provides an alternative method for
client authentication. It's called SFTP public key authentication. This method
allows users to login to your SFTP service without entering a password and is
often employed for automated file transfers. In this post, we'll walk you
through the process of setting up this kind of authentication on the command
line. It's really easier to do this on a GUI-based interface but if you simply
love doing things on the terminal, this post is for you.

*Note*: SFTP (through SSH) is usually installed on Linux distros, so we'll be
using Linux for both the (SFTP) server and client machines in this tutorial.

** [[https://www.jscape.com/blog/bid/104856/5-Big-Business-Benefits-of-Using-SSO-Single-Sign-On][Single Sign On]]
Although it's been around for quite a while, Single Sign-On or SSO has just
started gaining widespread adoption. But it's spreading real fast. In fact, if
you surf the Web everyday, I bet you've seen many websites inviting you to
login using one of these ...

[[file:./resources/sso-examples.png]]

Never tried clicking any of those buttons? There's really nothing to it. If you
have absolutely no idea what SSO is, here's a good introductory article that
should get you warmed up on this awesome technology:
- [[https://www.jscape.com/blog/bid/104558/SSO-Single-Sign-On-Simplified][SSO (Single Sign-On) Simplified]]


So why are organizations adopting SSO? And more importantly, why would you want
to implement it in your business? Here are five reasons:

** [[https://www.jscape.com/blog/bid/104558/SSO-Single-Sign-On-Simplified][SSO (Single Sign-On) Simplified]]
There was a time when the average computer user had to enter login credentials
only once per day - likely to simply gain access into the Windows
environment. But in this cloud-computing/mobile device age, unless you've
activated the "stay signed in" option (assuming it's available), you'd probably
have to login to 5 or even 20 different Web sites or online applications per
day.

Many people already find it hard to remember a single username/password pair,
let alone five or more. To work around this difficulty, some individuals use
the same login credentials for all the sites or applications they need access
to. But in doing so, they create a serious vulnerability. If a malicious
individual gets hold of those credentials, he could potentially gain access to
multiple applications.

That's why some organizations have started implementing SSO or Single Sign-On.

[[file:./resources/sso-google.png]]

* LEGAL---Electronic Signatures
** [[https://www.govinfo.gov/content/pkg/PLAW-106publ229/pdf/PLAW-106publ229.pdf][ELECTRONIC SIGNATURES IN GLOBAL AND NATIONAL COMMERCE ACT]]
- PUBLIC LAW 106229JUNE 30, 2000
- 114 STAT. 464
- To facilitate the use of electronic records and signatures in interstate or
  foreign commerce.

* Listings
:PROPERTIES:
:unnumbered: t
:END:
#+texinfo:@listoffloats Listing

* Concept Index
:PROPERTIES:
:index:    cp
:unnumbered: t
:END:
* Export Settings                                                  :noexport:
** Options
#+options: H:4 ':t
** Texinfo Export Settings
#+texinfo_filename:security.info
#+texinfo_class: info
#+texinfo_header:
#+texinfo_post_header:
#+subauthor:
#+texinfo_dir_category:WebDev
#+texinfo_dir_title:Security
#+texinfo_dir_desc:Security information
#+texinfo_printed_title:Security Information
#+subtitle:For WebDev
** Macro Definitions
#+macro:heading @@texinfo:@heading $1@@
#+macro:subheading @@texinfo:@subheading $1@@
#+macro:dfn @@texinfo:@dfn{$1}@@
#+macro:noindent @@texinfo:@noindent @@
