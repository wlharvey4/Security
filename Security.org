# -*- mode: org; -*-
#+title:Security Information
#+author:Pinecone062
#+date:December 19, 2019
#+macro:version 0.9.9.<2019-12-19 Thu 11:20>
Version {{{version}}} By {{{author}}}

* Cross Origin Resource Sharing---CORS
- https://www.w3.org/TR/access-control/

- [[https://www.w3.org/wiki/CORS][CORS Wiki Page]] The text below was previously part of the CORS
  specification. It was taken out per a suggestion at the May 2012 F2F so it
  could be maintained by the wider web community.

- [[https://fetch.spec.whatwg.org/#http-cors-protocol][CORS Protocol]] To allow sharing responses cross-origin and allow for more
  versatile fetches than possible with HTML’s form element, the CORS protocol
  exists. It is layered on top of HTTP and allows responses to declare they can
  be shared with other origins.  This section explains the CORS protocol as it
  pertains to server developers. Requirements for user agents are part of the
  fetch algorithm, except for the new HTTP header syntax.  The CORS protocol
  consists of a set of headers that indicates whether a response can be shared
  cross-origin.


This document defines a mechanism to enable client-side cross-origin requests.
Specifications that enable an API to make cross-origin requests to resources
can use the algorithms defined by this specification.

#+cindex:CORS, definition
-  CORS :: A request for a resource (like an image or a font) outside of the
           origin is known as a cross-origin request.  CORS (cross-origin
           resource sharing) manages cross-origin requests.

           file:./resources/same-origin-40.png

* JSON Web Tokens
** Article---How JWTs Secure Your API
:PROPERTIES:
:source-url:   https://vuejsdevelopers.com/2019/04/15/api-security-jwt-json-web-tokens/?
:source-title: How JSON Web Token (JWT) Secures Your API
:source-author: Anthony Gore
:source-date: April 14, 2019
:END:
*** Introduction From How JWTs Securre Your API
You've probably heard that the JSON Web Token (JWT) is the current
state-of-the-art technology for securing APIs.  Like most security topics, it's
important to understand how it works (at least, somewhat) if you're planning to
use it.  The problem is that most explanations of JWT are technical and
headache-inducing.  Let's see if I can explain how a JWT can secure your API
without crossing your eyes!

*** API Authentication

{{{heading(Need to Authenticate Access)}}}

#+CINDEX:authentication
Certain API resources need restricted access.  We don't want one user to be
able to change the password of another user, for example.  That's why we
protect certain resources---make users supply their ID and password before
allowing access---in other words, we authenticate them.

{{{heading(HTTP Requests are Stateless)}}}

#+CINDEX:stateless, HTTP
The difficulty in securing an HTTP API is that requests are stateless---the API
has no way of knowing whether any two requests were from the same user or not.
So why don't we require users to provide their ID and password on every call to
the API?  Only because that would be a terrible user experience.

*** JSON Web Token
:PROPERTIES:
:article-title: What is a JSON Web Token?
:article-cite: https://robmclarty.com/blog/what-is-a-json-web-token
:article-author: Rob McLarty
:END:
What we need is a way to allow a user to supply their credentials just once,
but then be identified in another way by the server in subsequent requests.
Several systems have been designed for doing this, and the current
state-of-the-art standard is the JSON Web Token.

{{{heading(How JWTs Work)}}}

There's a great [[https://robmclarty.com/blog/what-is-a-json-web-token][article]] on the topic which makes a good analogy about how JSON
web tokens work:
#+begin_quote
Instead of an API, imagine you're checking into a hotel.  The "token" is the
plastic hotel security card that you get that allows you to access your room,
and the hotel facilities, but not anyone else's room.  When you check out of
the hotel, you give the card back.  This is analogous to logging out.
#+end_quote

*** Structure of the Token

{{{heading(What a JWT Looks Like)}}}

#+CINDEX:HTTP request header
#+CINDEX:header, HTTP request
#+CINDEX:request, HTTP header
#+CINDEX:bearer, authorization
#+CINDEX:authorization, bearer
#+CINDEX:token
#+CINDEX:bearer token
Normally a JSON web token is sent via the header of HTTP requests. Here's what
one looks like:
: Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIn0.dozjgNryP4J3jVmNHl0w5N_XgL0n3I9PlFUP0THsR8U
In fact, the token is the part after "Authorization: Bearer", which is just the
HTTP header info.

{{{heading(The Header Payload and Signature)}}}

#+CINDEX:header
#+CINDEX:payload
#+CINDEX:signature
#+CINDEX:Base 64 encode
Before you conclude that it's incomprehensible gibberish, there are a few
things you can easily notice.  Firstly, the token consists of three different
strings, separated by a period.  These three string are base 64
encoded[fn::Base 64 encoding is a way of transforming strings to ensure they
don't get screwed up during transport across the web.  It is not a kind of
encryption and anyone can easily decode it to see the original data.] and
correspond to:
- the /header/,
- the /payload/, and
- the /signature/.


We can decode these strings to get a better understand of the structure of JWT.

{{{subheading(Header)}}}

#+CINDEX:header, dfn
The following is the decoded header from the token.  The @@texinfo:@dfn{header}@@ is
meta information about the token.  It doesn't tell us much to help build our
basic understanding, so we won't get into any detail about it.

#+BEGIN_SRC js
{
  "alg": "HS256",
  "typ": "JWT"
}
#+END_SRC

{{{subheading(Payload)}}}

#+CINDEX:payload, dfn
The payload is of much more interest.  The @@texinfo:@dfn{payload}@@ can include any
data you like, but you might just include a user ID if the purpose of your
token is API access authentication.

#+BEGIN_SRC js
{
  "userId": "1234567890"
}
#+END_SRC

It's important to note that the payload is not secure.  Anyone can decode the
token and see exactly what's in the payload.  For that reason, we usually
include an ID rather than sensitive identifying information like the user's
email.  Even though this payload is all that's needed to identify a user on an
API, it doesn't provide a means of authentication.  Someone could easily find
your user ID and forge a token if that's all that was included.

So this brings us to the signature, which is the key piece for authenticating
the token.

*** Hashing Algorithms
#+CINDEX:hashing algorithm, dfn
#+CINDEX:hashing algorithm, SHA256
#+CINDEX:hash, dfn
#+CINDEX:SHA256 hashing algorithm
Before we explain how the signature works, we need to define what a
@@texinfo:@dfn{hashing algorithm}@@ is.  To begin with, it's a function for
transforming a string into a new string called a @@texinfo:@dfn{hash}@@.  For example,
say we wanted to hash the string "Hello, world".  Here's the output we'd get
using the =SHA256= hashing algorithm:
: 4ae7c3b6ac0beff671efa8cf57386151c06e58ca53a78d83f36107316cec125f
The most important property of the hash is that you can't use the hashing
algorithm to identify the original string by looking at the hash.  In other
words, we can't take the above hash and directly figure out that the original
string was "Hello, world". The hash is complicated enough that guessing the
original string would be infeasible.  There are many different types of hashing
algorithms, but =SHA256= is commonly used with JWT.

{{{heading(JWT Signature)}}}

#+CINDEX:signature, dfn
So coming back to the JWT structure, let's now look at the third piece of the
token, the @@texinfo:@dfn{signature}@@.  This actually needs to be calculated:

#+BEGIN_SRC js
HMACSHA256(
  base64UrlEncode(header) + "." + base64UrlEncode(payload),
  "secret string"
);
#+END_SRC

Here's an explanation of what's going on here:

#+CINDEX:hashing function
- Firstly, =HMACSHA256= is the name of a hashing function and takes two
  arguments:
  - the string to hash, and
  - the "secret" (defined below).
- Secondly, the string we hash is the base 64 encoded /header/, plus the base 64
  encoded /payload/.
- Thirdly, the /secret/ is an arbitrary piece of data that only the server
  knows.


Why include the header and payload in the signature hash?  This ensures the
signature is unique to this particular token.

{{{subheading(The Secret)}}}

#+CINDEX:secret
What's the @@texinfo:@dfn{secret}@@?  To answer this, let's think about how you would
forge a token.  We said before that you can't determine a hash's input from
looking at the output.  However, since we know that the signature includes the
header and payload, as those are public information, if you know the hashing
algorithm (hint: it's usually specified in the header), you could generate the
same hash.  But the secret, which only the server knows, is not public
information.  Including it in the hash prevents someone generating their own
hash to forge the token.  And since the hash obscures the information used to
create it, no one can figure out the secret from the hash, either.

{{{subheading(Salting)}}}

#+CINDEX:salting
The process of adding private data to a hash is called @@texinfo:@dfn{salting}@@ and
makes cracking the token almost impossible.

*** Authentication Process
#+CINDEX:authentication process
So now you have a good idea of how a token is created.  How do you use it to
authenticate your API?

{{{heading(Login)}}}

#+CINDEX:token, generate
#+CINDEX:generate token
A token is generated when a user logs in and is stored in the database with the
user model.  The token then gets attached as the /authorization header/ in the
response to the login request.

#+caption:Generating a Token Upon Login; ~loginController.js~
#+name:generate-token
#+BEGIN_SRC js
if (passwordCorrect) {
  user.token = generateToken(user.id);
  user.save();
  res.headers("authorization", `Bearer ${token}`).send();
}
#+END_SRC

{{{heading(Authenticating requests)}}}

#+CINDEX:requests, authenticate
#+CINDEX:authenticate requests
Now that the client has the token, it can attach it to any future requests to
authenticate the identity of the user.  When the server receives a request with
an authorization token attached, the following happens:

1. It decodes the token and extracts the ID from the payload.
2. It looks up the user in the database with this ID.
3. It compares the request token with the one that's stored with the user's
   model.  If they match, the user is authenticated.

#+caption:The Server authenticates requests from the Client; ~authMiddleware.js~
#+name:authenticate-requests
#+BEGIN_SRC js
const token = req.header.token;
const payload = decodeToken(token);
const user = User.findById(payload.id);
if (user.token = token) {
  // Authorized
} else {
  // Unauthorized
}
#+END_SRC

{{{heading(Logging out)}}}

#+CINDEX:logout
If the user logs out, simply delete the token attached to the user model, and
now the token will no longer work.  A user will need to log in again to generate
a new token.

#+caption:Logging a user out; ~logoutController.js~
#+name:logout
#+BEGIN_SRC js
user.token = null;
user.save();
#+END_SRC

*** Wrapup
So that's a very basic explanation of how you can secure an API using JSON Web
Tokens.  I hope your head doesn't hurt too much.

** Course---JSON Web Token Authentication with Node.js
:PROPERTIES:
:source:   Egghead.io
:author:   Joel Lord
:END:
*** About the Course
In this course, we will build a simple authentication server that will act as a
token issuer, and we will use those tokens to access resources on an API.
Starting from scratch, the participants will learn how easy token based
authentication can be and will understand how to use them on their APIs as well
as on the front end of their web applications.
**** Source Code
[[https://github.com/eggheadio-projects/egghead-auth-course/tree/master][eggheadio-projects/egghead-auth-course]]
**** The Author
- Joel Lord
- [[http://www.javascripteverything.com/about][About the author]]
- [[http://www.javascripteverything.com/about][Javascript Everything]] author's blog
- [[https://github.com/joellord][GitHub]]
**** Author's Introduction
00:00 Hey everyone, welcome to this course on JSON web token authentication
with Node.JS.  The goal of this course is to introduce you to web-based
authentication using JWTs.

00:11 Through these few lessons, we will build a simple application that will
connect to a secured API and we will build an authentication server to provide
us with tokens that we need in order to connect and access those routes.

00:25 We will start slowly by building a simple web server using Express.  We
will then see how to make this API more flexible by introducing environment
variables, and then how to handle post request, and how to parse the body of
those requests.

00:40 At this point, we will be able to start building our authentication
server.  The server will validate the user credentials and provide those users
with a JSON web token.  Using this token, we will be able to go back to our API
and secure one of our routes so that only an authenticated user can access
those resources.

00:59 Finally, what would a back-end be without a good UI? We will build a
quick front-end that will connect to our API.  This UI will also collect user
credentials and send them over to the authentication server to fetch a JWT.

01:13 All this will be done using plain old vanilla JavaScript and none of
those fancy frameworks.  This will give you all the necessary tools to
implement this solution in any application you might build.

01:25 Of course, the examples in this course will be simple, and we will focus
more on the concepts rather than building a real secure API.  For that reason,
we will also show you how to switch your primitive authentication server to use
a proven solution.

01:40 In this lesson, you will be introduced to Auth0 as a solution to provide
secure identity management and federated log in to your users.  Go ahead, watch
this course, and learn how to build more secure applications right now.
*** Lesson 0---Package Setup
#+CINDEX:root directory @code{egghead-jwt-auth/}
#+CINDEX:@code{yarn init}
The course will be set up in a root directory ~egghead-jwt-auth~, with
~lesson#~ directories for each of the lessons 1 through 8.  The following shell
script checks for the existence of a ~package.json~ file in the root directory
~egghead-jwt-auth/~.  If one is found, it simply prints a message.  If one is
not found, then it initializes a new package using the ~yarn init~ command
using default values.  The lessons will add and install prerequisites to this
~package.json~ file.

{{{subheading(Tangle all Files)}}}

#+CINDEX:tangle
#+CINDEX:root directory
Tangle (export into files) all source code first.  This shell script creates
the root directory (~egghead-jwt-auth/~) and all ~lesson#/~ directories inside
of the root directory and all source code from Lessons 1 through 8.

#+NAME:tangle-files
#+BEGIN_SRC emacs-lisp :results output :exports both
(org-babel-tangle-file (buffer-file-name))
#+END_SRC

{{{subheading(Initialize @code{package.json})}}}

#+CINDEX:@code{package.json} file, initialize
#+CINDEX:@code{node_modules/} directory
#+CINDEX:@code{index.js} main file
#+CINDEX:@code{yarn init} command
Check for the ~package.json~ file in the root directory and create a new
package if one is not found.  Note that the =main= file is named ~index.js~ in
~package.json~.  Each of the ~lesson#/~ directories has its own ~index.js~ file
which will be called to run the code for that lesson.  All dependency files are
installed into the ~ndoe_modules/~ directory located in the root directory.
Only one ~node_modules/~ directory is created for all of the independent
~lesson#/~ directories.

#+caption:Package Initialization
#+name:package-init
#+begin_src sh :dir egghead-jwt-auth :results output :exports both
[ -e package.json ] && \
  echo "package.json has already been created" || \
  yarn --yes init
  echo;echo package.json; echo ------------
  cat package.json
  echo;echo listing;echo -------
  ls . lesson*
#+end_src
*** Lesson 1---Set Up an API Web Server in Node.js Using Express
#+CINDEX:Express web server
#+CINDEX:web server, Express
#+CINDEX:server, Express web
#+CINDEX:404 error
In this lesson, we build a very simple API Express server.  This API server
will have a single route that displays the current date and time and a handler
for =404= "Not Found" pages.

**** Setting Up A Little Express Server
#+CINDEX:Express server, build
#+CINDEX:@code{express} library
00:00 To build your first Express server, the first thing you need to do is to
import the Node.js ~express~ library into your API server.  In order for your
code to be able to use ~express~, you need to install it.  This program uses
~yarn~ to install all Node.js dependencies:

#+name:lesson1-package.json
#+begin_src sh :dir egghead-jwt-auth :results output :exports both
yarn add express
echo;echo package.json;echo ------------
cat package.json
#+end_src

#+CINDEX:@code{index.js}
: index.js
: --------

#+CINDEX:@code{express} library
#+name:require-express
#+begin_src js -n
const express = require("express");
#+end_src

{{{heading(Setup Constants)}}}

#+CINDEX:@code{PORT}, define
#+CINDEX:@code{API_PORT}, define
00:16 We'll go back to our code.  We'll declare a new constant ~app~ which will
use the ~express~ library that we've just included.  We'll also declare a new
constant for the =API_PORT= number.  We'll use =8888= for now.

#+name:app-express
#+begin_src js +n
const app = express();
#+end_src

#+name:api-port-8888
#+begin_src js +n
const API_PORT = 8888;
#+end_src

{{{heading(Setup Routes)}}}

{{{subheading(Status Route)}}}

#+CINDEX:route, define
#+CINDEX:@code{app.get}
#+CINDEX:status route
00:30 Then we can do our first route.  We'll use ~app.get~, and we'll specify
the name of the route.  In this case, we're using =status=, and it takes a
callback which has a request and a response as parameters.

#+name:api-status-route
#+begin_src js +n
app.get("/status", (req, res) => {
    const localTime = (new Date()).toLocaleTimeString();
    res.status(200).send(`Server time is ${localTime}.`);
});
#+end_src
{{{subheading(Catchall Route)}}}

#+CINDEX:catchall route
01:13 Let's also add a catchall route. We'll just use star (=*=), which means
any route that wasn't defined already.  01:19 It also takes a callback with a
request and response.  We can build our response here, and it will simply sense
that as =404=, or 'page not found'.

#+name:api-catchall-route
#+begin_src js +n
app.get("*", (req, res) => {
    res.sendStatus(404);
});
#+end_src

{{{heading(Start the App Listening)}}}

#+CINDEX:@code{app.listen}
#+CINDEX:app, run
01:30 Finally, we'll use ~app.listen~ to initialize our server.  It'll take a
=PORT=---which we've defined earlier---as a parameter, and a callback for on
success.  01:42 We'll simply say "Server is running on port", and we'll specify
the =PORT= number here.  You now have your first express server.

#+name:app-listen
#+begin_src js +n
app.listen(API_PORT, () => {
    console.log(`Server is running on port ${API_PORT}.`);
});
#+end_src

**** Testing the Server

This Makefile sets up some commands to run specific lessons.  Each lesson's
server can be started by moving into the root directory (~egghead-jwt-auth/~)
and running the ~make~ command with the lesson number (1-8):
: make lesson# where =#= is one of 1..8.

Thereafter, specific commands can be run from a different terminal, such as:
: make open-browser-status

#+BEGIN_SRC sh :mkdirp yes :tangle egghead-jwt-auth/Makefile
FORCE:

.phony : lesson1
lesson1 : FORCE
	node lesson1

#+END_SRC

01:53 If we go back to our terminal, we can start the server by using Node from
the root directory:
: make lesson1

We've got our server running.

These three Makefile rules provide easy commands to open different routes in
your default browser:

#+BEGIN_SRC sh :tangle egghead-jwt-auth/Makefile
.phony: open-browser
open-browser :
	open http://localhost:8888/

.phony: open-browser-status
open-browser-status :
	open http://localhost:8888/status/

.phony: open-browser-random
open-browser-random :
	open http://localhost:8888/random/

#+END_SRC

#+CINDEX:@code{Page Not Found} error
02:02 Now if we go through our browser window, we can type in the
~localhost:8888~.  We'll get a 'page not found' because that route was not
defined.
: make open-browser

#+CINDEX:status route
02:10 We can use =/status= to get the server time, and any other page will give
us a =404= error.
: make open-browser-status
: make open-browser-random

That's it.  You've got your first Express server up and running.
**** Express Server Index.js Code
#+caption:Lesson 1 ~index.js~
#+name:lesson01-index.js
#+begin_src js -n :tangle egghead-jwt-auth/lesson1/index.js :mkdirp yes :noweb yes
<<require-express>>
<<app-express>>

<<api-status-route>>
<<api-catchall-route>>

<<api-port-8888>>
<<app-listen>>
#+end_src

*** Lesson 2---Set the Server Port in Express Using an Environment Variable
#+CINDEX:environment variables
In this lesson we learn how to use an environment variable to set the port of
an express server.

**** Use ~process.env~ to Set the =PORT= Variable
#+CINDEX:@code{process.env}
#+CINDEX:@code{PORT} environment variable, set
00:00 We'll change the =PORT= that this server is using.  We'll use
~process.env~ to access the environment variables from our ~index.js~, and then
we'll create a new variable called =PORT=.  If the =PORT= environment variable
is not defined, we'll still use =8888= as a default.

: index.js
: ----------
#+name:port-env-or-assign
#+begin_src js -n
const PORT = process.env.PORT || 8888;
#+end_src

**** Testing the =PORT= Assignment
00:15 If you run this server, we see that the server is running on =port 8888=.
If we do an ~export~ in our terminal and we set the =PORT= environement
variable for our operating system to say =3000=
: export PORT=3000
{{{noindent}}}and we run this server again, we can see that the server is now
running on ~port 3000~.

00:34 If we open our browser, we go to =localhost:8888=, it can't be
reached.  If we go to =3000=, we're getting a =404= in this case.  If we go to
=localhost:3000/status=, we are getting the server time.

00:48 That's how you set the =PORT= inside an environment variable.

**** Lesson 2 ~index.js~ Code
#+caption:Lesson 2 ~index.js~
#+name:lesson2-index.js
#+begin_src js -n :tangle egghead-jwt-auth/lesson2/index.js :mkdirp yes :noweb yes
<<require-express>>
<<app-express>>
<<port-env-or-assign>>

<<api-status-route>>
<<api-catchall-route>>

<<app-listen>>
#+end_src

{{{heading(Adding a Makefile Rule for Lesson 2)}}}

From within the root directory (~egghead-jwt-auth/~) run the command:
: make lesson2
to start the server.  Then type:
: open-browser-3000
: open-browser-status-3000
: open-browser-random-3000
to test.

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson2
lesson2 : FORCE
	(export PORT=3000; node lesson2)
.phony : open-browser-3000
open-browser-3000 :
	open http://localhost:3000/
.phony : open-browser-status-3000
open-browser-status-3000 :
	open http://localhost:3000/status/
.phony : open-browser-random-3000
open-browser-random-3000 :
	open http://localhost:3000/random/
#+end_src

*** Lesson 3---Add a =POST= Route To Express And Parse the Body
#+CINDEX:POST requests
#+CINDEX:@code{body-parser}
In this lesson, we see how to handle =POST= requests on our server and we
extract the data that was passed in the body of the requests using
~body-parser~.

**** Add a =POST= Method to ~index.js~
#+CINDEX:POST method
#+CINDEX:user login
#+CINDEX:login route
00:01 In order to handle our first post request, we will use Express' =POST=
method.  We will create a route that handles user logins.

#+CINDEX:request
#+CINDEX:response
00:08 The first argument is a route, which is =/login= in our case.  The second
argument is a callback with the =request= and =response= arguments.

#+CINDEX:username property
#+CINDEX:JSON object
#+CINDEX:post login route
00:15 Let's now define a constant that will contain the name of the user that
was posted to this route.  The constant name =user= will have the value of the
=username= property that was passed in our =request= as a JSON object.

#+name:post-route
#+begin_src js -n
app.post("/login", (req, res) => {
    const user = req.body.username;

#+end_src

**** Add ~body-parser~ Middleware
#+CINDEX:middleware, body-parser
#+CINDEX:body-parser middleware
00:27 At this point, Express can't read the body of the request.  We will need
to ~require~ an additional middleware called ~body-parser~.

#+name:require-body-parser
#+begin_src js -n
const bodyParser = require("body-parser");
#+end_src

We also go into the terminal to install this new library.

#+name:install-body-parser
#+begin_src sh :dir egghead-jwt-auth :results output :exports both
yarn add body-parser
#+end_src

: package.json
: ------------
#+begin_src sh :dir egghead-jwt-auth :results output :exports results
cat package.json
#+end_src

#+CINDEX:use method, express
#+CINDEX:JSON responses
00:40 Now that it's installed, we can add the middleware to Express using the
=use= method.  We will specify that it will handle JSON responses.

#+name:app-use-body-parser
#+begin_src js -n
app.use(bodyParser.json());
#+end_src

**** Build the =response=
#+CINDEX:response, post request
#+CINDEX:200 status
#+CINDEX:status 200
#+CINDEX:success status 200
00:49 We are now able to read the =request= body, so our constant contains the
=username= that was passed into login route.  We are ready to build our
=response=, which has a status of =200= because this is a success.

01:01 We will send back a simple string that says, "You logged in with
username: ${user}".  It will display the =username= that we just received.

#+name:post-route-res
#+begin_src js -n
    res
    .status(200)
    .send(`You logged in with username: "${user}"`);
});
#+end_src

**** Start the Server
01:08 Let's start our server using ~node~.  From the root directory type:
: make lesson3

#+name:Makefile
#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson3
lesson3 : FORCE
	(export PORT=3000;node lesson3)
#+end_src

The server is now listening on =localhost:3000=, which was defined as an
environment variable previously.

**** Test the Server
#+CINDEX:Postman
#+CINDEX:@command{curl}
01:18 To test this new route, we can use Postman (or ~curl~).  If we try to do
a =GET= request to =/status=, we should get the local time:
: make open-browser-status-3000

#+CINDEX:POST request
#+CINDEX:@code{username} property
#+CINDEX:Content-Type
#+CINDEX:application/json
01:28 Now, we can do a =POST= request to the =/login= route.  Let's start by
specifying the body of our request.  It will be a JSON object with a =username=
property.  Make sure that you change the Content-Type to =application/json=.

#+name:Makefile
#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : post-login
post-login : FORCE
	curl \
	  --header Content-Type:application/json \
	  --data   '{"username":"admin"}' \
	  http://localhost:3000/login \
#+end_src

#+CINDEX:parse POST request
01:43 If we run this, you get a, "You logged in with username: \"admin\""
message.  That is how you parse a =POST= request and handle the =request= data.

**** Lesson 3 ~index.js~ Code
#+caption:Lesson 3 ~index.js~
#+name:lesson3-index.js
#+begin_src js :tangle egghead-jwt-auth/lesson3/index.js :mkdirp yes :noweb yes
<<require-express>>
<<require-body-parser>>

<<app-express>>
<<app-use-body-parser>>

<<api-status-route>>
<<post-route>>
<<post-route-res>>
<<api-catchall-route>>

<<port-env-or-assign>>
<<app-listen>>
#+end_src

*** Lesson 4---Provide Users With A JSON Web Token
#+CINDEX:token issuer
#+CINDEX:JSON web token
In this lesson, we will build a token issuer that will return a JSON Web
Token.  This simple server will have a single endpoint for login that queries a
list of users and returns a web token for the matching user.

**** The User Database
#+CINDEX:authentication server
#+CINDEX:user database
#+CINDEX:user array
00:00 Since this lesson is all about creating an authentication server, let's
start by creating a user database.  We will use a user array that contains all
of our users and store the passwords in plain text right now.

#+CINDEX:warning
00:11 Warning, do not do this in production.  You should always encrypt
passwords and ensure that no sensitive information about your users is
accessible to potential hackers.  For the sake of this lesson, let's just do it
this way.

#+name:users-array
#+begin_src js -n
const users = [
    {id: 1, username: "admin", password: "admin"},
    {id: 2, username: "guest", password: "guest"}
];
#+end_src

**** Authentication Route
#+CINDEX:@code{/login} route
#+CINDEX:@code{POST} request
#+CINDEX:user authentication
00:26 We can now start with our =/login= =POST= request.  This is the request
that will handle user authentication.  The first thing to check is if the
request is formatted correctly.  We are expecting both a username and a
password.

#+CINDEX:400 status
#+CINDEX:status 400
#+CINDEX:invalid request, status 400
00:45 If we don't have both, we =return= a status code of =400= for invalid
request, and we =send= a message to the user, saying that "You need a username
and password".  We can then do a ~return~ to stop the execution of this
callback.

#+CINDEX:@code{find} method
01:08 Now, if we have a valid request, we need to check if the user is in our
database.  Using the =find= method, we will check if we have a user that has a
=username= and =password= that matches those in the =request=.

#+CINDEX:401 status
#+CINDEX:status 401
#+CINDEX:unauthorized request
01:20 If we find a matching user, it will be stored in a constant, ~user~.  If
we can't find a matching user, we can send a response with the status of =401=
for =unauthorized=.  We can also ~send~ a message to the user, saying "User not
found".  Once again, we ~return~ to stop the execution of this callback.

#+name:authentication-login
#+begin_src js -n
app.post("/login", (req, res) => {
    if (!req.body.username || !req.body.password) {
        res
        .status(400)
        .send("You need a username and password");
        return;
    }

    const user = users.find((u) => {
        return u.username === req.body.username && u.password === req.body.password;
    });

    if (!user) {
        res
        .status(401)
        .send("User not found");
        return;
    }

#+end_src

**** Create a JWT for a Valid User
#+CINDEX:JSON web token
01:45 If we have a valid user, we will send back a JSON web token as a
response.

#+CINDEX:@code{jsonwebtoken} library
In order to do so, we will need to ~require~ the ~jsonwebtoken~ library.  We will
also need to install it using ~yarn add jsonwebtoken~.

#+name:require-jsonwebtoken
#+begin_src js -n
const jwt = require("jsonwebtoken");
#+end_src

#+begin_src sh :dir egghead-jwt-auth :results output :exports both
yarn add jsonwebtoken
#+end_src

: package.json
: ------------
#+begin_src sh :results output :exports both :dir egghead-jwt-auth
cat package.json
#+end_src

#+CINDEX:@code{sign} method
#+CINDEX:sign token
#+CINDEX:payload
#+CINDEX:secret key
02:13 Now that it's installed, we can use the =sign= method to create a sign
token.  We start by passing the payload we want to attach in the =jwt=.  We
then pass a string which is the =secret key=.  In this case, it's
"mysupersecretkey".

#+CINDEX:options
#+CINDEX:access_token
02:34 Finally, we can pass some options like in how much time this token will
expire, so we'll say expires in three hours for us.  Finally, we can send back
our response with a status of =200= and a JSON object with our =access_token=.

#+name:create-access-token
#+begin_src js -n
      const token = jwt.sign(
        {
          sub: user.id,
          username: user.username
        }, "mysupersecretkey", {expiresIn: "3 hours"}
      );

      res
       .status(200)
       .send({access_token: token});
  });
#+end_src

**** Testing the Lesson 4 Server
#+CINDEX:authentication server, run
03:01 We can now run the authentication server using node and the name of the
file.

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson4
lesson4 : FORCE
	(export PORT=3000;node lesson4)
#+end_src

Let's now open Postman (use ~curl~) to test this out.

03:10 If we try a =GET= request on the server, we're getting a =404= because we
haven't defined any =GET= route on the server.

#+begin_src sh :dir egghead-jwt-auth
make open-browser-status-3000
#+end_src

Let's change that to a =POST= and use the =/login= endpoint that we just
created.  Sending a ~request~ to that URL without a body will give us a =400= with a
message, "You need a username and password."  Let's try to add those.

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : wrong-auth-login
wrong-auth-login :
	curl \
	  --header Content-Type:application/json \
	  --data   '{"username":"Felix","password":"the-cat"}' \
	  http://localhost:3000/login \

.phony : auth-login
auth-login :
	curl \
	  --header Content-Type:application/json \
	  --data   '{"username":"admin","password":"admin"}' \
	  http://localhost:3000/login \

#+end_src

03:29 For the =body=, select =raw= and make sure that the =type= is set to
=application/json=.  You can now type in a =username= and =password= in JSON
format.  If we type a wrong password, we should be getting the "User not found"
message.  If we fix the password to use the right one, we get our JSON object
with an =access_token=.

03:56 You can copy and paste this JSON web token in a website like ~jwt.io~ and
you will be able to see the content.  If you try it with another user like
=guest=, you will get a different =access_token=, and if we go into ~jwt.io~,
we can once again see all of the content and we can see that it's different
this time.

04:28 That's it.  You have now created your first authentication server.

**** Lesson 4 ~index.js~ Code
#+caption:Lesson 4 ~index.js~ Code
#+name:lesson4-index.js
#+begin_src js :tangle egghead-jwt-auth/lesson4/index.js :mkdirp yes :noweb yes
<<require-express>>
<<require-body-parser>>
<<require-jsonwebtoken>>

<<app-express>>
<<app-use-body-parser>>
<<users-array>>

<<api-status-route>>
<<authentication-login>>
<<create-access-token>>
<<api-catchall-route>>

<<port-env-or-assign>>
<<app-listen>>
#+end_src

*** Lesson 5---Allow CORS in Node.js and Expres
In this quick lesson, we see how to add the CORS middleware so that our Express
server can handle requests from different origins.

**** The CORS Prohibition
#+CINDEX:CORS prohibition
00:00 If you have an API that runs on a different server or even a different
port than your application, and you try to do a ~fetch~, you should see a
message in your console complaining about
=Access-Control-Allow-Origin=.[fn::Safari allows such a fetch, but Google
Chrome does not.]

[[file:./resources/cors-error-50.png]]

**** The Fix to the CORS Prohibition
00:19 The fix for this in your Express server is very simple.

#+CINDEX:@code{cors} library
First of all, you need to require the CORS library:

#+name:require-cors
#+begin_src js -n
const cors = require("cors");
#+end_src

Secondly, you need to tell your Express server to use this middleware by using
~app.use~ and the library that we've just installed.

#+name:app-use-cors
#+begin_src js +n
app.use(cors());
#+end_src

#+CINDEX:@code{express-jwt} library
Thirdly, use a different JSON web token library, ~express-jwt~, which the author
does not explain here, but explains in the next lesson.

#+name:require-expressjwt
#+begin_src js +n
const expressjwt = require("express-jwt");
#+end_src

#+name:jwtCheck
#+begin_src js +n
const jwtCheck = expressjwt({secret: "mysupersecretkey"});
#+end_src

<<add-express-jwt>>You'll also need to install both using ~yarn add~:

#+begin_src sh :dir egghead-jwt-auth :results output :exports both
yarn add cors express-jwt
#+end_src

Our ~package.json~ now looks like this:

: package.json
: ------------
#+begin_src sh :dir egghead-jwt-auth :results output :exports results
cat package.json
#+end_src

**** Start Lesson 5 Server Running
00:46 Now, if you restart your server and try the same ~fetch~ call in your
browser, you won't have that CORS error any more.

Start the server for this lesson with:
: make lesson5

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson5
lesson5 : FORCE
	(export PORT=3000;node lesson5;)
#+end_src

[[file:./resources/cors-fix-50.png]]

**** Set Up Two New Routes for Public and Private Resources
Two new routes will be added here, and explained in the next lesson.

#+name:public-resource-route
#+begin_src js -n
app.get("/resource", (req, res) => {
    res
    .status(200)
    .send("Public resource; okay to see");
});

#+end_src

#+name:private-resource-route
#+begin_src js +n
app.get("/resource/secret", jwtCheck, (req, res) => {
    res
    .status(200)
    .send("Secret resource; you should be logged in to see this.");
});

#+end_src

**** Lesson 5 ~index.js~ Code
Here is the code for Lesson 5 in ~index.js~.  The two routes will be explained
in the next lesson.

#+name:Lesson5-index.js
#+begin_src js :tangle egghead-jwt-auth/lesson5/index.js :mkdirp yes :noweb yes
<<require-express>>
<<require-body-parser>>
<<require-cors>>
<<require-expressjwt>>
<<jwtCheck>>

<<app-express>>
<<app-use-body-parser>>
<<app-use-cors>>

<<public-resource-route>>
<<private-resource-route>>
<<api-catchall-route>>

<<port-env-or-assign>>
<<app-listen>>
#+end_src

*** Lesson 6---Authenticate Users With JWT for Access to Protected Resources
In this lesson, we build a simple API with two endpoints, one public and one
secure.  Using JWT and validating with the signature, we ensure that the user is
authorized and has access to a protected resource before serving it.

**** Create Two Resource Routes
00:00 In this lesson, we will create an API with two routes.  The first one for
the ~/resource~ endpoint will be public, and simply return a status of =200=, and
a message saying, "Public resource, you can see this".

#+begin_src js -n :noweb yes
<<public-resource-route>>
#+end_src

00:22 Our second route will be for the ~/resource/secret~ endpoint.  This will
be a secured route.  For this endpoint, we will return a =200=, as well as a
message that says, "Secret resource, you should be logged in to see this."

#+begin_src js +n :noweb yes
<<private-resource-route>>
#+end_src

**** Create an =API_PORT= Environment Variable
00:42 This server will run on the port specified by the environment variable
=API_PORT=.  Let's go into our terminal, set this using ~export~, and set the
=API_PORT= to =5000=.  Now, we can run the server by using ~node~ and the name
of the file.
: make lesson6

#+name:api-port
#+begin_src js -n
const API_PORT = process.env.API_PORT;
#+end_src

#+name:app-listen-api-port
#+begin_src js +n
app.listen(API_PORT, () => console.log(`API Server is running on port ${API_PORT}`))
#+end_src

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson6
lesson6 : FORCE
	(export API_PORT=5000;node lesson6;)
#+end_src

**** Test the Server
01:00 To test our API, we will use Postman.  If we go to ~localhost:5000~,
we're getting a =404=, =page not found=, because that route was not defined.  If we
try ~localhost:5000/resource~, we should see our public resource there.  If we try
~localhost:5000/resource/secret~, we can also see the content of this resource.

**** Block the Secret Resource Route
#+CINDEX:@code{express-jwt}
#+CINDEX:block protected routes
#+CINDEX:middleware
Our next step will be to block those requests by requesting a valid JSON web
token.  To do so, we will require the ~expressjwt~ middleware.

#+begin_src js :noweb yes
<<require-expressjwt>>
#+end_src

01:39 Let's now open a terminal, and install it, using ~yarn~[fn::this was done
in the prior lesson] [[add-express-jwt][express-jwt]].

#+CINDEX:@code{express-jwt} initialization
Good.  Now, let's define this middleware.  We can initialize this middleware by
using ~expressjwt~ and passing it some options.  If you are using a real
authentication server, you'd want to check for the =issuer=, the =audience=,
and more to validate the integrity of the server.

02:01 In our case, we will only check to see if the signature matches the one
from our authentication server, "mysupersecretkey", in this case.

#+begin_src js -n :noweb yes
<<jwtCheck>>
#+end_src

Finally, we can secure our private route by adding the middleware as the second
argument of our =app.get= method.

#+begin_src js -n :noweb yes
<<private-resource-route>>
#+end_src

**** Testing the Server with a Protected Route
We are now ready to restart our server and test it in Postman.

02:24 Now, if we try a protected route again, we see that we're getting an
error message, saying that no authorization token was found.

[[file:./resources/postman-unauthorized-get-40.png]]

Let's go to the Authorization section, and select a =Bearer Token= type of
authentication.

[[file:./resources/bearer-token-authentication-type-50.png]]

02:38 We can take a valid token from ~jwt.io~ in this case[fn::After first
entering the secret key "mysupersecretkey" in the =verify signature= box
[[file:./resources/jwt.io-secret-key-25.png]]], and simply paste that in the token
box in Postman.
: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6Ikp\
: vaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.oGFhqfFFDi9sJMJ1U2dWJZNYEiUQBEtZRVuwKE7Uiak

We can now try to make our call to =/resource/secret= again, and we can now see
the content of this route.  Now, you have an API with a secured endpoint.

[[file:./resources/postman-with-bearer-token-40.png]]

**** Lesson 6 ~index.js~ Code

#+caption:Lesson 6 ~index.js~ Code
#+name:Lesson6-index.js
#+begin_src js :tangle egghead-jwt-auth/lesson6/index.js :noweb yes :mkdirp yes
<<require-express>>
<<require-body-parser>>
<<require-cors>>
<<require-expressjwt>>
<<jwtCheck>>

<<app-express>>
<<app-use-cors>>
<<app-use-body-parser>>

<<public-resource-route>>
<<private-resource-route>>
<<api-catchall-route>>

<<api-port>>
<<app-listen-api-port>>
#+end_src

*** Lesson 7---Connect a Front-End to a Secure API using JWTs
In this lesson, we add the login form to a single page application and we pass
our tokens to the API.  Should the token be valid, we will have access to the
data from the secure endpoint in the API.

**** The Single Page Application
{{{heading(File ~index.html~)}}}

#+name:index.html
#+begin_src html -n :tangle egghead-jwt-auth/lesson7/index.html :mkdirp yes :noweb tangle
<html>
    <head>

        <<link-stylesheet>>

    </head>

    <body>

        <<container>>
        <<modal>>
        <<cdn-scripts>>

        <<app-scripts>>

    </body>
</html>
#+end_src

{{{subheading(Section ~<head>~)}}}

#+name:link-stylesheet
#+begin_src html
<link rel="stylesheet"
      href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
      integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm"
      crossorigin="anonymous">
#+end_src

{{{subheading(Section ~<body>~)}}}

{{{subheading(Container)}}}

#+name:container
#+begin_src html :noweb yes
<div class="container container-fluid">
    <<navbar>>
    <<mainPage>>
    <<secret-unauthorized-Pages>>
</div>

#+end_src

#+name:navbar
#+begin_src html :noweb yes
<nav class="navbar navbar-expand-lg navbar-light bg-light">
    <<navbar-a>>
    <<navbar-toggler>>

    <<navbar-collapse>>
</nav>

#+end_src

#+name:navbar-a
#+begin_src html
<a class="navbar-brand" href="#">Secure your SPA</a>
#+end_src

#+name:navbar-toggler
#+begin_src html
<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
</button>
#+end_src

#+name:navbar-collapse
#+begin_src html :noweb yes
<div class="collapse navbar-collapse" id="navbarSupportedContent">
    <<navbar-collapse--nav>>
    <<navbar-collapse--form>>
</div>
#+end_src

#+name:navbar-collapse--nav
#+begin_src html
<ul class="navbar-nav mr-auto">
    <li class="nav-item active" data-route="#">
        <a class="nav-link" href="#">Home</a>
    </li>
</ul>
#+end_src

#+begin_comment
For Lesson 8, change the modal-login-button to remove the data-toggle and data-target
Create something like <<login-button>> instead
#+end_comment

#+name:navbar-collapse--form
#+begin_src html :noweb yes
<form class="form-inline">
    <<modal-login-button>>
    <<logout-button>>
</form>
#+end_src

#+begin_comment
Remove the data-toggle and data-target for Lesson 8
#+end_comment

<<modal-login-button>>
#+name:modal-login-button
#+begin_src html
<button class="btn btn-outline-success my-2 my-sm-0" data-toggle="modal" data-target="#loginModal" type="button" id="loginModalBtn">Login</button>&nbsp;
#+end_src

#+name:logout-button
#+begin_src html
<button class="btn btn-outline-danger d-none" id="logoutBtn">Logout</button>
#+end_src

#+name:mainPage
#+begin_src html
<span id="mainPage">

    <div class="row">
        <div class="col-1"></div>
        <div class="col-10 text-center">
            <p>Welcome to the headline generator application.  Click on the buttons to get a headline</p>
        </div>
        <div class="col-1"></div>
    </div>

    <div class="row">
        <div class="col-12 text-center">
            <button class="btn btn-lg btn-primary" id="headline">Public</button>&nbsp;
            <button class="btn btn-lg btn-secondary" id="secret">Private</button>
        </div>
    </div>

    <div class="row">&nbsp;</div>

    <div class="row">
        <div class="col-2"></div>
        <div class="col-8">
            <div class="alert alert-dark" style="overflow-wrap: break-word">
                Test the API
            </div>
        </div>
        <div class="col-2"></div>
    </div>

    <div class="row justify-content-center">
        <div class="col-4 text-center">
            <img src="http://http.cat/200" id="httpcat" width="350px"/>
        </div>
    </div>
</span>

#+end_src

#+name:secret-unauthorized-Pages
#+begin_src html
<span id="secretPage" class="d-none">
    This is a secret area!
</span>

<span id="unauthorizedPage" class="d-none">
    You are not authorized to see this page.
</span>

#+end_src

{{{subheading(Modal)}}}

#+name:modal
#+begin_src html
<div class="modal fade" id="loginModal" tabindex="-1" role="dialog">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Modal title</h5>
                <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                    <span aria-hidden="true">&times;</span>
                </button>
            </div>
            <div class="modal-body">
                <form>
                    <div class="form-group">
                        <label for="username">Username</label>
                        <input type="text" class="form-control" id="username">
                    </div>
                    <div class="form-group">
                        <label for="password">Password</label>
                        <input type="password" class="form-control" id="password">
                    </div>
                </form>
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                <button type="button" class="btn btn-primary" data-dismiss="modal" id="loginBtn">Login</button>
            </div>
        </div>
    </div>
</div>

#+end_src

{{{subheading(Scripts)}}}

#+name:cdn-scripts
#+begin_src html
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
#+end_src

#+name:app-scripts
#+begin_src html
<script src="./ui-update.js"></script>
<script src="./index.js"></script>
#+end_src

**** The Helper Functions in UI-Update
<<ui-update-buttons>>
#+name:ui-update-loggedIn
#+begin_src js :exports none
UIUpdate.loggedIn = function(token) {
  UIUpdate.alertBox(`Just logged in<br>Token:<br>${localStorage.getItem("access_token")}`);
  loginModalBtn.classList.add("d-none");
  logoutBtn.classList.remove("d-none");
};
#+end_src

#+name:ui-update-loggedOut
#+begin_src js :exports none
UIUpdate.loggedOut = function() {
  localStorage.removeItem("access_token");
  loginModalBtn.classList.remove("d-none");
  logoutBtn.classList.add("d-none");
};
#+end_src

#+name:ui-update-helper-functions
#+begin_src js :exports none
UIUpdate.routeChange = function() {
  if (document.querySelector(".navbar-nav li.active")) {
    document.querySelector(".navbar-nav li.active").classList.remove("active");
  }
  document.querySelector(".navbar [data-route='#" + window.location.hash.replace("#", "") + "']").classList.add("active");
};

UIUpdate.updateCat = function(status) {
  const httpCat = document.querySelector("#httpcat");
  httpCat.src = "http://http.cat/" + status;
};

UIUpdate.alertBox = function(message) {
  const alertBox = document.querySelector(".alert");
  alertBox.innerHTML = message;
};

UIUpdate.getUsernamePassword = function() {
  return {
    username: document.querySelector("#username").value,
    password: document.querySelector("#password").value
  }
};
#+end_src

#+name:ui-update.js
#+begin_src js -n :tangle egghead-jwt-auth/lesson7/ui-update.js :mkdirp yes :noweb yes
let UIUpdate = {};

<<ui-update-loggedIn>>

<<ui-update-loggedOut>>

<<ui-update-helper-functions>>

window.addEventListener("hashchange", UIUpdate.routeChange);
#+end_src

**** The Authentication Server
#+name:auth.js
#+begin_src js -n :tangle egghead-jwt-auth/lesson7/auth.js :mkdirp yes :noweb yes
<<require-express>>
<<require-body-parser>>
<<require-jsonwebtoken>>
<<require-cors>>
<<users-array>>

<<app-express>>
<<app-use-body-parser>>
<<app-use-cors>>

<<authentication-login>>
<<create-access-token>>
<<api-catchall-route>>

<<port-env-or-assign>>
<<app-listen>>
#+end_src

**** The API Server
#+name:api.js
#+begin_src js -n :tangle egghead-jwt-auth/lesson7/api.js :mkdirp yes :noweb yes
<<require-express>>
<<require-body-parser>>
<<require-cors>>
<<require-expressjwt>>
<<jwtCheck>>

<<app-express>>
<<app-use-body-parser>>
<<app-use-cors>>

<<public-resource-route>>
<<private-resource-route>>
<<api-catchall-route>>

<<api-port>>
<<app-listen-api-port>>
#+end_src

**** Install Static Server ~httpster~
To set up a static file server for the front end, install ~httpster~ from NPM.
To start the server using =PORT 5000=, use
: yarn run httpster -p 5000 -d lesson7
from inside the root directory (~egghead-jwt-auth/~).

To start all of the servers (~auth~, ~api~, and ~frontend~), run the ~make~
command ~make lesson7~.  To terminate all of the servers, run the ~make~
command ~make kill~.  The ~auth~ server will run on =PORT 3000= while the ~api~
server will run on =PORT 3333=.

#+begin_src sh :results output :exports both :dir egghead-jwt-auth
yarn add httpster --dev
#+end_src

: package.json
: ------------
#+begin_src sh :results output :exports both :dir egghead-jwt-auth
cat package.json
#+end_src

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson7
lesson7 : FORCE
	yarn run httpster -d lesson7 -p 5000 &
	export PORT=3000;node lesson7/auth.js &
	export API_PORT=3333;node lesson7/api.js &

.phony : kill
kill :
	pkill node
#+end_src

**** Framework of the Front End Connection
#+name:index.js
#+begin_src js -n :noweb tangle :tangle egghead-jwt-auth/lesson7/index.js
/* To run this file on a server, we are using httpster.
Type `httpster index.html -p 5000` in your console to start the server. */

<<api-url>>
<<auth-url>>

<<access-token>>

const headlineBtn = document.querySelector("#headline");
const secretBtn = document.querySelector("#secret");
const loginBtn = document.querySelector("#loginBtn");
const logoutBtn = document.querySelector("#logoutBtn");

<<headlineBtn.addEventListener>>

<<secretBtn.addEventListener>>

<<loginBtn.addEventListener>>

<<logoutBtn.addEventListener>>

#+end_src
**** Connect the Front End to the API Server
#+CINDEX:api server
00:00 To connect our front-end to our API in our authentication server, we
first need the URL for those.  In this case, I started the API on port 8888, so
we can add that to a constant.

#+name:api-url
#+begin_src js
const API_URL = "http://localhost:3333";
#+end_src

#+CINDEX:authentication server
00:18 The authentication server is also running at =http://localhost:3000=.
Let's add this to the =AUTH_URL= constant.

#+name:auth-url
#+begin_src js
const AUTH_URL = "http://localhost:3000";
#+end_src

#+CINDEX:@code{ACCESS_TOKEN}
We will keep the =ACCESS_TOKEN= from our authentication server stored in
memory.  For now, we can initialize the =ACCESS_TOKEN= constant to =undefined=.

#+name:access-token
#+begin_src js
let ACCESS_TOKEN = undefined;
#+end_src

**** Look at the Prebuilt Front End
#+CINDEX:front end
#+CINDEX:jumbotron
#+CINDEX:AJAX calls
00:36 Let's take a look at the front-end that was pre-built for us.  There is a
button labeled =public=, and another labeled =private=.  They will both update
the jumbotron beneath it with the response that we're getting from our AJAX
calls.

[[file:./resources/prebuilt-frontend-25.png]]

#+CINDEX:helper functions
#+CINDEX:@code{UI_Updates}
00:50 The image of the cat will also be updated with the status code that we
are getting from the server.  For the =UIUpdate= functions, all of the helper
functions are already created.  We will focus on the actual logic in here.

**** Set Up Buttons in Front End

{{{heading(The PUBLIC Button)}}}

#+CINDEX:public button
01:03 For now, none of the buttons do anything.  Let's go back to our code in
~index.js~.

#+CINDEX:@code{/resource} endpoint
#+CINDEX:API server
The variable =headlineBtn= holds a reference to the button labeled =public=.
We will start by doing a ~fetch~ to our public ~/resource~, which is on the API
server at the ~/resource~ endpoint.

#+CINDEX:@code{fetch}
#+CINDEX:promise, from @code{fetch} call
01:23 ~fetch~ returns a promise, so we will use the ~then~ method with the
response and we will return the result of =resp.text=.  This will return the
actual data in text format to the next chained ~.then~ method.

#+CINDEX:jumbotron
#+CINDEX:@code{UI_Update} object
01:40 Finally, we can use the =UIUpdate= object and the ~alertBox~ method to update
the jumbotron with the data from our response.

#+name:headlineBtn.addEventListener
#+begin_src js -n
  headlineBtn.addEventListener("click", () => {
          fetch(`${API_URL}/resource`).then(resp => {
              UIUpdate.updateCat(resp.status);
              return resp.text();
          }).then(data => {
              UIUpdate.alertBox(data);
          });
  });
#+end_src

{{{subheading(Test the PUBLIC Button)}}}

01:51 We are ready to test our first AJAX call.  Clicking on the =public=
button shows the public resource.  You can see this message.  That works.

{{{heading(The PRIVATE Button)}}}

#+CINDEX:private button
02:00 Let's now move on to the second button, the one labeled =private=.  In
here, we will do a very similar code.  We start by doing a ~fetch~ to the
=API_URL= and ~/resource/secret~ URL.  We return the ~.text~ from the response
and we update our jumbotron the same way we did for the public button.

#+begin_src js -n
  secretBtn.addEventListener("click", (event) => {
          fetch(`${API_URL}/resource/secret`).then(resp => {
              UIUpdate.updateCat(resp.status);
              return resp.text();
          }).then(data => {
              UIUpdate.alertBox(data);
          });
  });
#+end_src

{{{subheading(Test the PRIVATE Button)}}}

#+CINDEX:authorization header
02:25 If we go and test this, we will see that we are getting an error message
instead of the actual response that we are expecting.  That is due to the fact
that we have not passed in an authorization header.

#+CINDEX:@code{UIUpdate.updateCat} method
#+CINDEX:@code{resp.status} code
02:35 Now that we know that this URL will sometimes return us an error code,
let's update our =httpCat= with the response that we get from the server.
Before we return the parse body of our response, we can use the
=UIUpdate.updateCat= method with the =resp.status= code.

#+begin_src js
  secretBtn.addEventListener("click", (event) => {
          fetch(`${API_URL}/resource/secret`).then(resp => {
              UIUpdate.updateCat(resp.status);
              return resp.text();
          }).then(data => {
              UIUpdate.alertBox(data);
          });
  });
#+end_src

#+CINDEX:401 error code
#+CINDEX:unauthorized access
02:52 If we try this again, we see that we're getting a =401=, which is the error
code for an =unauthorized access=.

**** Authentication
#+CINDEX:authenticate
#+CINDEX:login
#+CINDEX:@code{LOGIN} button
#+CINDEX:authorization server
03:00 Before we can pass in a token with our request, we will need to
authenticate.  Let's go to the =login= button click event listener and do a
=POST= request to our authorization server.

#+CINDEX:Content-Type
#+CINDEX:application/json
#+CINDEX:request headers
#+CINDEX:headers, request
#+CINDEX:accept header
03:12 In here, we will do a request to the =${AUTH_URL}/login= endpoint.  We
will also specify a few options with our request.  First, this is not a =GET=,
so we will need to add method =POST=; then we need to specify the headers to
tell our server that we are sending =Content-Type:"application/json"=.

#+CINDEX:@code{UIUpdate} helper object
03:31 We need to specify that we are ~accepting~ a response type of
"application/json".  The body of our request will be the =username= and
=password= in JSON format provided by our =UIUpdate= helper object.

#+CINDEX:@code{httpCat}
03:47 We will update our =httpCat= with the ~resp.status~ code.  If we get a
=200=, we will send the JSON object from our response to the next promise.  If
our response was anything else, we will use the text of the response.

#+CINDEX:@code{ACCESS_TOKEN}
04:01 We can then chain with another ~.then~ and verify the presence of an
=ACCESS_TOKEN=.  If we have one, we can store the =ACCESS_TOKEN= in the
=ACCESS_TOKEN= variable that we defined in the beginning.

#+CINDEX:@code{UIUpdate.loggedIn} method
04:22 We can also overwrite the content of data with =ACCESS_TOKEN=: and the
content of the token.  If we have an =ACCESS_TOKEN=, this means that we are
logged in, so we can use the ~UIUpdate.loggedIn~ method to update our UI.

#+CINDEX:jumbotron
04:43 Finally, we will update our jumbotron with our data variable.

<<loginBtn>>
#+name:loginBtn.addEventListener
#+begin_src js -n
  loginBtn.addEventListener("click", (event) => {
      fetch(`${AUTH_URL}/login`, {
          method: "POST",
          headers: {
              "Content-Type": "application/json",
              "accept": "application/json",
          },
          body: JSON.stringify(UIUpdate.getUsernamePassword())
      }).then(resp => {
          UIUpdate.updateCat(resp.status);
          if (resp.status == 200) {
              return resp.json();
          } else {
              return resp.text();
          }
      }).then(data => {
          if (data.access_token) {
              ACCESS_TOKEN = data.access_token;
              data = `Access Token: ${data.access_token}`;
              UIUpdate.loggedIn();
          }
          UIUpdate.alertBox(data);
      });
  });
#+end_src

**** Test the Authentication Login
Let's try this out.

#+CINDEX:400 status
#+CINDEX:bad request, 400
04:54 If we click on =login=, we have a modal asking for our credentials.  If we
enter nothing, we are getting a =400= bad request error with the message, "You
need a username and password."

#+CINDEX:401 status
#+CINDEX:unauthorized error
05:05 Let's try to enter =username= "admin", and an invalid password.  This
time, we are getting a =401= =unauthorized= with the message, "User not found."

#+CINDEX:access token, receive
Now, if we use the right =username= and =password= combination, we are getting
an access token.

#+CINDEX:@url{jwt.io}
05:20 If we copy and paste the access token in ~jwt.io~, we can see the content
of the token.  It has the right username.

05:30 Back to our application, if we click on =private=, we are still getting a
"No authorization token was found" error message.  That's because we are still
not passing a token with our request.

**** Set Up Authentication to the Private Route
#+CINDEX:headers, request
#+CINDEX:@code{secretBtn}
05:43 Back to the =secretBtn=, let's start by defining our headers.  We can
start by initializing with an empty object, then we test to see if =ACCESS_TOKEN=
is still =undefined= or if we have an =ACCESS_TOKEN= stored there.

#+CINDEX:bearer token
05:58 If we do, we can specify the headers.  We will add an "Authorization" with
the value of =Bearer= followed by a space, and then =${ACCESS_TOKEN}=.

06:13 Now, we can add those through our request as a second argument to our
~fetch~.

#+name:secretBtn.addEventListener
#+begin_src js -n
secretBtn.addEventListener("click", (event) => {
	let headers = {};
	if (ACCESS_TOKEN) {
		headers = {
			"Authorization": `Bearer ${ACCESS_TOKEN}`
		};
	}
	fetch(`${API_URL}/resource/secret`, { headers }).then(resp => {
		UIUpdate.updateCat(resp.status);
		return resp.text();
	}).then(data => {
		UIUpdate.alertBox(data);
	});
});
#+end_src

**** Test Authentication to Private Resource Route
Let's test this out.  Start by refreshing the app, and then log in using =admin=
and the valid password.

#+CINDEX:secret resource
06:27 Now, if you click on =private=, you'll get the secret resource.  You should
be logged in to see this message.  We now have access to our secret resource.

**** Log Out Procedure
#+CINDEX:@code{logoutBtn}
#+CINDEX:@code{UIUpdate.loggedout} method
06:36 Finally, we will need a way to log out.  If we go to the =logoutBtn= "click"
event handler, we can simply reset our =ACCESS_TOKEN= to =undefined= and use the
~UIUpdate.loggedout~ method.

#+name:logoutBtn.addEventListener
#+begin_src js -n
logoutBtn.addEventListener("click", (event) => {
	ACCESS_TOKEN = undefined;
	UIUpdate.loggedOut();
});
#+end_src

06:51 One last time to our application, and we can now ~login~ using a valid
credential and get access to the =private= button.  Now, if you log out and try
the =private= button again, you're getting the =401= error with the "No
authorization token found" error message again.

07:09 That's it.  You now have a front-end that access both public and private
data from an API using a JSON web token.

*** Lesson 8---Authenticate Users in a Single Page Application with Auth0
#+CINDEX:Auth0
#+CINDEX:custom authentication server, replace with Auth0
In this lesson, we take the previous API and front-end and we convert them to
use Auth0 to replace our custom authentication server built in the previous
lessons.

**** Setting Up Auth0

{{{heading(Create Account at Auth0)}}}

#+CINDEX:@url{https://auth0.com}
#+CINDEX:Auth0, create account
00:00 Since this lesson is aimed at using Auth0 for authentication, the first
thing we'll need to do is to go to the [[https://auth0.com/][auth0.com]] website and create a free
account.

[[file:./resources/auth0.com-25.png]]

00:09 The sign-up process is fairly straightforward.  You can use an email and
password or you can use any of the social connections here.  This free account
will give you access to most of the Auth0 API for up to 7,000 users, which is
more than enough for the purpose of this lesson.

[[file:./resources/auth0-signup-25.png]]

[[file:./resources/auth0-signed-up-25.png]]

00:24 Once you're signed up, you can log into your account, and you will land
on this dashboard.  This shows you your active users and the number of logins
in the last few days.

[[file:./resources/auth0-dashboard-25.png]]

{{{subheading(Create New User)}}}

Create a new tenant "sandbox" to avoid using the root account name that was
auto-assigned, which is just a random set of letters.

[[file:./resources/auth0-create-tenant-25.png]]

{{{heading(Auth0 Create New API)}}}

#+CINDEX:API section, Auth0
00:34 From here, we'll want to go to the API section to create a new
entry.  This is what will be used to protect our API.

[[file:./resources/auth0-create-api-35.png]]

{{{subheading(Auth0 Create API Name and Identifier)}}}

#+CINDEX:identifier
00:42 You can pick anything for the =name=.  Let's just use =egghead-demo=.
For the =identifier=, you can use anything, but it is recommended that you use
the URL of your application.  In this case, we don't have a URL, so we'll just
use =egghead-demo= as well.

[[file:./resources/auth0-api-create-35.png]]

{{{subheading(Auth0 API Signing Algorithm)}}}

#+CINDEX:signing algorithm
#+CINDEX:HS256
00:58 Finally, you will want to use =HS256= for the signing algorithm, because
this is what we used in the previous lesson.

{{{subheading(Auth0 Quick Start Page)}}}

#+CINDEX:quick start page
Once you have this, you click on =create=, and the modal is closed, and you get
redirected to the quick start page.

[[file:./resources/auth0-api-quick-start-35.png]]

#+CINDEX:middleware, Auth0
01:11 If you look at this page, you get code examples on how to implement this
with your API.  As you can see, it uses the same middleware as we currently use,
the main difference being the settings for the middleware itself.

{{{subheading(Middleware Options)}}}

#+CINDEX:secret
#+CINDEX:audience
#+CINDEX:issuer
01:24 We will have a =secret= key, but we also check who is the token meant
for, the =audience=, and who created this token, the =issuer=.  Those are
additional checks that will make your API even more secure.

**** Updating ~api.js~ With Auth0 Options
Let's now go back at our code editor and open ~api.js~.

01:41 You can simply change the settings of the middleware by pasting the
values you copied from the Auth0 website.

*Note*: that those values will need to be the ones from your Auth0 account.  If
you try to copy the values that I just pasted in, this won't work for you.

#+CINDEX:@code{api.js}
#+name:auth0-jwtCheck
#+begin_src js -n
const jwtCheck = expressjwt({
  secret: "7zEaiA557eeLRSDgYJdjqpEeS0lPtQRG",
  audience: "egghead-demo",
  issuer: "https://pinecone062-sandbox.auth0.com/"
});
#+end_src

{{{heading(Create Lesson8 Makefile Rule)}}}

#+begin_src sh :tangle egghead-jwt-auth/Makefile
.phony : lesson8
lesson8 : FORCE
	yarn run httpster -d lesson8 -p 5000 &
	export API_PORT=3333;node lesson8/api.js &
#+end_src

{{{heading(Test the Setup)}}}

#+CINDEX:API server, start
01:56 We can now head to our terminal window and start our API server by
running ~node api~ via the ~make~ rule from the root directory
(~egghead-jwt-auth~):
: make lesson8

Your server is now running on port 3333.

***** File ~api.js~ for Lesson 8

Everything is the same except for the ~express-jwt~ options:

#+name:auth0-api.js
#+begin_src js -n :tangle egghead-jwt-auth/lesson8/api.js :mkdirp yes :noweb yes
<<require-express>>
<<require-body-parser>>
<<require-cors>>
<<require-expressjwt>>

/* Auth0 express-jwt options */
<<auth0-jwtCheck>>

<<app-express>>
<<app-use-body-parser>>
<<app-use-cors>>

<<public-resource-route>>
<<private-resource-route>>
<<api-catchall-route>>

<<api-port>>
<<app-listen-api-port>>
#+end_src

**** Setting Up the Front End ~index.html~ for a Token from Auth0
#+CINDEX:token
If you try this now, nothing will work.  Your front end also needs to get a
token from Auth0.[fn::This is because the default setup for Auth0 is to require
authentication for all endpoints.  This error for all routes could probably be
eliminated by changing the Auth0 settings to be line with the demo premise that
there is a =PUBLIC= route.]

[[file:./resources/auth0-need-token-40.png]]

Let's get back to our code and do those changes.

***** Delete Authorization Server ~auth.js~

#+CINDEX:@code{auth.js}, delete
02:13 Because we won't be using our authorization server anymore, we can go
ahead and remove the ~auth.js~ file from this folder altogether.

***** Update ~index.html~ Code for Auth0

#+CINDEX:@code{index.html}
It's now time to edit our ~index.html~ page to use Auth0's authentication server
instead of ours.

{{{subheading(Remove Login Modal)}}}

#+CINDEX:login modal, remove
#+CINDEX:login screen, Auth0
02:28 The first thing that we'll want to do is to remove the login modal.  We
will be using Auth0's login screen, so let's go to line 21 and remove those
data tags that were used to open the modal.

#+name:auth0-container
#+begin_src html :noweb yes :exports none
<div class="container container-fluid">
    <<auth0-navbar>>
    <<mainPage>>
    <<secret-unauthorized-Pages>>
</div>

#+end_src

#+name:auth0-navbar
#+begin_src html :noweb yes :exports none
<nav class="navbar navbar-expand-lg navbar-light bg-light">
    <<navbar-a>>
    <<navbar-toggler>>

    <<auth0-navbar-collapse>>
</nav>

#+end_src

#+name:auth0-navbar-collapse
#+begin_src html :noweb yes :exports none
<div class="collapse navbar-collapse" id="navbarSupportedContent">
    <<navbar-collapse--nav>>
    <<auth0-navbar-collapse--form>>
</div>
#+end_src

#+name:auth0-navbar-collapse--form
#+begin_src html :noweb yes :exports none
<form class="form-inline">
    <<auth0-login-button>>
    <<logout-button>>
</form>
#+end_src

The =data-toggle= and =data-target= are removed from the =form= element
([[modal-login-button][modal login button]] in Lesson 7).

#+CINDEX:@code{loginBtn}
02:40 We can also rename this button to be =loginBtn= instead of =loginModalBtn=.

#+name:auth0-login-button
#+begin_src html
<button class="btn btn-outline-success my-2 my-sm-0" type="button" id="loginBtn">Login</button>&nbsp;
#+end_src

Since we won't be using the modal anymore, we can go down here and delete all
of the markup for our login modal.

{{{subheading(Add Auth0 Library from CDN)}}}

#+CINDEX:CDN, Autho0
02:55 We will use Auth0's library, which we will get from their CDN.  We can
add a script tag.  The source will be =https://cdn.auth0.com/js/auth0/=, the
version number, which is =9.5.1=, the latest at this moment, and finally
=/auth0.min.js=.[fn::Current version is =<script
src="https://cdn.auth0.com/js/auth0/9.10/auth0.min.js"></script>=]

#+name:auth0-cdn-script
#+begin_src html
<script src="https://cdn.auth0.com/js/auth0/9.5.1/auth0.min.js"></script>
#+end_src

***** Lesson 8 ~index.html~
#+name:auth0-index.html
#+begin_src html -n :tangle egghead-jwt-auth/lesson8/index.html :noweb yes
<html>
    <head>

        <<link-stylesheet>>

    </head>

    <body>

        <<auth0-container>>
        <<cdn-scripts>>
        <<auth0-cdn-script>>

        <<app-scripts>>

    </body>
</html>
#+end_src

**** Setting Up ~ui-update.js~
#+CINDEX:@code{ui-update.js}
#+CINDEX:@code{loginBtn}
03:21 Our ~index.html~ file is now ready, but to finish the UI changes, we will
need to go to the ~ui-update.js~ file and do a few minor changes in there.

***** Changes to ~ui-update~ loggedIn and loggedOut Buttons
Instead of showing and hiding the login modal button, we will do that on the
=loginBtn=.  Let's change line 5 to use =loginBtn=, and same thing on line 11.
We're almost done.  ([[ui-update-buttons][Prior ui-update code]]).

#+name:auth0-ui-update-loggedIn
#+begin_src js
UIUpdate.loggedIn = function(token) {
  UIUpdate.alertBox(`Just logged in<br>Token:<br>${ACCESS_TOKEN}`);
  loginBtn.classList.add("d-none");
  logoutBtn.classList.remove("d-none");
};
#+end_src

#+name:auth0-ui-update-loggedOut
#+begin_src js
UIUpdate.loggedOut = function() {
  localStorage.removeItem("access_token");
  loginBtn.classList.remove("d-none");
  logoutBtn.classList.add("d-none");
};
#+end_src

***** File ~ui-update.js~ for Auth0
#+name:auth0-ui-update.js
#+begin_src js -n :tangle egghead-jwt-auth/lesson8/ui-update.js :noweb yes
let UIUpdate = {};

<<auth0-ui-update-loggedIn>>

<<auth0-ui-update-loggedOut>>

<<ui-update-helper-functions>>

<<parseHash>>
#+end_src

**** Setting Up ~index.js~ to Use Auth0 Authentication Server

***** Create a New Auth0 Application
#+CINDEX:@code{index.js}
#+CINDEX:@code{webAuth} object
03:44 Let's open our ~index.js~ file to change our code to use Auth0's
authentication server instead of the one we built.  In here, we will need to
use Auth0's =webAuth= object.  First, we need to get the settings for this
object.  Let's go back to Auth0's website and go into the =Applications=
section.

[[file:./resources/auth0-create-application-50.png]]

{{{heading(Create New Auth0 Application)}}}

04:03 In here, we choose to create a new application.  We can name it whatever,
but we will use =egghead-demo= for consistency.  This application is of type
=single-page application=, so we can select this and click on create.

[[file:./resources/auth0-new-application-50.png]]

04:17 Similar to when we created the API, we get a screen that suggests us
various quick starts.  In here, you can find for most major JavaScript
frameworks, but we are going to use plain vanilla JavaScript here.

[[file:./resources/auth0-app-technologies-50.png]]

04:30 If you scroll down, you will find a section which has all of your
settings for your application.

*Note*: Once again, make sure that you copy those from your Auth0 account, and
not those from this video.

Let's copy that and go back to our code.

[[file:./resources/auth0-app-settings-50.png]]

***** Create a ~webAuth~ Object

04:44 Now we can create a =webAuth= object using a new =auth0.WebAuth=, and we
can paste the settings we got from the quick start.[fn::Quick start settings
are missing the =audience= type.]]

: default webAuth settings
: ------------------------

#+begin_src js -n
let webAuth = new auth0.WebAuth({
  domain: 'pinecone062-sandbox.auth0.com',
  clientID: '1XIQVmd85gJXfbyz5tdsG6AQhJF09P45',
  responseType: 'token id_token',
  scope: 'openid',
  redirectUri: window.location.href
});
#+end_src

***** Update Auth0 Application Settings

#+CINDEX:OpenID Connect
04:52 If you use Auth0's application with a default setting, it is =OpenID
Connect-enabled=, which is outside the scope of this lesson.  We will need to
tweak the settings of this application in order to be able to use it.

#+CINDEX:callback url
05:04 Going back to Auth0 and into the settings of our application, the first
thing that we will need to change is the Callback URL.

This is the page where users are redirected after they're logged in on
Auth0.  You can go to your application, get the URL from there, and simply paste
it in the settings.

[[file:./resources/auth0-callback-url-50.png]]

***** Update App Advanced Settings
#+CINDEX:OIDC conformant application
#+CINDEX:HS256
#+CINDEX:JWT signature
05:22 We will also need to go all the way down to the =Advanced= settings.  This
is not an OIDC conformant application, so we can uncheck this.  We can change
our JWT signature to also use =HS256=.  We're good.  Just save this, and we can
head back to our code editor.

[[file:./resources/auth0-show-advanced-settings-50.png]]

[[file:./resources/auth0-advanced-settings-40.png]]

***** Further Auth0 Setting Tweaks
#+CINDEX:issuer of token
#+CINDEX:tenant
#+CINDEX:clientID
05:42 We need to tweak our settings just a little bit here.  Our =domain=
(=domain: 'pinecone062-sandbox.auth0.com'=) is the issuer of the token.  It's
what is referred to as =tenant= in Auth0's website.  The =clientID= (=clientID:
'1XIQVmd85gJXfbyz5tdsG6AQhJF09P45'=) is found in your settings.  This should be
good.

#+CINDEX:responseType
#+CINDEX:id_token
#+CINDEX:audience
#+CINDEX:scope
05:54 In =responseType= (=responseType: 'token id_token'=), we won't need the
=id_token=, so we can remove this.  The =audience= is the API that we want to
connect to.  Let's change this to =egghead-demo=.  Finally, the =scope=
(=scope: 'openid'=) is irrelevant in this case, so we can simply remove this.

#+CINDEX:redirectUri
06:10 The =redirectUri= (=redirectUri: window.location.href=) is where your
user will be redirected afterwards. This URL has to be in your application
settings in the allowed callback URL section, which we already took care of.

: index.js webAuth object
: -----------------------

#+CINDEX:webAuth object
#+name:auth0-webAuth-object
#+begin_src js
let webAuth = new auth0.WebAuth({
  domain: 'pinecone062-sandbox.auth0.com',
  clientID: '1XIQVmd85gJXfbyz5tdsG6AQhJF09P45',
  responseType: 'token',
  audience: 'egghead-demo',
  scope: '',
  redirectUri: window.location.href
});
#+end_src

***** Setup Logic for Login Button
#+CINDEX:login button
Let's now change the logic behind our login button ([[loginBtn][loginBtn code]]).

#+CINDEX:@code{webAuth.authorize} method
06:25 Right now, we had to get all of that info from the modal and post that to
our authentication server, but we won't need any of this now. Let's just remove
all of this and use =webAuth= with the =authorize= method instead. Save this,
and you should be good to go.

#+name:auth0-loginBtn.addEventListener
#+begin_src js
loginBtn.addEventListener("click", (event) => {
	webAuth.authorize();
});
#+end_src

***** Lesson 8 ~index.js~ Code
#+name:auth0-index.js
#+begin_src js -n :noweb yes :tangle egghead-jwt-auth/lesson8/index.js
/* To run this file on a server, we are using httpster.
Type `httpster index.html -p 5000` in your console to start the server. */

<<api-url>>

<<auth0-webAuth-object>>

<<access-token>>

const headlineBtn = document.querySelector("#headline");
const secretBtn = document.querySelector("#secret");
const loginBtn = document.querySelector("#loginBtn");
const logoutBtn = document.querySelector("#logoutBtn");

<<headlineBtn.addEventListener>>

<<secretBtn.addEventListener>>

<<auth0-loginBtn.addEventListener>>

<<logoutBtn.addEventListener>>

#+end_src

**** Setup Private Access
06:40 If we go to our app and refresh it, and you try the public button, it
should return you the data from our public endpoint. If you tried a private
one, you should be getting an error message, which is normal, since we haven't
logged in, yet.

{{{heading(Login using Auth0)}}}

#+CINDEX:login button
#+CINDEX:redirect to Auth0 login
06:53 Let's do that right away and click on the =login= button. You can see
that we are redirected to the Auth0 login screen. You now have some social
sign-ons, you have a =sign-up= page, you have a =forgot password= page. All of
that for free just by using Auth0. I'll go ahead and log in with Google.

#+CINDEX:consent UI screen
07:13 Now you get the consent UI screen asking you if you want to share the
information with the application.

Let's go ahead and accept that, and we are sent back to our website.

07:23 As you can see, as part of my URL, now has a hash followed by an access
token.

{{{subheading(Parse the Hash for the Access Token)}}}

#+CINDEX:parse hash
#+CINDEX:access token, extract from hash
Now if I try my =Public= button, it still works, but if I use a =Private=
button, I'm still getting the "No authorization token was found," error
message. That's because we need to ~parse~ our hash and extract the =access
token= from there, and store it so that it can be used by our ~fetch~ call.

#+CINDEX:@code{parseHash} function
#+CINDEX:@code{webAuth.parseHash} method
07:43 Thankfully, there is a method in the Auth0 library to help us with
that. Let's create a ~parseHash~ function here. This function will call
~webAuth.parseHash~ method, which takes a callback as an argument.

#+CINDEX:@code{authResult}
#+CINDEX:@code{accessToken}
07:56 This callback has an =error=, and =authResult= arguments. Let's look at
the happy path and check if we have an =authResult= and an =accessToken=.

#+CINDEX:@code{ACCESS_TOKEN}
#+CINDEX:@code{accessToken} variable
08:04 We can remove the hash part of the URL. We can also store our
=ACCESS_TOKEN= in our =accessToken= variable.

#+CINDEX:@code{UIUpdate} helper
08:12 Finally, let's use our =UIUpdate= helper to indicate that we are
loggedIn. This function will need to run at some point. Let's
=addEventListener= to our window object for "DOMContentLoaded", and run this
function then.

#+name:parseHash
#+begin_src js
const parseHash = () => {
    webAuth.parseHash(function(err, authResult) {
        if (authResult && authResult.accessToken) {
            window.location.hash = '';
            ACCESS_TOKEN = authResult.accessToken;
            UIUpdate.loggedIn();
        }
    });
};

window.addEventListener("DOMContentLoaded", parseHash);
#+end_src

**** Test the Auth0 Application
08:28 Let's go back to our application now and refresh this. We can try
=Public= and =Private=, and we are getting the expected result. Let's go ahead
and =Login=.

08:38 I'll login with Google again. You'll notice that I haven't been asked for
my consent again, as I had given it previously and it remembers this.

08:48 Now I'm redirected back to the application, our URL is clean, it doesn't
have hash in it anymore, and we have our access token right here. If you copied
this token, you can go to the ~jwt.io~ website and paste it there.

09:01 This will decode the token for you and show you all of the details of
this JWT. You can see that it's an =HS256= encoded token. You also have a bunch
of stuff like the =issuer= -- so who created this token -- you have your =user
ID=, and the =audience=, which is who this token is meant for. You also have
your =issued at= and an =expiry= time-stamps, which can be very useful.

09:26 Now that you have this token, you can click on the =Private= button and
you see the response from your secured endpoint in your API. That's how you
make a real secure application with Auth0.
** Course---AngularJS Authentication with JWT
:PROPERTIES:
:uri:      https://egghead.io/courses/angularjs-authentication-with-jwt
:instructor: Kent C. Dodds
:time:     31 minutes
:subject:  JWT Angular
:date:     2014-09-24
:Github:   https://github.com/eggheadio/egghead-angularjs-aunthentication-with-jwt
:END:
Example AngularJS application featuring authentication with Javascript Web
Tokens (JWT)

JSON Web Tokens (JWT) are a more modern approach to authentication. As the web
moves to a greater separation between the client and server, JWT provides a
terrific alternative to traditional cookie based authentication models. For
more information on JWT visit http://jwt.io/

In this series, we’ll be building a simple application to get random user
information from a node server with an Angular client. We’ll then implement JWT
to protect the random user resource on the server and then work through the
frontend to get JWT authentication working.

By the end, we’ll have an application which has a single username/password
combination (for simplicity) and uses tokens to authorize the client to see the
random user information. You’ll be able to login, get random users, and logout.

{{{heading(Project Code Repository)}}}

The GitHub repository for this project is at:

- https://github.com/eggheadio/egghead-angularjs-aunthentication-with-jwt

*** Set Up the Project
**** Prerequisites---AngularJS Authentication with JWT
This is the example project for the AngularJS Authentication with JWT lesson
series on =egghead.io=.

#+CINDEX:@code{node.js}
#+CINDEX:@code{npm}
This project uses ~node.js~ and Node Package Manager (~npm~).[fn::I will be
using ~yarn~ instead of ~npm~ to install Node prerequisites.]

#+CINDEX:Bower
#+CINDEX:AngularJS
Additionally it uses Bower to grab AngularJS.

#+CINDEX:tags
The lessons correspond to tags. Note that ~npm~ dependencies will be added for
each lesson, so it will be required to run ~npm install~ for each lesson to get
the latest dependencies.

[[file:resources/dodds-jwt-tags-50.png]]

{{{heading(Static File Server)}}}

#+CINDEX:static file server @file{http-server}
#+CINDEX:@file{http-server}
The front end needs a static file server.  The demo uses the Node module
~http-server~, which by default loads files from a ~public/~ directory using
port =8080=, both acceptable defaults for this project.  Feel free to use your
own choice of static file server.  *Note* that you can delete the =dev=
dependency below if you wish, *but* you will need to update the Makefile to use
your choice instead of ~http-server~ ([[makefile-static-file-server][Makefile static file server]]).

**** Project Initialization

#+name:tangle-Security.org
#+BEGIN_SRC emacs-lisp :results output silent :exports results
(org-babel-tangle-file "Security.org")
#+END_SRC

Initialize a new Node.js package in the root directory ~angularjs-auth-jsw~
using defaults (@option{--yes}) and then add two development dependencies,
~bower~ and ~http-server~:

#+CINDEX:init
#+CINDEX:@file{package.init}
#+name:dodds-jwt-package-init
#+begin_src sh :dir angularjs-auth-jwt :results output :exports both
[ -e package.json ] && \
  echo "package.json has already been created" || \
  yarn --yes init
  yarn add --dev bower http-server
  mkdir public
#+end_src

List ~package.json~ contents:

#+name:list-package.json
#+begin_src sh :dir angularjs-auth-jwt :results output :exports results
echo package.json;
echo ------------
cat package.json
#+end_src

**** Makefile for AngularJS Auth JWT Project
Create a Makefile and add some user-definable variables.

This project uses Safari as the default browser for the backend server, Google
Chrome as the default browser for the front end server, and the Perl
command-line script ~json_xs~ to pretty-print JSON output to the terminal.
There are many available options, so feel free to change these to your
preferences.  Also, this project is running on a Mac, so it is using ~open -a~
to open the default browsers and feed them URLs from the command line.  If you
are using Linux or Windows, this =OPEN= command will need to be changed for
your operating system.

The backend server uses =localhost= on PORT 3000.

<<makefile-static-file-server>>Finally, this project is using ~http-server~ as
a static file server.  Feel free to change this to better suit your preference.
The static file server ~http-server~ uses =localhost= on PORT 8080 by default.
You can change these if you need.

Each lesson uses a different server number.  The Makefile is used to
start individual servers with the command:
: make server<#>
: make app<#>
where <#> is a number between 1 and 6, and roughly correspond to lessons.
Different numbers can be used together.

#+name:angularjs-auth-jwt-makefile
#+begin_src make :tangle angularjs-auth-jwt/Makefile :mkdirp yes
# ============================================================
# USER-DEFINABLE COMMANDS AND VARIABLES

BROWSER := "Safari"
FRONT_END := "Google Chrome"
CURL    := curl -sS
JSON_PP := json_xs
OPEN    := open -a

URL     := http://localhost
PORT    := 3000

# http-server defaults to using /public and port 8080
APP_SERVER      := http-server
APP_SERVER_URL  := $(URL)
APP_SERVER_PORT := 8080
START_APP_SERVER = $(PKG_MGR-RUN) $(APP_SERVER)

# This is the only route used by this tutorial.
DEF_ROUTE := random-user

# END USER-DEFINABLE COMMANDS AND VARIABLES
# ============================================================

PROJECT = angularjs-auth-jwt

URL_PORT         := $(URL):$(PORT)
APP_SERVER_URL_PORT := $(APP_SERVER_URL):$(APP_SERVER_PORT)

OPEN_BROWSER     := $(OPEN) $(BROWSER)
OPEN_BROWSER_URI  = $(OPEN_BROWSER) $(URL_PORT)/$(ROUTE)
OPEN_APP         := $(OPEN) $(FRONT_END)
OPEN_APP_URI     := $(OPEN_APP) $(APP_SERVER_URL_PORT)

CURL_URL         := $(CURL) $(URL_PORT)
CURL_URI_PP       = $(CURL_URL)/$(ROUTE) | $(JSON_PP)

NODE     := node
PKG_MGR  := yarn
PKG_MGR-RUN := $(PKG_MGR) run

# START OF RULES
# ============================================================

.phony : clean
clean :
	-cd .. && rm -vf *.{texi,info}

.phony : dist-clean
dist-clean : clean
	-cd .. && rm -rf $(PROJECT)
#+end_src

*** JSON Web Token---JWT---Introduction
A basic introduction to the mechanics of JWTs and the application we will be
building in this lesson series.

**** About JWTs
#+CINDEX:JSON Web Token
#+CINDEX:token
00:00 This is an introductory video on JSON Web Tokens, also known as JWTs. A
JOT is an encoded JSON object, digitally signed by the server, which the client
sends with every request to identify the user. A JWT here is a token.

[[https://jwt.io][JWT dot IO]]

00:14 We have some identification information about this token, we have the
payload of the token represented by this blue string of characters, and then we
have the signed secret piece of the token.

00:29 The server has signed this token with the term =secret=. Let's say it was
signed with the term =secrets=, this is no longer valid, because this doesn't
decode properly. That's how the server knows that the token is legitimate.

**** About the App GetRandomUserInfo
00:47 In this series, we are going to be building this app, get random user
info, and you'll be required to log in. Then, when you get a random user, every
request will send the token over the wire to the server. The server will decode
that token to validate that it's legitimate, and then send back the response if
it is legitimate.

**** About the Tools
#+CINDEX:Node.js
#+CINDEX:Angular.js
01:09 We'll be using Node.js on the back end for our JWT implementation, and
we'll use Angular.js on the front end. I'll show you how to use the tools that
Angular gives you to use JWTs, and that's what our series is going to be all
about.

*** Basic Server Setup for JWT Authentication
Creating the basic node server to serve up random users via API endpoints.

00:00 This is "Authentication with AngularJS, Getting it Right with JWT."
That's pronounced "Jot".

#+CINDEX:overview
00:07 We're going to create a basic server that will serve up a random user and
then create a front end client that will consume this service to illustrate how
to do authentication with JWTs.

**** Install Server Dependencies

#+CINDEX:@code{server.js}
#+CINDEX:Express
#+CINDEX:Faker
00:21 First off, we're going to need our JavaScript file. We'll call
that ~server.js~.[fn::Each lesson will use a different ~server<#>.js~
file.  This lesson will use ~server1.js~.]]  A couple of things that
we're going to need through NPN[fn::I will be installing dependencies
with ~yarn~.] are:
- Express
- Faker

{{{heading(Install Express and Faker)}}}

#+name:angularjs-auth-jwt-prereqs-install
#+begin_src sh :dir angularjs-auth-jwt :results output :exports both
yarn add express faker
#+end_src

#+call:list-package.json()

**** Create server1.js
00:33 Faker's how we're going to make the random user. We're going to ~require
express~ and we'll ~require faker~.  Then we'll create our app.  Then we'll
have our app and have a get a random user with the request (~req~) and response
(~resp~).

#+caption:Server basic requirements
#+name:angularjs-auth-jwt-app-requires
#+begin_src js
const express = require('express');
const faker = require('faker');
#+end_src

#+caption:Initializing the server app
#+name:angularjs-auth-jwt-app
#+begin_src js
const app = express();
#+end_src

{{{subheading(Setting Up a User with faker)}}}

00:52 We'll save our "User = faker.Helpers.userCard" and "user.avatar =
faker.Image.avatar." Then we'll say response send back the user as JSON.

#+caption:Setting up a 'random-user' route
#+name:angularjs-auth-jwt-app--random-route
#+begin_src js
  app.get('/random-user', (req,res) => {
      const user = faker.helpers.userCard();
      user.avatar = faker.image.avatar();
      res.json(user);
  });

#+end_src

{{{subheading(Have the app listen on port 3000)}}}

Then I will have our app listen on port 3000. We'll just say, "App listening on
localhost:3000."

#+caption:Start the server listening
#+name:angularjs-auth-jwt-app--listen
#+begin_src js
  app.listen(3000, () => {
      console.log("App listening on localhost:3000");
  });
#+end_src

***** Code for server1.js

#+caption:server1.js
#+name:angularjs-auth-jwt-server1.js
#+begin_src js :tangle angularjs-auth-jwt/server1.js :mkdirp yes :noweb yes
<<angularjs-auth-jwt-app-requires>>
<<angularjs-auth-jwt-app>>
<<angularjs-auth-jwt-app--random-route>>
<<angularjs-auth-jwt-app--listen>>
#+end_src

***** Makefile for server1
Hit the ~server1~ endpoint at =/random-user= with a =GET= request:
: make server1

The Makefile checks for a running ~server1~; if it is not running,
then it starts the server before hitting the endpoint with a =GET=
request.

Terminate all Node server processes with the command:
: make terminate

#+caption:Makefile for server1.js
#+name:angularjs-auth-jwt-makefile-server1
#+begin_src make :tangle angularjs-auth-jwt/Makefile :mkdirp yes
ROUTE ?= $(DEF_ROUTE)

.phony : server
server :
	@pgrep -qlf $(NODE) $(SERVER) || { $(NODE) $(SERVER).js & sleep 2; }
	@$(CURL_URI_PP) && printf "${YELLOW}$(SERVER) started...\'make terminate\' to stop.${CLEAR}"
	@$(OPEN_BROWSER_URI)

.phony : server1
server1 : SERVER = server1
server1 : server
	@:

.phony : terminate
terminate :
	-@pgrep -lf 'node server[[:digit:]]'
	-@pkill -lf 'node server[[:digit:]]'
	-@pgrep -lf $(APP_SERVER)
	-@pkill -lf $(APP_SERVER)

.phony : terminate-clean
terminate-clean : terminate dist-clean
	@:

#+end_src

**** Run the Server with Nodemon
#+CINDEX:Nodemon
01:17 We're going to use ~nodemon~ to have our server automatically
restart every time we make changes so ~nodemon server.js~.[fn::Since
this project is being set up by Org, I will not be using ~nodemon~,
but rather a Makefile.]

01:29 Here we'll go to local host:3000.  Obviously we can't get a route but we
can get random user.  Here every time we refresh we have a random user.

For this project, type the command:
: make server1

to start the server and hit the ~/random-user~ endpoint.  You will get a random
user pretty-printed to the terminal as well as a random user pretty-printed to
Chrome.

*** Client Front End Setup for JWT Authentication
#+CINDEX:Angular application
#+CINDEX:CORS
Creating a basic Angular application to access the random users resource.  Also
setting up CORS on the node server to enable the resource sharing across
different domains (ports in our case).

#+CINDEX:front end client
00:00 We have our server running and it's serving up a random user every time
we hit "/random-user."  We want to create a front end client that is going to
interface with this service. It will do so being served at from a different
server.

**** Install Angular using Bower inside ~public/~ Directory
00:16 First we're going to make directory called ~public/~.
Then we'll go into that directory and ~bower install angular~.

#+name:bower-install-angular
#+begin_src sh :dir angularjs-auth-jwt :results output :exports both
mkdir -v public
cd public && ../node_modules/.bin/bower install angular
#+end_src

**** Create an Angular App in ~public/index.html~
We'll create a new file called ~index.html~.

{{{heading(Index.html)}}}

{{{subheading(Install Scripts)}}}

#+CINDEX:Angular script
#+CINDEX:scripts
#+CINDEX:import @file{app.js}
00:29 Here we'll want to have a script for Angular and then we'll have another
script that will create called ~app.js~.

#+caption:Importing scripts
#+name:angularjs-auth-jwt-index--body---scripts
#+begin_src html
<script src="bower_components/angular/angular.js"></script>
<script src="app.js"></script>
#+end_src

{{{subheading(Create an Angular App)}}}

#+CINDEX:Angular app
#+CINDEX:app, Angular
#+CINDEX:@code{ng-app}
We're going to want to make this an Angular app with the module =ng-app=.

#+caption:Angular app
#+name:angularjs-auth-jwt-index--html---angular_app
#+begin_src html
<html ng-app="app">
#+end_src

{{{subheading(Add a Title)}}}

#+CINDEX:title
We'll call this (=<title>= it as) =JWT Example=.

#+caption:JWT Example title
#+name:angularjs-auth-jwt-index--head---title
#+begin_src html
<title>JWT Example</title>
#+end_src

{{{subheading(Create an Angular Controller as View Model)}}}

#+CINDEX:controller, Angular
#+CINDEX:Angular controller
#+CINDEX:@code{ng-controller}
#+CINDEX:@code{vm}
#+CINDEX:@code{MainCtrl}
Then we'll make an Angular controller (=ng-controller=) called =Main Controller
as View Model= (=MainCtrl as vm=).

#+caption:Angular controller
#+name:angularjs-auth-jwt-index--body---MainCtrl_vm
#+begin_src html
<body ng-controller="MainCtrl as vm">
#+end_src

{{{heading(Add a Get User Button)}}}

#+CINDEX:button
#+CINDEX:click-handler, for button
#+CINDEX:@code{ng-click}
#+CINDEX:@code{vm.RandomUser}
00:54 Then we'll have a section "Get Random User" with a =div= and a button
"Get User", and a click-handler (=ng-click=) on that (=vm.getRandomUser=).
01:07 Then we'll just have, for simplicity's sake, a =<pre>= here that's bound
to the =vm.RandomUser=.

#+name:angularjs-auth-jwt-index--body---h1.get_random_user
#+begin_src html
<h1>Get Random User</h1>
#+end_src

#+caption:Get User button
#+name:angularjs-auth-jwt-index--body---button.get_random_user
#+begin_src html
<div>
  <button ng-click="vm.getRandomUser()">Get User</button>
  <pre ng-bind="vm.randomUser | json"></pre>
</div>
#+end_src

***** Code for index.html

#+caption[angularjs-auth-jwt-index1.html]:Code for the AngularJS Auth Jwt @code{index1.html} file
#+name:angularjs-auth-jwt-index1.html
#+begin_src html :tangle angularjs-auth-jwt/public/index1.html :mkdirp yes :noweb tangle
<!DOCTYPE html>
<<angularjs-auth-jwt-index--html---angular_app>>
    <head lang="en">
        <meta charset="UTF-8">
        <<angularjs-auth-jwt-index--head---title>>
    </head>

    <<angularjs-auth-jwt-index--body---MainCtrl_vm>>
        <<angularjs-auth-jwt-index--body---h1.get_random_user>>
        <<angularjs-auth-jwt-index--body---button.get_random_user>>

        <<angularjs-auth-jwt-index--body---scripts>>

    </body>
</html>

#+end_src

**** Create a First Basic Angular App in ~public/app1.js~
#+CINDEX:@file{app1.js}
01:18 Now we're going to want to have our app.  We'll create a new JavaScript
file called ~app1.js~ and we'll put this in an immediately-invoking
function.  We'll have our app have no dependencies.

{{{heading(Create ~app1.js~ Application File)}}}

#+caption:First Angular app creation
#+name:angularjs-auth-jwt-app--var_app
#+begin_src js
var app = angular.module('app', []);
#+end_src

{{{subheading(The =API_URL= Constant)}}}

#+CINDEX:@code{API_URL}
01:28 We're going to make a constant called =API_URL= because we're serving
these up on different URLs.  This is a construct for us to be able to make sure
that all of our HTTP requests will go through the same URL.

#+name:angularjs-auth-jwt-app--const_API_URL
#+begin_src js
app.constant('API_URL', 'http://localhost:3000');
#+end_src

{{{subheading(Create the App Controller Called =MainCtrl=)}}}

#+CINDEX:@code{MainCtrl}
#+CINDEX:app controller
#+CINDEX:controller, app, main
#+CINDEX:main controller
01:40 We're going to create an =app.controller=.  We'll call this Main
Controller (=MainCtrl=).

#+caption:Angular app controller
#+name:angularjs-auth-jwt-app--controller.MainCtrl
#+begin_src js :noweb yes
app.controller('MainCtrl', function MainCtrl(RandomUserFactory) {
    'use strict';
    var vm = this;

    <<aaja-getRandomUser>>
})
#+end_src

{{{subheading(Get a Random User)}}}

#+CINDEX:@code{getRandomUser} function
#+CINDEX:@code{vm.getRandomUser}
Then we'll have the =vm.getRandomUser= assigned to =getRandomUser=.  We'll
define that down here.

#+CINDEX:server, Angular
#+CINDEX:Angular service
#+CINDEX:Angular factory
#+CINDEX:factory, Angular
#+CINDEX:@code{RandomUserFactory}
#+CINDEX:@code{getUser} method
#+CINDEX:data, from factory
#+CINDEX:@code{response.data}
#+CINDEX:@code{randomUser}
01:52 This, we're obviously going to use a service for this so we'll say
=RandomUserFactory.getUser().then=.  We'll assign =vm.randomUser= to the data
that we get back.

#+caption:@code{getRandomUser()} Service
#+name:aaja-getRandomUser
#+begin_src js
vm.getRandomUser = getRandomUser;

function getRandomUser() {
    RandomUserFactory.getUser().then(function success(response) {
        vm.randomUser = response.data;
    });
}
#+end_src

{{{heading(Create the =RandomUserFactory=)}}}

#+CINDEX:@code{RandomUserFactory}, create
#+CINDEX:factory, Angular, create
#+CINDEX:@code{getUser} object, function
#+CINDEX:HTTP @code{GET}
02:09 Now let's create this =RandomUserFactory=.  This will have the
~getUser()~ method.  This will be a simple HTTP =GET= to our server defined
above.  We'll use our =API_URL/randomUser= and we'll return that.

#+caption:@code{RandomUserFactory} definition
#+name:angularjs-auth-jwt-app--RandomUserFactory
#+begin_src js
app.factory('RandomUserFactory', function RandomUserFactory($http, API_URL) {
    'use strict';
    return ({
        getUser: getUser
    });

    function getUser() {
        return $http.get(API_URL + '/random-user');
    }
});
#+end_src

{{{heading(Tidy Up)}}}

02:24 Now we're going to need to inject a couple things into our HTTP and our
=API_URL= and then up here in our Main Controller we'll inject the
=RandomUserFactory=.  We also need to define =getUser= here.

***** Code for app1.js

#+caption:@file{app1.js} Code
#+name:angularjs-auth-jwt-app1.js
#+begin_src js :tangle angularjs-auth-jwt/public/app1.js :noweb yes :mkdirp yes
(function() {
    'use strict';
    <<angularjs-auth-jwt-app--var_app>>
    <<angularjs-auth-jwt-app--const_API_URL>>
    <<angularjs-auth-jwt-app--controller.MainCtrl>>
    <<angularjs-auth-jwt-app--RandomUserFactory>>
})()
#+end_src

***** Makefile for app1
Start this first Application by typing the command:
: make app1

This command starts the static file server, which uses the ~public/~ directory
on port 3000 to serve up the ~index.html~, which consumes the ~app<#>.js~
file.

To shut off the server, type the command:
: make terminate

This command terminates both servers.

#+CINDEX:static-server, Makefile
#+CINDEX:Makefile static-server
#+name:angularjs-auth-jwt-makefile-static_file_server
#+begin_src make :tangle angularjs-auth-jwt/Makefile :mkdirp yes
.phony : app
app :
	@cd public && ln -fs $(APP).js app.js
	@cd public && ln -fs $(INDEX).html index.html
	@$(START_APP_SERVER) &
	@pgrep -qlf $(APP_SERVER) && \
		printf "${YELLOW}$(APP) started... \'make terminate\' to stop.${CLEAR}" || \
		printf "${RED}$(APP) failed to start.${CLEAR}"
	@$(OPEN_APP_URI) &

.phony : app1
app1 : APP = app1
app1 : INDEX = index1
app1 : app
	@:
#+end_src

**** Allow Cross-Site Scripting with the CORS Module in ~server2.js~
02:37 Let's see what we blew up.  From the command line, type =? http-server=
and we'll go to =http://localhost:8080=.  That's serving up our client side
code, ~getUser~.

#+begin_example
? yarn run http-server
yarn run v1.13.0
$ /usr/local/dev/programming/Security/angularjs-auth-jwt/node_modules/.bin/http-server
Starting up http-server, serving ./public
Available on:
  http://127.0.0.1:8080
  http://10.0.0.250:8080
#+end_example

[[file:./resources/angularjs-auth-jwt--front-end.png]]

#+CINDEX:error 'Access-Control-Allow-Origin'
#+CINDEX:'Access-Control-Allow-Origin'
There is going to be an error.  It's "Access-Control-Allow-Origin."

[[file:./resources/angularjs-auth-jwt--cors_error.png]]

#+CINDEX:CORS error
#+CINDEX:error, CORS
#+CINDEX:'Cross Origin Resource Sharing', CORS
02:54 This is CORS.  CORS stands for "Cross Origin Resource Sharing".  It's a
security mechanism.  We have to enable CORS on our server explicitly.

{{{heading(Install ~cors~ Module in ~server.js~)}}}

#+CINDEX:@file{cors} module, require
03:03 We're going to use a module, "npm install cors." This is just a very
simple module that will enable CORS for us.

#+name:add-cors
#+begin_src sh :results output :exports both :dir angularjs-auth-jwt
yarn add cors
#+end_src

#+call:list-package.json()

03:10 Down here we'll say ~app.use(cors())~.

#+caption:require-cors
#+name:angularjs-auth-jwt-app-requires2
#+begin_src js :noweb yes
<<angularjs-auth-jwt-app-requires>>
const cors = require('cors');
#+end_src

#+caption:Use @file{cors} module
#+name:angularjs-auth-jwt-app--use_cors
#+begin_src js
app.use(cors());
#+end_src

***** Code for server2 Code

#+caption:server2.js
#+name:angularjs-auth-jwt-server2.js
#+begin_src js :tangle angularjs-auth-jwt/server2.js :mkdirp yes :noweb tangle
<<angularjs-auth-jwt-app-requires2>>

<<angularjs-auth-jwt-app>>
<<angularjs-auth-jwt-app--use_cors>>

<<angularjs-auth-jwt-app--random-route>>
<<angularjs-auth-jwt-app--listen>>
#+end_src

***** Makefile for server2
To invoke the server with CORS enabled, type the command:
: make server2

#+CINDEX:server2, Makefile
#+CINDEX:Makefile server2
#+caption:Makefile for server2.js
#+name:angularjs-auth-jwt-makefile-server2
#+begin_src make :tangle angularjs-auth-jwt/Makefile :mkdirp yes
.phony : server2
server2 : SERVER = server2
server2 : server
	@:

#+end_src

**** Front End Serves Up Random Users
That should restart our server, click =Get User=, and =[object Object]=.  It
looks like we're not piping this through =json=.  Click =Get User=.  There we
go.

[[file:./resources/angularjs-auth-jwt-front-end-get-user.png]]

03:22 Then we can hit our server over and over again to get these random users.

03:27 The next step will be, obviously, setting up authentication to protect
this resource. That's what we'll cover in the next video.

*** Add Authentication with Username and Password
Setting up a login on the Angular application and an authentication endpoint on the
server.

**** Add a Login Form to index2
#+CINDEX:authentication, on app
00:01 Here we have an app where we can get random users.  Our goal for this
video is to add authentication to this application.

#+CINDEX:form, login
#+CINDEX:login form
#+CINDEX:@code{vm.login}
#+CINDEX:Username
#+CINDEX:Password
#+CINDEX:login button
#+CINDEX:button, login
00:09 The first thing that we're gong to need is a form.  Instead of an
=action= we'll have an ~ng-submit="vm.login(vm.username, vm.password)"~.

00:18 Then we'll have an ng label input with the out label of Username and the
type is text and the model is ~vm.username~.  Then we'll have another one of
these for Password.  It will be a type =password=.  We'll also add a break
=<br />= to make things look nice.  Then we'll have a =button= with "Login" and
it's type =submit=.

#+caption:Login Form
#+name:angularjs-auth-jwt-index2--authentication-form
#+begin_src html
<div>
  <form ng-submit="vm.login(vm.username, vm.password)">
    <label>Username: <input type="text" ng-model="vm.username" /></label><br/>
    <label>Password: <input type="password" ng-model="vm.password" /></label><br />
    <button type="submit">Login</button>
  </form>
</div>
#+end_src

***** Code for index2.html

#+caption[angularjs-auth-jwt-index2.html]:Code for the AngularJS Auth Jwt @code{index2.html} file
#+name:angularjs-auth-jwt-index2.html
#+begin_src html :tangle angularjs-auth-jwt/public/index2.html :mkdirp yes :noweb tangle
<!DOCTYPE html>
<<angularjs-auth-jwt-index--html---angular_app>>
    <head lang="en">
        <meta charset="UTF-8">
        <<angularjs-auth-jwt-index--head---title>>
    </head>

    <<angularjs-auth-jwt-index--body---MainCtrl_vm>>
        <<angularjs-auth-jwt-index--body---h1.get_random_user>>

        <<angularjs-auth-jwt-index2--authentication-form>>

        <<angularjs-auth-jwt-index--body---button.get_random_user>>

        <<angularjs-auth-jwt-index--body---scripts>>

    </body>
</html>

#+end_src

**** Add a Login Form to app2
#+CINDEX:@code{app2.js}
#+CINDEX:@code{vm.login}
#+CINDEX:@code{login()} function
#+CINDEX:@code{vm.user}
00:39 Let's go to our app.  We'll have a ~vm.login = login~.  ~login()~ takes a
~username~ and ~password~.  We'll create a ~UserFactory~ that will have the
~login()~.  That takes the ~username~, ~password~.  Then we'll say ~vm.user~ equals the
data that we get back.

#+caption:Login on the App controller
#+name:angularjs-auth-jwt-app2--controller.MainCtrl
#+begin_src js :noweb yes
app.controller('MainCtrl', function MainCtrl(RandomUserFactory, UserFactory) {
    'use strict';
    var vm = this;

    <<aaja2-getRandomUser>>
    <<aaja2-login>>
    <<aaja2-handleError>>
})
#+end_src

#+caption:Login function and Handle Errors on App Controller
#+name:aaja2-login
#+begin_src js
vm.login = login;

function login(username, password) {
    UserFactory.login(username, password).then(function success(response) {
        vm.user = response.data;
    }, handleError);
}

#+end_src

00:58 In case of failure, we're going to make a simple function called
~handleError()~.  We'll define that here.  That will take a =response= and it
will simply alert "('Error: ' + response.data)".

#+caption:@caption{handleError} function
#+name:aaja2-handleError
#+begin_src js
function handleError(response) {
    alert('Error: ' + response.data);
}

#+end_src

We'll use that ~handleError()~ function here, as well (in ~getRandomUser()~).

#+caption:Handle Error in @code{getRandomUser()} Service
#+name:aaja2-getRandomUser
#+begin_src js
vm.getRandomUser = getRandomUser;

function getRandomUser() {
    RandomUserFactory.getUser().then(function success(response) {
        vm.randomUser = response.data;
    }, handleError);
}

#+end_src

**** Add a User Factory to app2
01:12 Let's create this ~Userfactory~, ~app.factory('Userfactory', function)~.
Login takes your username and password and it will return HTTP =GET=.
Actually, it will be a =POST= because we're locking.  We're going to post the
data. =API_URL/login= and the data will be =userName=, =password=.

#+name:angularjs-auth-jwt-app2--UserFactory
#+begin_src js
app.factory('UserFactory', function UserFactory($http, API_URL) {
    'use strict';
    return ({
        login: login
    });

    function login(username, password) {
        return $http.post(API_URL + '/login', {
            username: username,
            password: password
        });
    }
});
#+end_src

01:36 Then we'll export that and we'll inject =$http= and =_API_URL=.  Then
we'll want to inject the ~UserFactory= here (in ~app.controller~).

**** Running App2 with Authentication
01:46 Let's go ahead and refresh.  We have =username=, "kentcdodds" and cannot
=POST= a login because we haven't created that yet but we can still get these
users.  That's important for now.

**** Login Code for app2
***** Code for app2.js

#+caption:@file{app2.js} Code
#+name:angularjs-auth-jwt-app2.js
#+begin_src js :tangle angularjs-auth-jwt/public/app2.js :noweb yes :mkdirp yes
(function() {
    'use strict';
    <<angularjs-auth-jwt-app--var_app>>
    <<angularjs-auth-jwt-app--const_API_URL>>
    <<angularjs-auth-jwt-app2--controller.MainCtrl>>
    <<angularjs-auth-jwt-app--RandomUserFactory>>
    <<angularjs-auth-jwt-app2--UserFactory>>
})()
#+end_src

***** Makefile for app2
#+name: angularjs-auth-jwt-makefile-static-file_server2
#+begin_src make :tangle angularjs-auth-jwt/Makefile :mkdirp yes
.phony : app2
app2 : APP = app2
app2 : INDEX = index2
app2 : app
	@:
#+end_src

**** Add a =login= Route with Authentication Middleware to server3
01:55 We'll go to our server (~server3.js~) and we'll make a =login= route:
~app.post/login~.  Now we need to authenticate the user.  We're gong to add a
middleware function here, ~authenticate~.  We'll have our =UTIL FUNCTIONS=.
~authenticate()~ will be one of those that takes a =request=, a =response= and
a =next=.

#+name:angularjs-auth-jwt-app--login-route
#+begin_src js
app.post('/login', authenticate, function(req, res) {
    res.send(user);
});

#+end_src

**** Add a =UTIL FUNCTIONS= Section for Authentication Middleware

#+caption:Authentication Middleware
#+name:angularjs-auth-jwt-app--utils-functions
#+begin_src js :noweb yes
//UTIL FUNCTIONS

function authenticate(req, res, next) {
    var body = req.body;
    <<angularjs-auth-jwt-app--require-username-password>>
    <<angularjs-auth-jwt-app--check-username-password>>
    next();
}
#+end_src

**** Install ~body-parser~
02:13 Now we need to be able to read the JSON that comes back in the =request=:
specifically, the =username= and =password=.

02:21 To do that we're going to install a module called ~body-parser~.  That
will give Express the ability to parse the body that comes in.  We'll ~require
body-parser~, and just like with CORS, we'll say, ~app.use(bodyParser.json())~.

#+name:install-body-parser
#+begin_src sh :dir angularjs-auth-jwt :results output :exports both
yarn add body-parser
#+end_src

#+call:list-package.json()

#+name:angularjs-auth-jwt-app--requires3
#+begin_src js :noweb yes
<<angularjs-auth-jwt-app-requires2>>
const bodyParser = require('body-parser');
#+end_src

#+name:angularjs-auth-jwt-app--use_bodyParser
#+begin_src js
app.use(bodyParser.json());
#+end_src

02:36 Now we have a =body= on the =request=.  If there's not a =body.username=
or not a =body.password= then we'll send back a response with status of 400 and
a message, "Must provide user name or password."

#+name:angularjs-auth-jwt-app--require-username-password
#+begin_src js
if (!body.username || !body.password) {
    res.status(400).end('Must provide username and password');
    return;
}

#+end_src

**** Add a User and Password
02:52 Now we need to have a username and password to check against.  Normally
you would obviously store all of your users in a database but in our case, just
to make things simple, we're going to make a mini-database here that's just a
variable user, which is an object with a =username= of "kentcdodds" and a
=password= of =p=.

#+name:angularjs-auth-jwt-app--mini-database
#+begin_src js
let user = {
    username: 'John Q. Smith',
    password: 'q'
};
#+end_src

03:11 If the ~body.username~ is not equal to the ~user.username~ or the
~body.password~ is not equal to the ~user.password~, then we'll send back a
status of 401, and a message "User name or password incorrect."

#+name:angularjs-auth-jwt-app--check-username-password
#+begin_src js
if (body.username !== user.username || body.password !== user.password) {
    res.status(401).end('Username-Password combination not correct');
    return;
}

#+end_src

03:30 Then we'll send them to the next function handler.

**** Testing Login
03:33 If they made it this far we know that they are authenticated.  We'll
simply send the user back.  We'll refresh the page.  Now, if we log in you see
we've got no error.  If we look in our network tab here we'll try and log in
again.

03:45 We hit the log in and let's make this big here.  Look at the preview.  We
have the password and user name.  We have the whole user object.

03:53 Obviously, generally you wouldn't want to send a password over the wire
but we'll just be simple for now.

03:58 That's a simple log in authentication.  We can still hit the endpoint to
get random users.  We can still get the random user here.

04:07 Our next video is going to be protecting this resource behind
authentication. That's where we'll start to use JWS.

**** server3 Code and Makefile
***** Code for server3

#+caption:Code for @code{server3.js}
#+name:angularjs-auth-jwt-server3.js
#+begin_src js :tangle angularjs-auth-jwt/server3.js :mkdirp yes :noweb tangle
<<angularjs-auth-jwt-app--requires3>>

<<angularjs-auth-jwt-app--mini-database>>

<<angularjs-auth-jwt-app>>
<<angularjs-auth-jwt-app--use_cors>>
<<angularjs-auth-jwt-app--use_bodyParser>>

<<angularjs-auth-jwt-app--random-route>>
<<angularjs-auth-jwt-app--login-route>>
<<angularjs-auth-jwt-app--listen>>

<<angularjs-auth-jwt-app--utils-functions>>
#+end_src

***** Makefile for server3

#+caption:Makefile for server3
#+name:angularjs-auth-jwt-makefile-server3
#+begin_src make :tangle angularjs-auth-jwt/Makefile :mkdirp yes
.phony : server3
server3 : SERVER = server3
server3 : server
	@:

#+end_src

*** JWT Authentication Setup on the Server
Adding JWT support to the server.  Signing a JSON object as a payload and
sending the signed token to the browser on authentication.

**** Setup Authentication
00:01 Here we have our application. I can log in, no errors, so it's
successful.  If I give it the wrong password, I get an error.  If I don't give
it a password at all, I get an error.

00:09 The problem with this application is I can still get a random user
without being authenticated and we want to protect that resource.

00:15 The first step for doing that from here is to implement JWTs on the
server.  We're going to need a module called ~jsonwebtoken~.  We'll ~require~
that and we'll call it ~jwt = jsonwebtoken~.

#+name:install-jsonwebtoken
#+begin_src sh :dir angularjs-auth-jwt :results output :exports both
yarn add jsonwebtoken
#+end_src

#+call:list-package.json()

#+name:angularjs-auth-jwt-app--requires4
#+begin_src js :noweb yes
<<angularjs-auth-jwt-app--requires3>>
const jwt = require('jsonwebtoken');
#+end_src

**** What a JWT Is
00:28 I'm just going to explain, really quickly, what a JWT is.

00:31 JSON Web Token is a specification for authentication.  A JWT is an
encoded JSON object that the server encodes using a secret key.  The encoded
JSON object is called a {{{dfn(token)}}}.  That token is sent to the client
when the client authenticates.  Then the client sends that token back on every
single request.

00:55 The server, at that point, will decode that token using the same private
key, so that it can identify who the user is and act accordingly.  What we're
going to do is set up the encoding of that token.

**** Create a JWT with a Secret
01:07 For simplicity's sake, we're going to create a JWT secret here and we'll
just make it a bunch of random characters.  Normally, you would want this to be
stored in an environment variable or some other secure place, but we'll just
leave it as a string in our app.

#+name:angularjs-auth-jwt-app--jwtSecret
#+begin_src js
var jwtSecret = 'dkekdkd9&dksk!KD80zen>'
#+end_src

01:23 Now, we want to encode the user object when the user authenticates.  If
we scroll down here (to the =POST /login= route), instead of sending the
=user=, we're going to want to send a token.  We'll create that token now.
Token is a JWT.sign and the payload is what is going to be the encoded object.
We'll just encode the username for now, but there is an entire specification on
what you should actually include in this that you can read up on.  For our
purposes, the username is sufficient.

01:54 Then we're going to give that secret that we set up earlier.

01:57 Now we have the token and we're going to send back the token to the
client.  Just for simplicity's sake, we'll send back the user as well.

#+name:angularjs-auth-jwt-app--login-route---token
#+begin_src js
app.post('/login', authenticate, function(req, res) {
    var token = jwt.sign({
        username: user.username
    }, jwtSecret);
    res.send({
        token: token,
        user: user
    });
});

#+end_src

**** Sending Back the Token
02:07 On the front end --- before we were expecting a user with this login
response --- now we're getting an object that has the user on it.  We'll say
~vm.user = response.data.user~.  We'll just alert with the
~response.data.token~.

#+caption:Login function and Handle Errors on App Controller with Token
#+name:aaja3-login
#+begin_src js
vm.login = login;

function login(username, password) {
    UserFactory.login(username, password).then(function success(response) {
        vm.user = response.data.user;
        alert("TOKEN: " + response.data.token);
    }, handleError);
}

#+end_src

#+caption:Login on the App controller with Token
#+name:angularjs-auth-jwt-app3--controller.MainCtrl
#+begin_src js :noweb yes
app.controller('MainCtrl', function MainCtrl(RandomUserFactory, UserFactory) {
    'use strict';
    var vm = this;

    <<aaja2-getRandomUser>>
    <<aaja3-login>>
    <<aaja2-handleError>>
})
#+end_src

02:24 We'll refresh and we'll go ahead and type in the username and
password.  We got a big, honking error.  Let's just go ahead and look at what
that is here.  It looks like the =username= is not defined.  We'll go to our server
and, lo and behold, it's =user.username=.

02:43 We don't need to refresh the page, because the server and the client are
totally served up on separate servers.  We can just go ahead and log in now.
That's our token.

**** Review the Use of Tokens in Accessing Protected Resources
02:56 In future requests, we need to store this token somewhere so that it can
be sent to the server over and over and over again for every protected resource
request.  Then the server can decode it back into this payload to identify who
the user is and protect the resource that way.

03:16 Just to recap here.  The client will send a request to log in and here we
have that token.  If we look at the request, we can see here we're sending the
=username= and =password=.  If we look here, we go to =authenticate=, we double
check that the =username= and =password= are correct, and then we'll sign this
token with the username and with that JWT secret.  Then we'll send the token
and the user across the wire.

03:46 If we look at the response here, you can see the token and the user comes
back in the response.  In future requests, that token will be used to make
those requests to identify the user.  We'll talk about that in the next video.

**** Code for server4 and app3 and Makefile

***** Code for server4

#+caption:Code for @code{server4.js}
#+name:angularjs-auth-jwt-server4.js
#+begin_src js :tangle angularjs-auth-jwt/server4.js :mkdirp yes :noweb tangle
/*--- requirements ---*/
<<angularjs-auth-jwt-app--requires4>>

/*--- jwtSecret ---*/
<<angularjs-auth-jwt-app--jwtSecret>>

/*--- mini-database ---*/
<<angularjs-auth-jwt-app--mini-database>>

/*--- app and app middlewares ---*/
<<angularjs-auth-jwt-app>>
<<angularjs-auth-jwt-app--use_cors>>
<<angularjs-auth-jwt-app--use_bodyParser>>

/*--- app routes ---*/
<<angularjs-auth-jwt-app--random-route>>
<<angularjs-auth-jwt-app--login-route---token>>

/*--- app listen ---*/
<<angularjs-auth-jwt-app--listen>>

/*--- util functions ---*/
<<angularjs-auth-jwt-app--utils-functions>>
#+end_src

***** Code for app3

#+caption:@file{app3.js} Code
#+name:angularjs-auth-jwt-app3.js
#+begin_src js :tangle angularjs-auth-jwt/public/app3.js :noweb yes :mkdirp yes
(function() {
    'use strict';
    <<angularjs-auth-jwt-app--var_app>>
    <<angularjs-auth-jwt-app--const_API_URL>>
    <<angularjs-auth-jwt-app3--controller.MainCtrl>>
    <<angularjs-auth-jwt-app--RandomUserFactory>>
    <<angularjs-auth-jwt-app2--UserFactory>>
})()
#+end_src

***** Code for index3.html
This code addes a =Welcome= heading to indicate when a user is logged in.  It
is actually added in the next section, but belongs here with ~app3~.

#+caption[angularjs-auth-jwt-index3.html]:Code for the AngularJS Auth Jwt @code{index2.html} file
#+name:angularjs-auth-jwt-index3.html
#+begin_src html :tangle angularjs-auth-jwt/public/index3.html :mkdirp yes :noweb tangle
<!DOCTYPE html>
<<angularjs-auth-jwt-index--html---angular_app>>
    <head lang="en">
        <meta charset="UTF-8">
        <<angularjs-auth-jwt-index--head---title>>
    </head>

    <<angularjs-auth-jwt-index--body---MainCtrl_vm>>
        <<angularjs-auth-jwt-index--body---h1.get_random_user>>

        <<angularjs-auth-jwt-index2--authentication-form>>

        <<angularjs-auth-jwt-index--body---button.get_random_user----Welcome>>

        <<angularjs-auth-jwt-index--body---scripts>>

    </body>
</html>

#+end_src

***** Makefile for server4 and app3

#+name:angularjs-auth-jwt-makefile-server4
#+begin_src make :tangle angularjs-auth-jwt/Makefile :mkdirp yes
.phony : server4
server4 : SERVER = server4
server4 : server
	@:

.phony : app3
app3 : APP = app3
app3 : INDEX = index3
app3 : app
	@:

#+end_src
*** Auth Interceptor in Angular for JWT
Adding JWT support to the client.  Storing the token in local storage, then
creating a HTTP interceptor to add the token to requests made to the
server.  Also implementing =logout=.

**** Updating the Front End for Login
00:01 OK, so here we have our application.  We can login, and get users.  We
don't have to be logged in to get users, and that's what we want to try and
protect.  Also, we don't actually know if we're logged in from the UI, so we're
just going to add this really quickly.  We'll say =<h2>Welcome
{{vm.user.username}}</h2>=.

See [[*Set Up the Logout User Feature][Set Up the Logout User Feature]] for the =Logout= information.

#+caption:Get User button with Welcome
#+name:angularjs-auth-jwt-index--body---button.get_random_user----Welcome
#+begin_src html
<div>
  <h2>Welcome {{vm.user.username}}</h2>
  <button ng-click="vm.logout()">Logout</button>
  <br />
  <button ng-click="vm.getRandomUser()">Get User</button>
  <pre ng-bind="vm.randomUser | json"></pre>
</div>
#+end_src

00:26 I'm not going to hide this. Normally you'd want to hide this if there is
no ~VM.user~, because this really doesn't make sense, but I'm going to keep it
here because we can still get users, and I want to show that until that
resource is protected.  Anyway, if we login here, now we can see, we do actually
login, that comes from the server.  Here we have our application.

00:46 There are a couple of things that we want to do to this application.  If
you recall from previous videos, when we login, the server is sending us back a
token, and we want to save that token, and send it on every request to a
protected resource, and so that's what we're going to do in this video, is save
this token in local storage, and then set up sending that token on every
protected resource request, and then we'll also implement logout.

**** Save the Token to Local Storage

***** Create an AuthTokenFactory
01:14 Let's go ahead and set up saving this to local storage.  We're going to
create a =Factory= that will manage our token for us.  We'll just say
~app.factory~, and it'll be an =AuthTokenFactory=, and this will be a simple
factory, it'll have a =getToken=, and a =setToken=, which will take a =token=.
We're going to inject =window= in here so that we can get our =store=, which
will be local storage.  Then we'll have a =key=, and that will be =auth-token=,
and then we'll have our =getToken=, and =setToken=.

01:52 Then here (~function getToken()~), =getToken= will just simply return
=store.getitemkey=, and (~function setToken()~) our =setToken= will say if a
=token= is provided then we'll say =store.setItem(key,token)= else
=store.removeItem=.  Now we have our =AuthTokenFactory=.

#+name:angularjs-auth-jwt-app4--AuthTokenFactory
#+begin_src js
app.factory('AuthTokenFactory', function AuthTokenFactory($window) {
    'use strict';
    var store = $window.localStorage;
    var key = 'auth-token';
    return ({
        getToken: getToken,
        setToken: setToken
    });

    function getToken() {
        return store.getItem(key);
    }

    function setToken(token) {
        if (token) {
            store.setItem(key, token);
        } else {
            store.removeItem(key);
        }
    }
});
#+end_src

***** Login and Save Token using AuthTokenFactory.setToken
When we login, we want to save this token, so we'll add a ~then~ here.  Here
we'll take =AuthTokenFactory= and =setToken= to the =response.data.token=, and
then we'll return the response for future items in the chain.

#+name:angularjs-auth-jwt-app4--UserFactory---save-token
#+begin_src js :noweb yes
app.factory('UserFactory', function UserFactory($http, API_URL, AuthTokenFactory) {
    'use strict';
    return ({
        login: login,
        logout: logout
    });

    function login(username, password) {
        return $http.post(API_URL + '/login', {
            username: username,
            password: password
        }).then(function success(response) {
            AuthTokenFactory.setToken(response.data.token);
            return response;
        });;
    }

    <<aaja4-userfactory--logout>>
});
#+end_src

***** Test for a Saved Token in Local Storage
02:31 We'll need to inject the auth token factory.  Now let's go ahead and see
this in action.  If I refresh the page, get that new client code, we'll say
'kentcdodds' 'p' =login=, and let's look at our local storage here, and our
resources.  There we have our =auth-token=.

Now we're storing our token in our local storage, and we want to us it on
request to protected resources, and so now we're going to use what in Angular
is called an =Interceptor=, and we're going to create that as a Factory.

**** Add Bearer Token to Each Request with an Angular Interceptor
03:04 We'll say ~app.factory~, it will be our =AuthInterceptor=, and
interceptors have a couple of cool things on them.  You have the =request=, the
=requestError=, =response=, and =responseError=.  Each one of them is doing
different things to the HTTP config.  The one that we care about is the
=request=, so we'll have =request= and it will be =addToken=, and then here
we'll implement that.  It'll take the =config=, and it'll return the =config=.

03:35 Here we'll have a =token=, and let's inject our =AuthTokenFactory=, and
will get the =token=.  Now if there is a =token=, so if the user is
authenticated, then we're going to add this to a header on this =config=
object, so we'll say ~config.headers~ is equal to ~config.headers~ or an empty
object, just to kind of protect ourselves there.  Then we'll say
=Authorization= equals 'bearer ' plus the =token=, and this is just part of the
spec.  It's the =Authorization= header; it's prefixed with =Bearer= space, and
then the =token=.

#+caption:Adding Bearer Token to Authorization Header
#+name:angularjs-auth-jwt-app4--AuthInterceptor
#+begin_src js
app.factory('AuthInterceptor', function AuthInterceptor(AuthTokenFactory) {
    'use strict';
    return ({
        request: addToken
    });

    function addToken(config) {
        var token = AuthTokenFactory.getToken();
        if (token) {
            config.headers = config.headers || {};
            config.headers.Authorization = 'Bearer ' + token;
        }
        return config;
    }
});
#+end_src

04:16 Now we're sending the =token= on every HTTP request. But not quite
actually.  We do need to do one more thing, and that is in our =app= config
(~angular.module()~), we need to inject =$httpProvider=.  On that
=$httpProvider=, it has an array called =interceptors=.  We're going to push on
that array, just a string, that is the name of our =Interceptor=.  Angular will
look up this =Interceptor=, and every single request that =$http= makes will
pass through our function that we defined down here, this =addToken= function.

#+caption:Add AuthInterceptor to ~app config~
#+name:angularjs-auth-jwt-app--var_app4---interceptor
#+begin_src js
var app = angular.module('app', [], function config($httpProvider) {
    $httpProvider.interceptors.push('AuthInterceptor');
});
#+end_src

***** Verifying the Authorization Bearer Token on a Request
04:51 We can see that in action here.  Let's refresh our client code, we'll say
'kentcdodds' 'p', and let's go ahead and look at our network tab.  We login,
and we can see the =token= is given to us.

[[file:./resources/angularjs-auth-jwt--token-after-login-40.png]]

We can see in here in our resources we have that =token= there.

[[file: ./resources/angularjs-auth-jwt--token_in_local_storage-40.png]]

Now if we say =Get User=, we'll click here, look at our headers, and it's right
there, our =auth= =Authorization= header with the =Bearer= and the =token=.

[[file:./resources/angularjs-auth-jwt--authorization_bearer_token-40.png]]

**** Set Up the Logout User Feature
05:21 Now we need to alter the server to take this =token= into account when
=Get User= is invoked so that that resource can be protected.  That's what
we'll do in the next video.

One more thing that we want to do in here that I want to show you is how easy
it is to logout.  We have this =auth-token= in here (local storage), we're
logged in, and it's very simple to add a =Logout= button (to ~index.html~), so
we'll just do that now.

{{{heading(Add a Logout Button to =index.html=)}}}

05:45 We'll create a button called =Logout=.  I'll just add a break =<br />=
here, and we'll say =ngclick= is equal to =vm.logout=.

{{{heading(Add a logout function to the app)}}}

And then up here (in in ~app.controller~) we'll say =vm.logout= is equal to
=logout=, and we'll create =logout= here, and we'll say =UserFactory.logout=
equals =logout=. <<vm.user-null>>

#+caption:Logout Functionality
#+name:aaja4-logout
#+begin_src js
vm.logout = logout;
function logout() {
    UserFactory.logout();
    vm.user = null;
}
#+end_src

#+caption:Login on the App controller with Token
#+name:angularjs-auth-jwt-app4--controller.MainCtrl
#+begin_src js :noweb yes
app.controller('MainCtrl', function MainCtrl(RandomUserFactory, UserFactory) {
    'use strict';
    var vm = this;

    <<aaja2-getRandomUser>>
    <<aaja3-login>>
    <<aaja4-logout>>
    <<aaja2-handleError>>
})
#+end_src

Then in our =UserFactory= where we have it =login=, we'll have it =logout=.
Then well logout, and we say that =AuthTokenFactory.setToken()= to nothing, and
that will remove the =token= from local storage, because that's how we
implemented it down here.

#+name:aaja4-userfactory--logout
#+begin_src js
function logout() {
    AuthTokenFactory.setToken();
}
#+end_src

06:29 Then for the view side of things (back to ~app.controller~, see [[vm.user-null][above]]),
will say =vm.user= equals =null=.

If we refresh the page, you can see the =auth-token= is still there, and we
don't have any logic to automatically log the user in to the client, and we'll
build that in the future.  But here we have the user logged in, now we have
this =Logout= button.  If we click =Logout=, you can see that the =auth-token=
is removed from local storage, and no longer is the user name appearing here.

**** Review of Authorization Bear Token Functionality and Logout
06:55 If we refresh, that key is still gone, and then we can login and logout.
Just in review, we simply added a =AuthTokenFactory= to store the =auth-token=
in local storage, and then we get that =token= from local storage on every
single request using our =AuthInterceptor=, and attaching it to the
=Authorization= header, with =Bearer = and =token=.  Then we take that
=AuthInterceptor= and push it onto the =interceptors= of the =$httpProvider=.

{{{heading(Review of Logout)}}}

07:27 We also implemented a =logout= function that simply set the =user= to
null, and removed the =token= from local storage.

In the next video, we'll talk about what we need to do to make it so that when
a request is made to get a random user, the server will take that token into
account, and protect that resource to only those who have a signed, verified
=token=.  That's what we'll see in the next video.

**** Code for app4 and Makefile

***** Code for app4
#+caption:Code for app4.js with Authorization Bearer Token
#+name:angularjs-auth-jwt-app4.js
#+begin_src js :tangle angularjs-auth-jwt/public/app4.js :noweb yes :mkdirp yes
(function() {
    'use strict';
    <<angularjs-auth-jwt-app--var_app4---interceptor>>
    <<angularjs-auth-jwt-app--const_API_URL>>
    <<angularjs-auth-jwt-app4--controller.MainCtrl>>
    <<angularjs-auth-jwt-app--RandomUserFactory>>
    <<angularjs-auth-jwt-app4--UserFactory---save-token>>
    <<angularjs-auth-jwt-app4--AuthTokenFactory>>
    <<angularjs-auth-jwt-app4--AuthInterceptor>>
})()
#+end_src

***** Makefile for app4 and index3
#+name:Makefile app4
#+begin_src make :tangle angularjs-auth-jwt/Makefile :mkdirp yes
.phony : app4
app4 : APP = app4
app4 : INDEX = index3
app4 : app
	@:

#+end_src

*** Finalizing JWT Authentication with AngularJS
Adding middleware to the node server to decode and verify the token sent from
the client. And tidying up the rest of the application. Finally, a walkthrough
of the whole process.

**** Set Up the Server for Authentication
00:00 OK, so now here we have our application.  Let's just make sure it's all
working here.  We can login, we can logout, we can get users whether or not we
are logged in.  This is what we are trying to protect.  If we look in our local
storage here, because I logged out there's nothing in here, but if I login
again it is in here.  I logout, it goes away.  If I'm logged in and I say =Get
User=, then I'm sending the =Authorization= header with the =token= that the
server gave to me in this =Login= request.

00:36 Now what we need to do is set up the server so that it will take this
=Authorization= header into account when this get user endpoint is hit.  This
is actually very simple with a module that we have called ~express-jwt~.  We'll
go ahead and install that using =npm install express-jwt=, and then up here
we'll simply ~require(express-jwt)~, and then it's as simple as an ~app.use
express-jwt~.  This will take a secret, and we'll use the same =jwtSecret=.

#+name:install-express-jwt
#+begin_src sh :dir angularjs-auth-jwt :results output :exports both
yarn add express-jwt
#+end_src

#+call:list-package.json()

#+name:angularjs-auth-jwt-app--requires5
#+begin_src js :noweb yes
<<angularjs-auth-jwt-app--requires4>>
const expressJwt = require('express-jwt');
#+end_src

01:19 Because this is going to be verifying our tokens, we need to verify it
with the same secret.  That's actually everything that we need to do.  However,
when a user is logging in, they obviously won't have a token, and so we need to
add =unless=, on this middleware, and we'll say the path is in this
array =[ /login ]=.  Now =expressJwt=, under the covers, is going to intercept all of
the requests that come in.

#+name:angularjs-auth-jwt-app--use_expressJwt
#+begin_src js
app.use(expressJwt({ secret: jwtSecret }).unless({ path: [ '/login' ]}));
#+end_src

01:52 It will take this =Authorization= header, with the =Bearer= and the
=token=, it will decode that =token= using the =jwtSecret=.  If it does decode
properly, and the signature is verified, then it will add =user= to the request
object, and the =user= property will simply be the decoded JSON object.  We're
going to see what that looks like here in a moment, but let's go ahead and see
what breaks here.

**** Check that the Server Protects the random-user Resource
02:20 I'm pointing to the server directly, to the =/random-user= endpoint, and
if I refresh here, now I'm getting an =Unauthorized= error, "No authorization
header was found."  If I refresh here, I'm not logged in, I say get...Oh, except
I think that I am logged in.  Refresh here, OK, "No authorization header was
found," and the error is coming from this =expressJwt=.

02:45 With just these two lines, we were able to take our application and add
=expressJwt=.  Obviously we do have this =jwt.sign()=ing, so that's a couple of
extra lines, but it's actually very simple to add this authentication scheme to
a Node application.

**** Update the Front End to Be More Sensible
We do have a couple of more things that we want to do on the front end to make
things a little more sensible.  If I go ahead and login here, I login.

03:09 Now I have, in our resources, I have that =auth-token=.  We'll clear our
network here, say =Get User=, and I can get the =user=.  We can see on here I
have the =Authorization= header, so that's why I was able to get through.  If I
refresh the page, you'll see it's not showing that I'm logged in, but when I
get the user everything works out fine, because I do have that token locally in
the client.

***** Automatic Login
03:35 What we want to implement now is to be automatically logged in when we
refresh the page if we have the =token= locally.

Let's go to our app, and we'll have this initialization step in our controller,
and we'll say, =UserFactory.getUser().then= we'll say =vm.user= is equal to the
data that comes back, =response.data=.

#+caption:App Controller Initialization
#+name:aaja5-initialization
#+begin_src js
UserFactory.getUser().then(function success(response) {
    vm.user = response.data;
});
#+end_src

#+caption:Automatic Login in app5
#+name:angularjs-auth-jwt-app5--controller.MainCtrl
#+begin_src js :noweb yes
app.controller('MainCtrl', function MainCtrl(RandomUserFactory, UserFactory) {
    'use strict';
    var vm = this;

    /* Get Random User */
    <<aaja2-getRandomUser>>
    /* Login and Logout */
    <<aaja3-login>>
    <<aaja4-logout>>
    /* Initialization */
    <<aaja5-initialization>>
    /* Handle Error */
    <<aaja2-handleError>>
})
#+end_src

and so let's go to our =UserFactory=, and will add a =getUser= function here,
and we'll define that down here.  We'll simply say if
=AuthTokenFactory.getToken()=, so if there is a token in existence, then we can
return =$http.get(API_URL + '/me')=.

04:30 Otherwise we'll return =$q.reject=, with the "data client has no auth
token".  We'll need to inject =$q= here (in ~app.factory~).

#+name:aaja5-userfactory--getUser
#+begin_src js
function getUser() {
    if (AuthTokenFactory.getToken()) {
        return $http.get(API_URL + '/me');
    } else {
        return ($q.reject({ data: 'client has no auth token' }));
    }
}
#+end_src

#+name:angularjs-auth-jwt-app5--UserFactory---getUser
#+begin_src js :noweb yes
app.factory('UserFactory', function UserFactory($http, API_URL, AuthTokenFactory, $q) {
    'use strict';
    return ({
        login: login,
        logout: logout,
        getUser: getUser
    });

    function login(username, password) {
        return $http.post(API_URL + '/login', {
            username: username,
            password: password
        }).then(function success(response) {
            AuthTokenFactory.setToken(response.data.token);
            return response;
        });;
    }

    <<aaja4-userfactory--logout>>
    <<aaja5-userfactory--getUser>>
});
#+end_src

***** Implement the /me Endpoint
Now we need to implement this =/me= endpoint.  We'll go back to our server and
just right here we'll say =app.get('/me')=.  Because we have this =expressJwt=
here, and the only path that is being excluded is the =/login=, we can know
that this =/me= is being protected by this =express.Jwt=, so no =request= will
come through to =/me= unless they pass through this =expressJwt= first.

05:20 We can rely on the fact that the user is authenticated at this point, and
=express.Jwt= will put the decoded =token= onto the =user= object, and so I can
simply just say =res.send(req.user)=.

#+name:angularjs-auth-jwt-app5--me-route
#+begin_src js
app.get('/me', function(req, res) {
    res.send(req.user);
});
#+end_src

***** Check Automatic Login Functionality
This is very simple; so all of this should work, assuming I didn't break
anything.  Let's just double check in our resources.  We have the =auth-token=,
now if I refresh... There we go, Kent C Dodds, we're automatically logged in,
and we can get the users right from the get go.

05:56 If we logout, there's no token in here. Oops. We'll refresh, and now
we're not able to get any users, and so that's the basic gist of what we're
trying to accomplish in the series.

***** Show and Hide Based Upon Login Status
Actually, there's one other thing that we want to do, and that's just for the
fun of it.  In ~index.html~, at the login form, we'll say =ng-show=, or
actually we'll say =ng-hide=; when there's a =vm.user= we'll hide this, and, at
the =Welcome= message, =ng-show= when there is a =vm-user=.  Now let's refresh.

#+caption:Login Form that hides and shows
#+name:angularjs-auth-jwt-index4--authentication-form-show-hide
#+begin_src html
<div ng-hide="vm.user">
  <form ng-submit="vm.login(vm.username, vm.password)">
    <label>Username: <input type="text" ng-model="vm.username" /></label><br/>
    <label>Password: <input type="password" ng-model="vm.password" /></label><br />
    <button type="submit">Login</button>
  </form>
</div>
#+end_src

#+caption:Get User button with Welcome that shows and hides
#+name:angularjs-auth-jwt-index--body---button.get_random_user----Welcome-show-hide
#+begin_src html
<div ng-show="vm.user">
  <h2>Welcome {{vm.user.username}}</h2>
  <button ng-click="vm.logout()">Logout</button>
  <br />
  <button ng-click="vm.getRandomUser()">Get User</button>
  <pre ng-bind="vm.randomUser | json"></pre>
</div>
#+end_src

***** Check Show and Hide Functionality
06:28 Now it makes more sense. Get random user. We'll login, and we'll login
with the wrong password, password/username incorrect.  We login without a
password... OK, so all of our error handling is working.  Now we login, here we
have... and now we can get the =user=, and we can logout, and go back and forth
that way.  If we just hit the endpoint directly, "No authorization header
found," and so this application is a working application, and that is what
we've created using JWTs.

**** Overall Review of the Working Application
06:59 Let's just take this full circle and explain what's happening here.
We'll refresh the page here, we'll clear out here.  We login with 'kentcdodds',
and 'p' as our password.  We send that with this login request.  Let's make
this big here.  The payload is the =password= and =username=.  Then the server
returns us a signed =token= with a secret that only the server knows about, and
the =user=.

07:28 Then behind the scenes on the client we add an =auth-token= to local
storage, and that we have an =AuthInterceptor= that will intercept every
request that we make with HTTP, and add this =auth-token= to our request.  If
we look at our network tab here again, say "Get User," we get the =user=, and
here in our headers we have that =Authorization= header with the =Bearer= and
the =token=.  Then when we want to logout, let's take a look at our resources
here.

07:59 We say =Logout=, and that =auth-token= is removed from local storage, and
the =user= on the view model is set to =null=, and so our view updates as
well.  That's the application, that's JWTs with Angular.

**** Code for server5 and app5

***** Code for server5

#+caption:Code for @code{server5.js}
#+name:angularjs-auth-jwt-server5.js
#+begin_src js :tangle angularjs-auth-jwt/server5.js :mkdirp yes :noweb tangle
/*--- requirements ---*/
<<angularjs-auth-jwt-app--requires5>>

/*--- jwtSecret ---*/
<<angularjs-auth-jwt-app--jwtSecret>>

/*--- mini-database ---*/
<<angularjs-auth-jwt-app--mini-database>>

/*--- app and app middlewares ---*/
<<angularjs-auth-jwt-app>>
<<angularjs-auth-jwt-app--use_cors>>
<<angularjs-auth-jwt-app--use_bodyParser>>
<<angularjs-auth-jwt-app--use_expressJwt>>

/*--- app routes ---*/
<<angularjs-auth-jwt-app--random-route>>
<<angularjs-auth-jwt-app--login-route---token>>
<<angularjs-auth-jwt-app5--me-route>>

/*--- app listen ---*/
<<angularjs-auth-jwt-app--listen>>

/*--- util functions ---*/
<<angularjs-auth-jwt-app--utils-functions>>
#+end_src

***** Code for app5
#+caption:Code for app5.js with Automatic Login
#+name:angularjs-auth-jwt-app5.js
#+begin_src js :tangle angularjs-auth-jwt/public/app5.js :noweb yes :mkdirp yes
(function() {
    'use strict';
    <<angularjs-auth-jwt-app--var_app4---interceptor>>
    <<angularjs-auth-jwt-app--const_API_URL>>
    <<angularjs-auth-jwt-app5--controller.MainCtrl>>
    <<angularjs-auth-jwt-app--RandomUserFactory>>
    <<angularjs-auth-jwt-app5--UserFactory---getUser>>
    <<angularjs-auth-jwt-app4--AuthTokenFactory>>
    <<angularjs-auth-jwt-app4--AuthInterceptor>>
})()
#+end_src

***** Code for index4

#+caption[angularjs-auth-jwt-index4.html]:Code for the AngularJS Auth Jwt @code{index4.html} file
#+name:angularjs-auth-jwt-index4.html
#+begin_src html :tangle angularjs-auth-jwt/public/index4.html :mkdirp yes :noweb tangle
<!DOCTYPE html>
<<angularjs-auth-jwt-index--html---angular_app>>
    <head lang="en">
        <meta charset="UTF-8">
        <<angularjs-auth-jwt-index--head---title>>
    </head>

    <<angularjs-auth-jwt-index--body---MainCtrl_vm>>
        <<angularjs-auth-jwt-index--body---h1.get_random_user>>

        <<angularjs-auth-jwt-index4--authentication-form-show-hide>>

        <<angularjs-auth-jwt-index--body---button.get_random_user----Welcome-show-hide>>

        <<angularjs-auth-jwt-index--body---scripts>>

    </body>
</html>

#+end_src

***** Makefile for server5

#+name:angularjs-auth-jwt-makefile-server5
#+begin_src make :tangle angularjs-auth-jwt/Makefile :mkdirp yes
.phony : server5
server5 : SERVER = server5
server5 : server
	@:

.phony : app5
app5 : APP = app5
app5 : INDEX = index4
app5 : app
	@:

#+end_src


** Reference
*** RFC 7797
- https://tools.ietf.org/html/rfc7519

**** Abstract
JSON Web Token (JWT) is a compact, URL-safe means of representing /claims/ to
be transferred between two parties.  The /claims/ in a JWT are encoded as a
JSON object that is used as the /payload/ of a JSON Web Signature (JWS)
structure or as the plaintext of a JSON Web Encryption (JWE) structure,
enabling the claims to be digitally signed or integrity protected with a
Message Authentication Code (MAC) and/or encrypted.

- claims
- payload
- JSON Web Signature structure (JWS) [[https://www.rfc-editor.org/info/rfc7515][RFC 7515]]
- JSON Web Encryption structure (JWE) [[https://tools.ietf.org/html/rfc7516][RFC 7516]]
- digital signature
- integrity protected
- Message Authentication Code (MAC)
- Base64url Encoding

The terms "JSON Web Signature (JWS)", "Base64url Encoding", "Header Parameter",
"JOSE Header", "JWS Compact Serialization", "JWS Payload", "JWS Signature", and
"Unsecured JWS" are defined by the JWS specification:
- https://tools.ietf.org/html/rfc7519#ref-JWS

*JSON Web Signature (JWS)* represents content secured with digital signatures
or Message Authentication Codes (MACs) using JSON-based data structures.
Related encryption capabilities are described in the separate JSON Web
Encryption (JWE) specification.  The JWS cryptographic mechanisms provide
integrity protection for an arbitrary sequence of octets.
- https://www.rfc-editor.org/rfc/rfc7515.txt


*JSON Web Encryption (JWE)* represents encrypted content using JSON-based data
structures.  Cryptographic algorithms and identifiers for use with this
specification are described in the separate JSON Web Algorithms (JWA)
specification and IANA registries defined by that specification.  The JWE
cryptographic mechanisms encrypt and provide integrity protection for an
arbitrary sequence of octets.
- https://tools.ietf.org/html/rfc7516

Two closely related serializations for JWEs are defined.  The JWE Compact
Serialization is a compact, URL-safe representation intended for space
constrained environments such as HTTP Authorization headers and URI query
parameters.  The JWE JSON Serialization represents JWEs as JSON objects and
enables the same content to be encrypted to multiple parties.  Both share the
same cryptographic underpinnings.
- https://tools.ietf.org/html/rfc7516

**** Introduction
JSON Web Token (JWT) is a compact /claims representation format/ intended for
space constrained environments such as HTTP Authorization headers and URI query
parameters.

JWTs encode /claims/ to be transmitted as a JSON [RFC7159] object that is used
as the payload of a JSON Web Signature (JWS) [JWS] structure or as the
plaintext of a JSON Web Encryption (JWE) [JWE] structure, enabling the /claims/
to be digitally signed or integrity protected with a Message Authentication
Code (MAC) and/or encrypted.

 The suggested pronunciation of JWT is the same as the English word "jot".

**** Definitions

- JSON Web Token (JWT) ::

     A string representing a set of claims as a JSON object that is encoded in
     a JWS or JWE, enabling the claims to be digitally signed or MACed and/or
     encrypted.

- JSON Web Signature (JWS) ::

     A data structure representing a digitally signed or MACed message.

- JOSE Header ::

                 JSON object containing the parameters describing the
                 cryptographic operations and parameters employed.  The JOSE
                 (JSON Object Signing and Encryption) Header is comprised of a
                 set of Header Parameters.

- JWS Payload ::
                 The sequence of octets to be secured -- a.k.a. the message.
                 The payload can contain an arbitrary sequence of octets.

- JWS Signature ::

                   Digital signature or MAC over the JWS Protected Header and
                   the JWS Payload.

- Base64url Encoding ::

     Base64 encoding using the URL- and filename-safe character set defined in
     Section 5 of RFC 4648 [RFC4648], with all trailing '=' characters omitted
     (as permitted by Section 3.2) and without the inclusion of any line
     breaks, whitespace, or other additional characters.

- JSON Web Encryption (JWE) ::

     A data structure representing an encrypted and integrity-protected
     message.  JWE represents encrypted content using JSON data structures and
     base64url encoding.

- JWT Claims Set ::

                    A JSON object that contains the claims conveyed by the JWT.

- Claim ::

           A piece of information asserted about a subject.  A claim is
           represented as a name/value pair consisting of a Claim Name and a
           Claim Value.

- Claim Name ::

                The name portion of a claim representation.  A Claim Name is
                always a string.

- Claim Value ::

                 The value portion of a claim representation.  A Claim Value
                 can be any JSON value.

- Nested JWT ::

                A JWT in which nested signing and/or encryption are employed.
                In Nested JWTs, a JWT is used as the payload or plaintext value
                of an enclosing JWS or JWE structure, respectively.

- Unsecured JWT ::

                   A JWT whose claims are not integrity protected or encrypted.

- Collision-Resistant Name ::

     A name in a namespace that enables names to be allocated in a manner such
     that they are highly unlikely to collide with other names.

- StringOrURI ::

                 A JSON string value, with the additional requirement that
                 while arbitrary string values MAY be used, any value
                 containing a ":" character MUST be a URI [RFC3986].
                 StringOrURI values are compared as case-sensitive strings with
                 no transformations or canonicalizations applied.

- NumericDate ::

                 A JSON numeric value representing the number of seconds from
                 1970-01-01T00:00:00Z UTC until the specified UTC date/time,
                 ignoring leap seconds.  This is equivalent to the IEEE Std
                 1003.1, 2013 Edition [POSIX.1] definition "Seconds Since the
                 Epoch", in which each day is accounted for by exactly 86400
                 seconds, other than that non-integer values can be
                 represented.  See RFC 3339 [RFC3339] for details regarding
                 date/times in general and UTC in particular.

- MAC ::

         *Message Authentication Code* ("tag") is a short piece of information
         used to /authenticate/ a message---in other words, to confirm that the
         message came from the stated sender (its authenticity) and has not
         been changed.  The MAC value protects both a message's 
  - data integrity as well as its
  - authenticity,

  by allowing verifiers (who also possess the secret key) to detect any changes
          to the message content.

          Informally, a message authentication code consists of three
          algorithms:
    - A key generation algorithm selects a key from the key space uniformly at
      random.
    - A signing algorithm efficiently returns a tag given the key and the
      message.
    - A verifying algorithm efficiently verifies the authenticity of the
      message given the key and the tag.  That is, return /accepted/ when the
      message and tag are not tampered with or forged, and otherwise return
      /rejected/.

      MACs differ from digital signatures as MAC values are both generated and
      verified using the same secret key. This implies that the sender and
      receiver of a message must agree on the same key before initiating
      communications.  In contrast, a digital signature is generated using the
      private key of a key pair, which is public-key cryptography.  Since this
      private key is only accessible to its holder, a digital signature proves
      that a document was signed by none other than that holder.

- HMAC ::

          Hash-Based Message Authentication Code is a specific type of message
          authentication code (MAC) involving a cryptographic hash function and
          a secret cryptographic key.  Any cryptographic hash function, such as
          SHA-256 or SHA-3, may be used in the calculation of an HMAC; the
          resulting MAC algorithm is termed HMAC-X, where X is the hash
          function used (e.g. HMAC-SHA256 or HMAC-SHA3).

          HMAC uses two passes of hash computation. The secret key is first
          used to derive two keys – inner and outer. The first pass of the
          algorithm produces an internal hash derived from the message and the
          inner key. The second pass produces the final HMAC code derived from
          the inner hash result and the outer key.

**** Overview
JWTs represent a set of /claims/ as a JSON object that is encoded in a JWS
and/or JWE structure.  This JSON object is the JWT Claims Set.

As per Section 4 of RFC 7159 [RFC7159], the JSON object consists of zero or
more /name/value pairs/ (or /members/), where the names are strings and the
values are arbitrary JSON values.  These members are the /claims/ represented
by the JWT.

This JSON object MAY contain whitespace and/or line breaks before or after any
JSON values or structural characters, in accordance with Section 2 of RFC 7159
[RFC7159].

The member names within the JWT Claims Set are referred to as /Claim Names/.
The corresponding values are referred to as /Claim Values/.

The contents of the *JOSE Header* describe the cryptographic operations applied
to the JWT Claims Set.

If the JOSE Header is for a *JWS*, the JWT is represented as a JWS and the claims
are digitally signed or MACed, with the JWT Claims Set being the JWS Payload.

If the JOSE Header is for a *JWE*, the JWT is represented as a JWE and the
claims are encrypted, with the JWT Claims Set being the plaintext encrypted by
the JWE.

A JWT may be enclosed in another JWE or JWS structure to create a *Nested JWT*,
enabling nested signing and encryption to be performed.

A JWT is represented as a sequence of URL-safe parts separated by period ('.')
characters.  Each part contains a /base64url-encoded value/.  The number of parts
in the JWT is dependent upon the representation of the resulting JWS using the
JWS Compact Serialization or JWE using the JWE Compact Serialization.

**** Example JWT
The following example *JOSE Header* declares that:
- the encoded object is a *JWT*, and
- the JWT is a *JWS* that is *MAC*ed using the =HMAC SHA-256= algorithm:

#+begin_src js
  {"typ":"JWT",
   "alg":"HS256"}
#+end_src

To remove potential ambiguities in the representation of the JSON object above,
the /octet sequence/ for the actual UTF-8 representation used in this example for
the JOSE Header above is also included below.  The octets representing the
UTF-8 representation of the JOSE Header in this example (using JSON array
notation) are:

: [123, 34, 116, 121, 112, 34, 58, 34, 74, 87, 84, 34, 44, 13, 10, 32,
:  34, 97, 108, 103, 34, 58, 34, 72, 83, 50, 53, 54, 34, 125]

*Base64url* encoding the octets of the UTF-8 representation of the JOSE Header
yields this *encoded JOSE Header* value:

{{{subheading(Encoded JOSE Header Value)}}}

: eyJ0eXAiOiJKV1QiLA0KICJhbGciOiJIUzI1NiJ9

The following is an example of a *JWT Claims Set*:

#+begin_src js
  {"iss":"joe",
   "exp":1300819380,
   "http://example.com/is_root":true}
#+end_src

The following octet sequence, which is the UTF-8 representation used in this
example for the JWT Claims Set above, is the JWS Payload:

#+begin_src js
  [123, 34, 105, 115, 115, 34, 58, 34, 106, 111, 101, 34, 44, 13, 10,
   32, 34, 101, 120, 112, 34, 58, 49, 51, 48, 48, 56, 49, 57, 51, 56,
   48, 44, 13, 10, 32, 34, 104, 116, 116, 112, 58, 47, 47, 101, 120, 97,
   109, 112, 108, 101, 46, 99, 111, 109, 47, 105, 115, 95, 114, 111,
   111, 116, 34, 58, 116, 114, 117, 101, 125]
#+end_src

*Base64url encoding* the *JWS Payload* yields this *encoded JWS Payload* (with
line breaks for display purposes only):

{{{subheading(Encoded JWS Payload)}}}

: eyJpc3MiOiJqb2UiLA0KICJleHAiOjEzMDA4MTkzODAsDQogImh0dHA6Ly
: 9leGFtcGxlLmNvbS9pc19yb290Ijp0cnVlfQ

Computing the *MAC*:
- of the encoded JOSE Header and
- encoded JWS Payload with the
- HMAC SHA-256 algorithm and
- base64url encoding the HMAC value
- in the manner specified in [JWS] yields
- this *encoded JWS Signature*:


{{{subheading(Encoded JWS Signature)}}}

: dBjftJeZ4CVP-mB92K27uhbUJU1p1r_wW1gFWFOEjXk

/Concatenating/ these encoded parts in this order with period ('.')  characters
between the parts yields this *complete JWT* (with line breaks for display
purposes only):

{{{subheading(Complete JWT)}}}

#+begin_src js
eyJ0eXAiOiJKV1QiLA0KICJhbGciOiJIUzI1NiJ9
.
eyJpc3MiOiJqb2UiLA0KICJleHAiOjEzMDA4MTkzODAsDQogImh0dHA6Ly9leGFt
cGxlLmNvbS9pc19yb290Ijp0cnVlfQ
.
dBjftJeZ4CVP-mB92K27uhbUJU1p1r_wW1gFWFOEjXk
#+end_src

**** Example Encrypted JWT
This example encrypts the same claims as used in the previous example to the
recipient using =RSAES-PKCS1-v1_5= and =AES_128_CBC_HMAC_SHA_256=.

The following example JOSE Header declares that:
- The Content Encryption Key is encrypted to the recipient using the
  =RSAES-PKCS1-v1_5= algorithm to produce the JWE Encrypted Key.
- Authenticated encryption is performed on the plaintext using the
  =AES_128_CBC_HMAC_SHA_256= algorithm to produce the JWE Ciphertext and the
  JWE Authentication Tag.


: {"alg":"RSA1_5","enc":"A128CBC-HS256"}

Other than using the octets of the UTF-8 representation of the JWT Claims Set
from [[https://tools.ietf.org/html/rfc7519#section-3.1][Section 3.1]] as the plaintext value, the computation of this JWT is
identical to the computation of the JWE in [[https://tools.ietf.org/html/rfc7519#appendix-A.2][Appendix A.2]] of [[[https://tools.ietf.org/html/rfc7519#ref-JWE][JWE]]], including the
keys used.

The final result in this example (with line breaks for display purposes only)
is:

#+begin_example
eyJhbGciOiJSU0ExXzUiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0.
QR1Owv2ug2WyPBnbQrRARTeEk9kDO2w8qDcjiHnSJflSdv1iNqhWXaKH4MqAkQtM
oNfABIPJaZm0HaA415sv3aeuBWnD8J-Ui7Ah6cWafs3ZwwFKDFUUsWHSK-IPKxLG
TkND09XyjORj_CHAgOPJ-Sd8ONQRnJvWn_hXV1BNMHzUjPyYwEsRhDhzjAD26ima
sOTsgruobpYGoQcXUwFDn7moXPRfDE8-NoQX7N7ZYMmpUDkR-Cx9obNGwJQ3nM52
YCitxoQVPzjbl7WBuB7AohdBoZOdZ24WlN1lVIeh8v1K4krB8xgKvRU8kgFrEn_a
1rZgN5TiysnmzTROF869lQ.
AxY8DCtDaGlsbGljb3RoZQ.
MKOle7UQrG6nSxTLX6Mqwt0orbHvAKeWnDYvpIAeZ72deHxz3roJDXQyhxx0wKaM
HDjUEOKIwrtkHthpqEanSBNYHZgmNOV7sln1Eu9g3J8.
fiK51VwhsxJ-siBMR-YFiA
#+end_example

**** Relationship of JWTs to SAML Assertions
Security Assertion Markup Language (SAML) 2.0 provides a standard for creating
security tokens with greater expressivity and more security options than
supported by JWTs.  However, the cost of this flexibility and expressiveness is
both size and complexity.  SAML's use of XML and XML Digital Signature (DSIG)
contributes to the size of SAML Assertions; its use of XML and especially XML
Canonicalization contributes to their complexity.

JWTs are intended to provide a simple security token format that is small
enough to fit into HTTP headers and query arguments in URIs.  It does this by
supporting a much simpler token model than SAML and using the JSON [RFC7159]
object encoding syntax.  It also supports securing tokens using Message
Authentication Codes (MACs) and digital signatures using a smaller (and less
flexible) format than XML DSIG.

Therefore, while JWTs can do some of the things SAML Assertions do, JWTs are
not intended as a full replacement for SAML Assertions, but rather as a token
format to be used when ease of implementation or compactness are
considerations.

SAML Assertions are always statements made by an entity about a subject.  JWTs
are often used in the same manner, with the entity making the statements being
represented by the "iss" (issuer) claim, and the subject being represented by
the "sub" (subject) claim.  However, with these claims being optional, other
uses of the JWT format are also permitted.

**** Relationship of JWTs to Simple Web Tokens (SWTs)
Both JWTs and SWTs [[[https://docs.microsoft.com/en-us/previous-versions/azure/azure-services/hh781551(v=azure.100)][SWT]]], at their core, enable sets of claims to be
communicated between applications.  For SWTs, both the claim names and claim
values are strings.  For JWTs, while claim names are strings, claim values can
be any JSON type.  Both token types offer cryptographic protection of their
content: SWTs with HMAC SHA-256 and JWTs with a choice of algorithms, including
signature, MAC, and encryption algorithms.

*** JSON Web Signature
- http://tools.ietf.org/html/draft-ietf-jose-json-web-signature-20

*** JSON Web Encryption
- http://tools.ietf.org/html/draft-ietf-jose-json-web-encryption-20
* MACs and HMACs
[[*%5B%5Bhttps://www.jscape.com/blog/what-is-hmac-and-how-does-it-secure-file-transfers%5D%5BWhat Is HMAC And How Does It Secure File Transfers?%5D%5D][What Is HMAC And How Does It Secure File Transfers?]]

* Overview of OAuth2 and OIDC
Prior to 2007 there was no way to safey delegate authorization.  Around 2007
the OAuth discussion group was formed around Twitter.  This group eventually
released a spec.  Now, when an app wants to access a user's data, the app
redirects the user to the user's resource owner where the user is presented
with a consent screen informing the user as to what resources the app wants to
access if allowed.  If the user authorizes the request, the app is given a
token which provides access.  The app no longer needs to obtain and store
sensitive data and the user no longer needs to worry about the app misusing its
credentials.


{{{heading(Authorization vs Authentication)}}}

/Authorization/ is all about finding out who is allowed to access certain data
and functionality.

/Authentication/ is all about logging in.

While OAuth solved the authorization problems present on the web at the time,
it didn’t even attempt to tackle authentication issues.  OAuth’s lack of
authentication guidance led to a number of confusing, complex integration
scenarios, which is precisely why OpenID Connect (OIDC) was created.

OIDC is a newer standard that extends OAuth, adding support for
authentication. It doesn’t change any of the OAuth behaviors, all it does is
add some extra stuff to solve both authentication and authorization challenges
that most web developers face.

The OIDC specification also clarified a number of ambiguities in the original
OAuth spec, giving implementors a much clearer understanding of what
technologies to use under the hood, how to validate requests and a number of
other things.

{{{heading(Grant Types)}}}

The OAuth and OIDC specs (and extensions) cover authentication and
authorization for:

- Users logging into a server-side web application
- Users logging into a client-side web application
- Users logging into a native mobile application
- Users logging into a TV/device application
- Server-to-server API authorization
- Etc.


These use case scenarios are translated into a concept called /grant types/ in
the OAuth specification, and each one works differently and has different
security profiles that the implementor needs to be aware of.  In addition to
grant types, implementors must also understand /tokens/ (specifically, /JSON
Web Tokens/) (which are a part of the OIDC specification).

In order to successfully implement OAuth/OIDC in your environment, you (as a
developer) need to fully understand:

- What the different OAuth grant types are
- Which grant types you should be using in your application in which scenarios
- What JWTs are
- How to generate JWTs securely and keep your keys safe
- How to sign (and optionally encrypt) your JWTs: what options do you use?
- How to validate JWTs
- How to assess the security repercussions of using JWTs in different ways
- And lots more


OAuth and OIDC are complicated, and it takes a lot of time and effort to
understand and use them properly without opening yourself up to exploitation.

** Video---OAuth 2.0 and OpenID Connect In Plain English
- https://www.youtube.com/watch?v=996OiexHze0

Developer Advocate Nate Barbettini breaks down OpenID and OAuth 2.0 in Plain
English.

** Video---Introduction to OAuth 2.0 and OpenID Connect
:PROPERTIES:
:author:   Philippe De Ryck
:date:     Jan 10, 2019
:END:
- https://www.youtube.com/watch?v=GyCL8AJUhww

** Video---How Google is using OAuth
:PROPERTIES:
:date:     Jun 19, 2016
:END:
- https://www.youtube.com/watch?v=fxRXLbgX53A


It is best practice to use OAuth for securing APIs. Google, Paypal and LinkedIn
are using it.  Sweet!  Let's check out how Google is using OAuth.

** Article---An Illustrated Guide to OAuth and OpenID Connect
:PROPERTIES:
:author:   David Neal
:date:     2019-10-21
:END:

- [[https://developer.okta.com/blog/2019/10/21/illustrated-guide-to-oauth-and-oidc][Source]]

- [[https://www.youtube.com/watch?v=t18YB3xDfXI][Video]]


In the “stone age” days of the Internet, sharing information between services
was easy.  You simply gave your username and password for one service to another
so they could login to your account and grab whatever information they wanted!

Yikes! You should never be required to share your username and password, your
credentials, to another service.  There’s no guarantee that an organization
will keep your credentials safe, or guarantee their service won’t access more
of your personal information than necessary.  It might sound crazy, but some
applications still try to get away with this!

Today we have an agreed-upon standard to securely allow one service to access
data from another.  Unfortunately, these standards use a lot of jargon and
terminology that make them more difficult to understand.  The goal of this post
is to explain how these standards work using simplified illustrations.

*** Introducing OAuth 2.0
[[https://oauth.net/2/][OAuth 2.0]] is a security standard where you give one application permission to
access your data in another application.  The steps to grant permission, or
consent, are often referred to as authorization or even delegated
authorization.  You authorize one application to access your data, or use
features in another application on your behalf, without giving them your
password.  Sweet!

As an example, let’s say you’ve discovered a web site named “Terrible Pun of
the Day” and create an account to have it send an awful pun joke as a text
message every day to your phone.  You love it so much, you want to share this
site with everyone you’ve ever met online.

However, writing an email to every person in your contacts list sounds like a
lot of work.  Good thing “Terrible Pun of the Day” has a feature to invite your
friends!  *You can grant “Terrible Pun of the Day” access to your email
contacts and send out emails for you! OAuth for the win!*

{{{heading(Basic Authorization Flow)}}}

Here are the steps that will occur to make that happen:

1. Pick your email provider

2. Redirect to your email provider and login if needed

3. Give “Terrible Pun of the Day” permission to access to your contacts

4. Redirect back to “Terrible Pun of the Day”


{{{heading(Right to Revoke)}}}

In case you change your mind, applications that use OAuth to grant access also
provide a way to revoke access. Should you decide later you no longer want your
contacts shared, you can go to your email provider and remove “Terrible Pun of
the Day” as an authorized application.

*** OAuth Flow
You’ve just stepped through what is commonly referred to as an OAuth flow.  The
OAuth flow in this example is made of visible steps to grant consent, as well
as some invisible steps where the two services agree on a secure way of
exchanging information.  The previous “Terrible Pun of the Day” example uses
the most common OAuth 2.0 flow, known as the “authorization code” flow.

*** OAuth Terminologies

- Resource Owner :: You! You are the owner of your identity, your data, and any
                    actions that can be performed with your accounts.

- Client :: The application (e.g. “Terrible Pun of the Day”) that wants to
            access data or perform actions on behalf of the *Resource Owner*.

- Authorization Server :: The application that knows the *Resource Owner*,
     where the *Resource Owner* already has an account.

- Resource Server :: The Application Programming Interface (API) or service the
     Client wants to use on behalf of the *Resource Owner*.

- Redirect URI :: The URL the *Authorization Server* will redirect the
                  *Resource Owner* back to after granting permission to the
                  *Client*.  This is sometimes referred to as the “Callback
                  URL.”

- Response Type :: The type of information the *Client* expects to receive.
                   The most common Response Type is =code=, where the *Client*
                   expects an *Authorization Code*.

- Scope :: These are the granular permissions the *Client* wants, such as
           access to data or to perform actions.

- Consent :: The *Authorization Server* takes the *Scopes* the *Client* is
             requesting, and verifies with the *Resource Owner* whether or not
             they want to give the *Client* permission.

- Client ID :: This ID is used to identify the *Client* with the *Authorization
               Server*.

- Client Secret :: This is a secret password that only the *Client* and
                   *Authorization Server* know.  This allows them to securely
                   share information privately behind the scenes.

- Authorization Code :: A short-lived temporary code the *Client* gives the
     *Authorization Server* in exchange for an *Access Token*.

- Access Token :: The key the client will use to communicate with the *Resource
                  Server*.  This is like a badge or key card that gives the
                  *Client* permission to request data or perform actions with
                  the *Resource Server* on your behalf.


Note: Sometimes the “Authorization Server” and the “Resource Server” are the
same server.  However, there are cases where they will not be the same server
or even part of the same organization.  For example, the “Authorization Server”
might be a third-party service the “Resource Server” trusts.

*** Detailed Outline of the OAuth Flow

1. You, the Resource Owner, want to allow “Terrible Pun of the Day,” the
   Client, to access your contacts so they can send invitations to all your
   friends.

2. The Client redirects your browser to the Authorization Server and includes
   with the request the Client ID, Redirect URI, Response Type, and one or more
   Scopes it needs.

3. The Authorization Server verifies who you are, and if necessary prompts for
   a login.

4. The Authorization Server presents you with a Consent form based on the
   Scopes requested by the Client. You grant (or deny) permission.

5. The Authorization Server redirects back to Client using the Redirect URI
   along with an Authorization Code.

6. The Client contacts the Authorization Server directly (does not use the
   Resource Owner’s browser) and securely sends its Client ID, Client Secret,
   and the Authorization Code.

7. The Authorization Server verifies the data and responds with an Access
   Token.

8. The Client can now use the Access Token to send requests to the Resource
   Server for your contacts.

*** Client ID and Secret

Long before you gave “Terrible Pun of the Day” permission to access your
contacts, the Client and the Authorization Server established a working
relationship.  The Authorization Server generated a /Client ID/ and /Client
Secret/, sometimes called the /App ID/ and /App Secret/, and gave them to the
Client to use for all future OAuth exchanges.  As the name implies, the Client
Secret must be kept secret so that only the Client and Authorization Server
know what it is. This is how the Authorization Server can verify the Client.

*** Welcome OpenID Connect

 OpenID Connect (OIDC) is a thin layer that sits on top of OAuth 2.0 that adds
 login and profile information about the person who is logged in.  Establishing
 a login session is often referred to as /authentication/, and information
 about the person logged in (i.e. the Resource Owner) is called /identity/.
 When an Authorization Server supports OIDC, it is sometimes called an
 /identity provider/, since it provides information about the Resource Owner
 back to the Client.

{{{heading(Single Sign On)}}}

OpenID Connect enables scenarios where one login can be used across multiple
applications, also known as /single sign-on/ (SSO).  For example, an
application could support SSO with social networking services such as Facebook
or Twitter so that users can choose to leverage a login they already have and
are comfortable using.

{{{heading(OpenID Connect Flow)}}}

The OpenID Connect flow looks the same as OAuth.  The only differences are, in
the initial request, a specific scope of =openid= is used, and in the final
exchange the Client receives both an *Access Token* and an *ID Token*.

{{{heading(OIDC ID Token)}}}

As with the OAuth flow, the OpenID Connect Access Token is a value the Client
doesn’t understand.  As far as the Client is concerned, the Access Token is
just a string of gibberish to pass with any request to the Resource Server, and
the Resource Server knows if the token is valid.  The ID Token, however, is
very different.

An ID Token is a specifically formatted string of characters known as a JSON
Web Token, or JWT.  JWTs are sometimes pronounced “jots.”  A JWT may look like
gibberish to you and me, but the Client can extract information embedded in the
JWT such as your ID, name, when you logged in, the ID Token expiration, and if
anything has tried to tamper with the JWT.  The data inside the ID Token are
called /claims/.

With OIDC, there’s also a standard way the Client can request additional
identity information from the Authorization Server, such as their email
address, using the Access Token.
* OAuth 2.0
- [[https://tools.ietf.org/html/rfc6749][RFC 6749]] The OAuth 2.0 Authorization Framework---October 2012

  The OAuth 2.0 authorization framework enables a third-party application to
  obtain limited access to an HTTP service, either on behalf of a resource
  owner by orchestrating an approval interaction between the resource owner and
  the HTTP service, or by allowing the third-party application to obtain access
  on its own behalf.  This specification replaces and obsoletes the OAuth 1.0
  protocol described in RFC 5849.

- [[http://tools.ietf.org/html/rfc6750][RFC 6750]] OAuth 2.0 Bearer token

- [[https://tools.ietf.org/html/rfc8252][RFC 8252]] OAuth 2.0 for Native Apps

  OAuth 2.0 authorization requests from native apps should only be made through
  external user-agents, primarily the user's browser.  This specification
  details the security and usability reasons why this is the case and how
  native apps and authorization servers can implement this best practice.

- https://www.oauth.com
- https://oauth.net
- https://www.okta.com
- https://www.tutorialspoint.com/oauth2.0/

** Books About OAuth 2.0
- [[https://oauth.net/books/]]

** OAuth 2.0 Bearer Token Usage
- RFC 6750---[[https://tools.ietf.org/html/rfc6750][The OAuth 2.0 Authorization Framework: Bearer Token Usage]]


This specification describes how to use bearer tokens in HTTP requests to
access OAuth 2.0 protected resources.  Any party in possession of a bearer
token (a "bearer") can use it to get access to the associated resources
(without demonstrating possession of a cryptographic key).  To prevent misuse,
bearer tokens need to be protected from disclosure in storage and in transport.
** Article---Is the OAuth 2.0 Implicit Flow Dead
:PROPERTIES:
:author:   Aaron Parecki
:date:     May 1, 2019
:END:
- https://developer.okta.com/blog/2019/05/01/is-the-oauth-implicit-flow-dead


You may have heard some buzz recently about the OAuth 2.0 Implicit flow. The
OAuth Working Group has published some new guidance around the Implicit flow
and JavaScript-based apps, specifically that the Implicit flow should no longer
be used. In this post we’ll look at what’s changing with the Implicit flow and
why.

*** The Best Practice Around Implicit in OAuth 2.0 is Changing
The Implicit flow in OAuth 2.0 was created nearly 10 years ago, when browsers
worked very differently than they do today.  The primary reason the Implicit
flow was created was because of an old limitation in browsers.  It used to be
the case that JavaScript could only make requests to the same server that the
page was loaded from.  However, the standard OAuth Authorization Code flow
requires that a POST request is made to the OAuth server’s token endpoint,
which is often on a different domain than the app.  That meant there was
previously no way to use this flow from JavaScript.  The Implicit flow worked
around this limitation by avoiding that POST request, and instead returning the
access token immediately in the redirect.

Today, Cross-Origin Resource Sharing (CORS) is universally adopted by browsers,
removing the need for this compromise.  CORS provides a way for JavaScript to
make requests to servers on a different domain as long as the destination
allows it.  This opens up the possibility of using the Authorization Code flow
in JavaScript.

It’s worth noting that the Implicit flow has always been seen as a compromise
compared to the Authorization Code flow.  For example, the spec provides no
mechanism to return a refresh token in the Implicit flow, as it was seen as too
insecure to allow that.  The spec also recommends short lifetimes and limited
scope for access tokens issued via the Implicit flow.

*** The OAuth Authorization Code Flow is Better
Now that it is possible to use the Authorization Code flow from a browser, we
still have one more issue to deal with regarding JavaScript apps.
Traditionally the Authorization Code flow uses a client secret when exchanging
the authorization code for an access token, but there is no way to include a
client secret in a JavaScript app and have it remain a secret.  If you were to
include a secret in the source code, anyone using the app could just “view
source” in their browser and see it.  So we need a solution.

Thankfully, this problem has already been solved, since the same issue applies
to mobile apps as well. As we’ve [[https://developer.okta.com/blog/2019/05/01/is-the-oauth-implicit-flow-dead][seen in the past]] [fn:2], native apps also can’t
safely use a client secret. The OAuth working group solved this problem several
years ago with the PKCE extension to the Authorization Code flow.

The Authorization Code flow with PKCE adds an additional step which allows us
to protect the authorization code so that even if it is stolen during the
redirect it will be useless by itself.  You can read more about how PKCE works
in our blog post, [[https://developer.okta.com/blog/2018/12/13/oauth-2-for-native-and-mobile-apps][OAuth 2.0 for Native and Mobile Apps]].

*** The OAuth 2.0 Implicit Flow for Existing Apps
The important thing to remember here is that there was no new vulnerability
found in the Implicit flow.  If you have an existing app that uses the Implicit
flow, it’s not that your app is suddenly now insecure after this new guidance
has been published.

That said, it is---and always has been---extremely challenging to implement the
Implicit flow securely.  If you have gone to the trouble of thoroughly auditing
your source code, knowing exactly which third-party libraries you’re using in
your application, have a strong Content Security Policy, and are confident in
your ability to build a secure JavaScript application, then your application is
probably fine.

So should you immediately switch all your apps to using PKCE instead of the
Implicit flow?  Probably not, it depends on your risk tolerance.  But at this
point I would definitely not recommend creating new apps using the Implicit
flow.

*** Does the Authorization Code Flow Make Browser-Based Apps Totally Secure
The best we can do is protect against common attacks, and reduce the overall
attack surface of an application.

Specifically, the Authorization Code flow with PKCE does completely protect the
application from the attack where an authorization code is stolen in transit
back to the application.  However, once the JavaScript app has obtained an
access token, it will still have to store it somewhere in order to use it, and
how it stores the access token will be the same whether the app used the
Implicit flow or PKCE to obtain it.  You’ll still need to ensure you have a
good Content Security Policy and are aware of any third-party libraries you’re
using in your application.

The best way to securely implement OAuth in a JavaScript app is to keep the
token management outside of JavaScript entirely.  If you’re building a
JavaScript app that is served from a dynamic server, such as a Spring Boot
backend with an Angular frontend, or an ASP.NET backend with a React front-end,
then you can keep all of the OAuth exchange and token management inside the
backend, never exposing it to the JavaScript front-end, and avoid all the risks
inherent in managing tokens in JavaScript.

*** Start Using PKCE in JavaScript Today
So you’re ready to start writing an app using PKCE in JavaScript? Let’s take a
look at exactly what that entails.

For the purposes of this demonstration, let’s assume you want to implement this
in pure JavaScript, with no additional libraries required.  This will
illustrate exactly how PKCE works, which you should then be able to translate
into your particular framework of choice.

You can find the completed sample code here and some interactive demos:
- [[https://github.com/aaronpk/pkce-vanilla-js][pkce-vanilla-js]]
- [[https://www.oauth.com/playground/authorization-code-with-pkce.html][Interactive demo of PKCE]]
- [[https://www.oauth.com/playground/implicit.html][Interactive demo of Implicit]]

**** Create an OKTA Application
1. First, [[https://developer.okta.com/signup/][sign up for a free Okta Developer account]].

2. Once you’ve signed up, select *Applications* from the menu at the top of the
   page, and click *Add Application*.

3. Choose *Single-Page App* from the options, which will configure this
   application to enable the CORS headers on the token endpoint, and will not
   create a client secret.

4. Give your application a name, and then there are two settings you’ll need to
   change.

   - Change the Login redirect URI to match the base URI, since we’ll be
     building a single-page app in just one HTML file.

   - Also make sure to check the Authorization Code checkbox, and uncheck
     Implicit.

   - That will register the application and provide you with a =client_id= on
     the next screen.  Make a note of this value since we’ll need it again
     later.

5. Create a new folder, and create an HTML file in it called ~index.html~ with
   the following contents.(Fill in your =client_id= in the =config= block
   below.)

   #+name:okta_app_index.html
   #+header: :mkdirp yes
   #+begin_src html :tangle examples/pkce/index.html
     <html>
     <title>OAuth Authorization Code + PKCE in Vanilla JS</title>
     <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

     <script>
     // Configure your application and authorization server details
     var config = {
         client_id: "",
         redirect_uri: "http://localhost:8080/",
         authorization_endpoint: "",
         token_endpoint: "",
         requested_scopes: "openid"
     };
     </script>
   #+end_src

6. Next, we need to find the /authorization/ endpoint and /token/ endpoint for
   your OAuth server.

   - Navigate to *API* in the main menu at the top, then choose *Authorization
     Servers*.

   - Copy the Issuer URI from that authorization server.

   - Your authorization endpoint will be that URI with ~/v1/auth~ appended, and
     the token endpoint will end with ~/v1/token~.

   - For example, if your Issuer URI is:
     : https://{yourOktaDomain}/oauth2/default
     then your authorization endpoint will be:
     : https://{yourOktaDomain}/oauth2/defalut/v1/authorize
     and your token endpoint will be:
     :  https://{yourOktaDomain}/oauth2/default/v1/token

   - Enter those two values in the JavaScript =config= object created in the
     previous step.


**** Set Up the HTML Structure

7. Next, let’s add some HTML to the page to create a couple of UI elements to
   help illustrate this flow.

   #+name:okta_app_index.html_ui_elements
   #+begin_src html :tangle :examples/pkce/index.html
     <div class="flex-center full-height">
         <div class="content">
             <a href="#" id="start">Click to Sign In</a>
             <div id="token" class="hidden">
                 <h2>Access Token</h2>
                 <div id="access_token" class="code"></div>
             </div>
             <div id="error" class="hidden">
                 <h2>Error</h2>
                 <div id="error_details" class="code"></div>
             </div>
         </div>
     </div>
   #+end_src

8. And to make it look good, add the following CSS below.

   #+name:okta_app_index.html_css_styles
   #+begin_src html :tangle examples/pkce/index.html
     <style>
     body {
       padding: 0;
       margin: 0;
       min-height: 100vh;
       font-family: arial, sans-serif;
     }
     @media(max-width: 400px) {
       body {
         padding: 10px;
       }
     }
     .full-height {
       min-height: 100vh;
     }
     .flex-center {
       align-items: center;
       display: flex;
       justify-content: center;
     }
     .content {
       max-width: 400px;
     }
     h2 {
       text-align: center;
     }
     .code {
       font-family: "Courier New", "Courier", monospace;
       width: 100%;
       padding: 4px;
       border: 1px #ccc solid;
       border-radius: 4px;
       word-break: break-all;
     }
     .hidden {
       display: none;
     }
     </style>
   #+end_src

**** Begin the PKCE Request

With that out of the way, we can get to the good stuff, actually starting the
PKCE flow in JavaScript.

1. First, add a new =<script>= tag so that we have a place to start writing
   JavaScript.

   #+name:okta_app_index.html_js_script
   #+header: :noweb tangle no-export :comments noweb
   #+begin_src html :tangle examples/pkce/index.html
     <script>
       <<pkce-js-source>>
       <<pkce-initiate-flow>>
       <<pkce-parse-query-string>>
       <<pkce-post-request>>
       <<pkce-get-access-token>>
     </script>
   #+end_src

   We’re first going to define a few helper functions that will take care of
   the tricky parts of PKCE: securely generating a random string, and
   generating the SHA256 hash of that string.

2. Add these functions into the =<script>= tag you just created.

   #+name:pkce-js-source
   #+begin_src js
     // PKCE HELPER FUNCTIONS

     // Generate a secure random string using the browser crypto functions
     function generateRandomString() {
         var array = new Uint32Array(28);
         window.crypto.getRandomValues(array);
         return Array.from(array, dec => ('0' + dec.toString(16)).substr(-2)).join('');
     }

     // Calculate the SHA256 hash of the input text. 
     // Returns a promise that resolves to an ArrayBuffer
     function sha256(plain) {
         const encoder = new TextEncoder();
         const data = encoder.encode(plain);
         return window.crypto.subtle.digest('SHA-256', data);
     }

     // Base64-urlencodes the input string
     function base64urlencode(str) {
         // Convert the ArrayBuffer to string using Uint8 array to convert to what btoa accepts.
         // btoa accepts chars only within ascii 0-255 and base64 encodes them.
         // Then convert the base64 encoded to base64url encoded
         //   (replace + with -, replace / with _, trim trailing =)
         return btoa(String.fromCharCode.apply(null, new Uint8Array(str)))
             .replace(/\+/g, '-').replace(/\//g, '_').replace(/=+$/, '');
     }

     // Return the base64-urlencoded sha256 hash for the PKCE challenge
     async function pkceChallengeFromVerifier(v) {
         hashed = await sha256(v);
         return base64urlencode(hashed);
     }
   #+end_src

   Now we’re ready to kick off the flow.  The first step of the PKCE flow is to
   generate a secret, hash it, then redirect the user over to the authorization
   server with that hash in the URL.

3. We’ll add an =onclick= listener to the =Click to Sign In= link we created in
   the HTML.

   #+name:pkce-initiate-flow
   #+begin_src js
     // Initiate the PKCE Auth Code flow when the link is clicked
     document.getElementById("start").addEventListener("click", async function(e){
         e.preventDefault();
    
         // Create and store a random "state" value
         var state = generateRandomString();
         localStorage.setItem("pkce_state", state);

         // Create and store a new PKCE code_verifier (the plaintext random secret)
         var code_verifier = generateRandomString();
         localStorage.setItem("pkce_code_verifier", code_verifier);

         // Hash and base64-urlencode the secret to use as the challenge
         var code_challenge = await pkceChallengeFromVerifier(code_verifier);

         // Build the authorization URL
         var url = config.authorization_endpoint 
             + "?response_type=code"
             + "&client_id="+encodeURIComponent(config.client_id)
             + "&state="+encodeURIComponent(state)
             + "&scope="+encodeURIComponent(config.requested_scopes)
             + "&redirect_uri="+encodeURIComponent(config.redirect_uri)
             + "&code_challenge="+encodeURIComponent(code_challenge)
             + "&code_challenge_method=S256"
             ;

         // Redirect to the authorization server
         window.location = url;
     });
   #+end_src

   This function does a few things:

   - Creates a random string to use as the state value and stores it in
     LocalStorage

   - Creates a random string to use as the PKCE code_verifier value

   - Hashes and base64-urlencodes the code verifier

   - Builds the authorization URL with all the required parameters, using the
     config values you defined at the beginning

   - Redirects the browser to the authorization URL


   At this point, the user is handed off to the authorization server to log in.
   The authorization server will then redirect the user back to the application
   and there will be two parameters in the query string: =code= and =state=.

**** Get an Access Token using the Authorization Code
This application will need to verify the =state= value matches the one it
generated at the beginning, then exchange the =authorization= code for an
=access token.  To accomplish this, we’ll need to add a couple more helper
functions.

1. Add the following function to the bottom of your JavaScript. This function
   will parse a query string into a JavaScript object.

   #+name:pkce-parse-query-string
   #+begin_src js
     // Parse a query string into an object
     function parseQueryString(string) {
         if(string == "") { return {}; }
         var segments = string.split("&").map(s => s.split("=") );
         var queryString = {};
         segments.forEach(s => queryString[s[0]] = s[1]);
         return queryString;
     }
   #+end_src

2. Also add the function below, which will give us an easy way to make a =POST=
   request and parse the =JSON= response.

   #+name:pkce-post-request
   #+begin_src js
     // Make a POST request and parse the response as JSON
     function sendPostRequest(url, params, success, error) {
         var request = new XMLHttpRequest();
         request.open('POST', url, true);
         request.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded; charset=UTF-8');
         request.onload = function() {
             var body = {};
             try {
                 body = JSON.parse(request.response);
             } catch(e) {}

             if(request.status == 200) {
                 success(request, body);
             } else {
                 error(request, body);
             }
         }
         request.onerror = function() {
             error(request, {});
         }
         var body = Object.keys(params).map(key => key + '=' + params[key]).join('&');
         request.send(body);
     }
   #+end_src

   Now you’re ready to exchange the authorization code for an access token.  If
   you’re familiar with the traditional Authorization Code flow, you’ll
   remember that this step normally requires a client secret.  But since we
   don’t have a client secret for this JavaScript application, instead we’ll
   send the PKCE code verifier when making this request, which ensures that
   only the application that requested a code can exchange it for an access
   token.

3. Add the following code to your JavaScript section.

   #+name:pkce-get-access-token
   #+begin_src js
     // Handle the redirect back from the authorization server and
     // get an access token from the token endpoint

     var q = parseQueryString(window.location.search.substring(1));

     // Check if the server returned an error string
     if(q.error) {
         alert("Error returned from authorization server: "+q.error);
         document.getElementById("error_details").innerText = q.error+"\n\n"+q.error_description;
         document.getElementById("error").classList = "";
     }

     // If the server returned an authorization code, attempt to exchange it for an access token
     if(q.code) {

         // Verify state matches what we set at the beginning
         if(localStorage.getItem("pkce_state") != q.state) {
             alert("Invalid state");
         } else {

             // Exchange the authorization code for an access token
             sendPostRequest(config.token_endpoint, {
                 grant_type: "authorization_code",
                 code: q.code,
                 client_id: config.client_id,
                 redirect_uri: config.redirect_uri,
                 code_verifier: localStorage.getItem("pkce_code_verifier")
             }, function(request, body) {

                 // Initialize your application now that you have an access token.
                 // Here we just display it in the browser.
                 document.getElementById("access_token").innerText = body.access_token;
                 document.getElementById("start").classList = "hidden";
                 document.getElementById("token").classList = "";

                 // Replace the history entry to remove the auth code from the browser address bar
                 window.history.replaceState({}, null, "/");

             }, function(request, error) {
                 // This could be an error response from the OAuth server, or an error because the 
                 // request failed such as if the OAuth server doesn't allow CORS requests
                 document.getElementById("error_details").innerText = error.error+"\n\n"+error.error_description;
                 document.getElementById("error").classList = "";
             });
         }

         // Clean these up since we don't need them anymore
         localStorage.removeItem("pkce_state");
         localStorage.removeItem("pkce_code_verifier");
     }
   #+end_src

   This code does a few things:

   - Checks if the authorization server returned an error message and displays
     it to the user if so

   - Checks if the authorization server returned an authorization code, and
     exchanges it for an access token

   - Sends a POST request to the token endpoint which includes the
     code_verifier parameter that it made in the previous step

   - Updates the UI to indicate error messages or show the access token
     returned

   - Removes the authorization code from the address bar using the Session
     History Management API


**** Test the PKCE Flow
At this point, you’re ready to try out the application!  You’ll need to either
run a local web server, or host it on a test domain.  In any case, just make
sure that the Base URI and Redirect URI in your application settings are set to
the URL that you’ll be visiting this application.[fn:3]

1. You can use any web server to serve the file, but I find that an easy way to
   launch this app is to use PHP’s built-in web server.  You can run the
   command below to start a web server on port 8080:

: php -S localhost:8080

2. You can now visit http://localhost:8080/ in your browser and you’ll see the
   sign-in link.

3. Click on that link and you’ll be redirected to Okta.  If you’re already
   signed in, you’ll be immediately redirected and the app will get an access
   token!


Congrats! You’ve successfully implemented PKCE in a browser with vanilla
JavaScript!  Hopefully this has been a helpful demonstration of what it takes
to do PKCE in a browser!  In practice, you’ll probably use a JavaScript library
that handles this behind the scenes for you, but it can still be useful to know
how this works under the hood!

** Article---Understanding OAuth2 and Building a Basic Authorization Server of Your Own-A Beginner's Guide
:PROPERTIES:
:author:   Ratros Y.
:url:      https://medium.com/google-cloud/understanding-oauth2-and-building-a-basic-authorization-server-of-your-own-a-beginners-guide-cf7451a16f66
:date:     May 25, 2018
:END:
This Beginner’s Guide provides a basic overview of OAuth2 and discusses how to
build a simple OAuth2 authorization server.

For a step-by-step tutorial on deploying a basic OAuth2 authentication service
on Google Cloud Platform, see the Understanding OAuth2 and Deploying a Basic
OAuth2 Authorization Service to Cloud Functions tutorial.
- =https://medium.com/@ratrosy/understanding-oauth2-and-deploying-a-basic-oauth2-authorization-service-to-cloud-functions-812e3643f94d=

*** Background
Many authorization processes involve credentials provided by the user, most
commonly in the form of username/password combination. Early websites usually
ask for credentials via an HTML form, which the browser will send to the
server. The server authenticates the information and writes a session value in
the cookie; as long as the session is still marked active, user can access
protected features and resources. Thanks to its simplicity and effectiveness,
this process is still used by many web applications and services at the present
day.

Popular as it might be, cookie-based authorization has several drawbacks:

- Cookie-based authorization are usually stateful. The server has to keep a
  record of active sessions and check with the database every time a request
  arrives, which requires some overhead on the server-side. It is also
  difficult to decouple the authorization process from the application server.

- Cookies are usually bundled with domains. If your application interacts with
  multiple domains, additional configuration may be required.

- Cookie-based authorization does not play well with mobile clients.

- Cookie-based authorization does not accommodate well the use case where users
  of one product or service would like to grant third-party clients access to
  their information on the platform.


OAuth addresses these concerns.  As an authorization framework enabling
applications to access resources from all kinds of services, it is widely used
on the web.  Currently OAuth has two versions of protocols, OAuth 1.0 ([[https://tools.ietf.org/html/rfc5849][RFC 5849]])
and OAuth 2.0 [[https://tools.ietf.org/html/rfc6749][(RFC 6749]]).  This guide focuses on the 2.0 version.  Essentially,
OAuth 2.0 allows arbitrary clients (for example, a first-party iOS application
or a third-party web application) to access user’s (resource owner’s) resources
on resource servers via authorization servers in a secure, reliable, and
efficient manner.

OAuth 2.0 is not backwards compatible with the previous version.  Advantages and
disadvantages regarding choosing OAuth 2.0 over OAuth 1.0 remain a [[https://hueniverse.com/oauth-2-0-and-the-road-to-hell-8eec45921529][topic of
debate]].

OAuth 2.0 specification defines 4 types of authorization flows:

- Authorization Code

- Resource Owner Password Credentials

- Implicit

- Client Credentials


Implicit and Client Credentials are flows typically reserved for special types
of clients. More specifically,

| Client Type                                                         | Flow              |
|---------------------------------------------------------------------+-------------------|
| Single-page Javascript Web Applications (for example, Google Fonts) | Implicit          |
| Non-interactive programs for machine-to-machine communications      | Client Credentals |
| (for example, background services and daemons)                      |                   |
|---------------------------------------------------------------------+-------------------|

As for other clients, depending on their trustworthiness, they can use the
following flows:

| Client Type                                                             | Flow                                                      |
|-------------------------------------------------------------------------+-----------------------------------------------------------|
| Highly trusted apps (first-party apps)                                  | Authorization Code or Resource Owner Password Credentials |
| Less trusted apps (third-party apps requesting access to your platform) | Authorization Code                                        |
|-------------------------------------------------------------------------+-----------------------------------------------------------|

Loosely speaking, if you plan to build a platform where third-party
applications and services can access its resources, go with the authorization
code flow; on the other hand, you can use the resource owner password
credentials flow to build a client (a web/mobile application) for your own
service.

Tokens play an important part in OAuth 2.0. There are two types of tokens:
access tokens and refresh tokens. Anyone with a valid access token can access
protected resources; usually it is short-lived so that even if there is a
security breach and the access token is leaked, the damage can be quickly
controlled. When an access token expires, developers can use an optional
refresh token to request a new access token without having to ask the user to
enter their credentials again.

*** Authorization Flows

**** Resource Owner Password Credentials
Resource Owner Password Credentials flow has the following requirements:

- The client must be highly trusted, as it directly handles user
  credentials. In most cases, the client should be a first-party app.


The flow includes the following steps:

1. The client prompts user to enter their credentials (for instance, a
   username/password combination).

2. The client sends the credentials and its own identification to the
   authorization server. The authorization server validates the information,
   then returns an access token and optionally a refresh token.

3. The client uses the access token to access resources on the resource server.


[[file:resources/oauth2_password_credentials_flow-50.png]]

**** Authorization Code
Authorization Code flow has the following requirements:

- The client must be able to interact with an user agent (browser) in the
  environment.


The flow includes the following steps:

1. The client prepares a link to the authorization server and opens the link
   for user in an user agent (browser). The link includes information that
   allows the authorization server to identify and respond to the client.

2. User enters their credentials on the new page.

3. Credentials are sent to authorization server via the user agent (browser).

4. The authorization server validates the credentials and redirects user back
   to the client with an authorization code.

5. The client talks with the authorization server, confirms its identify and
   exchanges the authorization code for an access token and optionally a
   refresh token.

6. The client uses the access token to access resources on the resource server.


Note that due to security concerns, even though both mobile app clients and web
app clients can use the authorization code flow, their approaches to identify
themselves in the flow are different. Web app clients usually use client IDs
and client secrets, while mobile app clients need to adopt the Proof Key for
Code Exchange (PKCE) technique and utilize code challenges and code verifiers.

[[file:./resources/oauth2_authorization_code_flow-50.png]]

**** Implicit and Client Credentials
Implicit flow, as said earlier, is designed for single-page Javascript
apps. This flow is vastly similar to the Authorization Code flow, except for
the part involving authorization code. Due to security concerns, in this flow
the client no longer receives an authorization code from the authorization
server; instead, after the user agent successfully transfers credentials, the
authorization server returns access tokens directly to the client. Refresh
tokens are not allowed in the Implicit flow.

[[file:./resources/oauth2_implicit_flow-50.png]]

Client Credentials flow, on the other hand, is closer to the Resource Owner
Password Credentials flow. Clients in this flow use client IDs and secrets to
identify themselves, and exchange them for access tokens with the authorization
server. You should not use refresh tokens in this flow either.

[[file:./resources/oauth2_client_credentials_flow-50.png]]

*** JWT (JSON Web Tokens)
You may have realized that even though tokens are frequently referenced in
OAuth 2.0, so far few has been said about their generation and usage. The truth
is, OAuth 2.0 framework does not specify what format access tokens and refresh
tokens should take and it is up to developers themselves to integrate tokens in
the their choice of authorization flows. Theoretically speaking, you may very
well use a predefined string that never expires as the access token, even
though it is obviously not very secure; in reality, however, many developers
choose to use the JWT ([[https://tools.ietf.org/html/rfc7519][JSON Web Token]]) format. JWT is self-contained, allowing
servers to validate tokens without having to inquire a data source.

A JWT includes three parts:

- A header describing the type of the token and the hashing algorithm it uses

- A payload containing the data

- A signature for verifying the token


All the three parts should be Base64URL encoded so that they can be safely
transferred in a query string.

You can use many hashing algorithms with JWT and the payload has a variety of
pre-defined fields (also known as [[https://tools.ietf.org/html/rfc7519#section-4.1][registered claim names]]).  This Beginner’s
Guide uses the =RS256=(RSA Signature with SHA-256) algorithm and specifies two
registered claims in the payload: =exp=(when does the token expire), and
=iss=(who issues the token). Aside from the supported claims, you can also
define your own claims in the payload, such as the scopes of the token.

Every time a JWT arrives at a server, the system first parses the JWT, and
verifies if the algorithm specified in the header is supported; then it checks
the signature to make sure that the JWT is valid, and at last, confirms that
registered claims (if exist) are valid. In the case of this guide, it means
making sure that the JWT hasn’t expired (=exp=), and comes from an expected
origin (=iss=). Custom claims, such as scopes, can be extracted from the token
and manually validated.

**** Expiration Date and Refresh Token
Additionally, developers have control over the lifespan of access tokens and
the usage of refresh tokens. Generally speaking, if you are building an
authorization server protecting critical resources, it might be better to stay
away from refresh tokens and keep access tokens short-lived. For less critical
resources though, it is OK to enable refresh tokens and let the access tokens
live a little bit longer. Resist the temptation to create evergreen tokens
though; long-lived access tokens do make development easier, however there is
always a trade-off between security and convenience.

*** What’s Next
This Beginner’s Guide includes examples for explaining how each of the
authorizations flows work in detail:

- Resource Owner Password Credentials
  : https://medium.com/@ratrosy/building-a-basic-authorization-server-using-resource-owner-password-credentials-flow-a666d06900fb

- Authorization Code flow
  : https://medium.com/@ratrosy/building-a-basic-authorization-server-using-authorization-code-flow-c06866859fb1

- Authorization Code flow (PKCE)
  : https://medium.com/@ratrosy/building-a-basic-authorization-server-using-authorization-code-flow-pkce-3155e843466

- Implicit flow
  : https://medium.com/@ratrosy/building-a-basic-authorization-server-with-implicit-flow-3f474eb2a306

- Client Credentials flow
  : https://medium.com/@ratrosy/building-a-basic-authorization-server-using-client-credentials-flow-db353d6debdf


These documents are largely independent of each other. If you have decided
which authorization flow to use, feel free to start with the example of your
choice. For a general understanding of OAuth 2.0 in action, it is recommended
to begin with Authorization Code flow.

Additionally, the
- Understanding OAuth2 and Building a Basic OAuth2 Authorization Server with
  Cloud Functions
  : https://medium.com/@ratrosy/understanding-oauth2-and-deploying-a-basic-oauth2-authorization-service-to-cloud-functions-812e3643f94d

  tutorial showcases how to use a Serverless solution

- [[https://cloud.google.com/functions/][Google Cloud Functions]]

  to deploy a custom OAuth 2.0 authorization service to the cloud.

** Article---Building a Basic Authorization Server using Authorization Code Flow
:PROPERTIES:
:url:      https://medium.com/@ratrosy/building-a-basic-authorization-server-using-authorization-code-flow-c06866859fb1
:author:   Ratros Y.
:date:     May 25, 2018
:END:
This document is part of the Understanding OAuth2 and Building a Basic
Authorization Server of Your Own guide. It discusses in detail how
Authorization Code flow works.

*** Before you begin
The sample code in this document uses Python 3 and the [[http://flask.pocoo.org/][flask]] framework. It is
for demonstration purposes only. The code is designed to demonstrate the
authorization process in an easy-to-understand manner; it does not necessarily
represent the best practices in development.

**** Setting up your environment
1. Install the latest version of Python 3. See [[https://cloud.google.com/python/setup][Setting Up a Python Development
   Environment]] for instructions.

2. Install the following Python packages:
   - flask,
   - pyopenssl
   - cryptography
   - pyjwt

   : pip install --upgrade flask pyopenssl cryptography pyjwt

3. Generate a private/public key pair (~private.pem~ and ~public.pem~):

   - Install the latest version of ~openssl~:

     | OS                    | Instructions                                           |
     |-----------------------+--------------------------------------------------------|
     | Linux (Debian/Ubuntu) | =sudo apt-get install openssl=                         |
     | macOS                 | (with Homebrew package manager) =brew install openssl= |
     | Windows               | See [[https://wiki.openssl.org/index.php/Binaries][here]] for instructions.                             |
     |-----------------------+--------------------------------------------------------|

   - Prepare the private key: =openssl genrsa -out private.pem 2048=. Do not
     specify a passphrase.

   - Prepare the public key: =openssl rsa -in private.pem -pubout -outform PEM
     -out public.pem=

**** Downloading the code
Download the source code [[https://github.com/michaelawyu/auth-server-sample][here]].

The sample includes the following files:

| Path                                         | Notes                                                                                              |
|----------------------------------------------+----------------------------------------------------------------------------------------------------|
| =client/AC_client.py=                        | A client web application using the Authorization Code flow to access a list of users.              |
| =client/public.pem=                          | A public key for verifying access tokens. You should replace this key file with one of your own.   |
| =client/templates/AC_login.html=             | An HTML template for preparing the login page.                                                     |
| =client/templates/users.html=                | An HTML template for preparing the results of user queries.                                        |
| =auth_server/AC_auth_server.py=              | An authorization server responsible for issuing access tokens in the Authorization Code flow.      |
| =auth_server/private.pem=                    | A private key for generating access tokens. You should replace this key file with one of your own. |
| =auth_server/auth.py=                        | Includes method(s) for generating access tokens and more.                                          |
| =auth_server/templates/AC_grant_access.html= | An HTML template for preparing the access request page.                                            |
| =API_server/API_server.py=                   | A simple API server offering access to a list of users.                                            |
| =API_server/public.pem=                      | A public key for verifying access tokens. You should replace this key file with one of your own.   |
| =API_server/auth.py=                         | Includes method(s) for verifying access tokens and more.                                           |
|----------------------------------------------+----------------------------------------------------------------------------------------------------|

**** Running the code
Run the code separately as follows:

#+begin_example
python AC_client.py
python AC_auth_server.py
python API_server.py
#+end_example

Visit the client at http://127.0.0.1:5000. The authorization server listens at
=127.0.0.1:5001= and the API server is available at =127.0.0.1:5002=.

*** How the Authorization Code flow works

**** Redirecting users to the sign-in page provided by the authorization server
The flows starts with users visiting the path =/login=. The following code in
=client/AC_client.py= presents a simple page at =/login= showing a button
prompting users to sign in with the authorization server:

#+begin_src python
@app.route('/login')
def login():
  # Presents the login page
  return render_template('AC_login.html', 
                         dest = AUTH_PATH,
                         client_id = CLIENT_ID,
                         redirect_url = REDIRECT_URL)
#+end_src

Parameters =dest=, =response_type=, =client_id= and =redirect_url= are passed
to build the full redirect URL. When the page is ready, pressing the buttons
will redirect users to:
: http://localhost:5001/auth?response_type=code&client_id=sample-client-id&redirect_url=http://localhost:5000/callback

The value of =response_type=, =code=, indicates the initialization of the
authorization code flow. Since the authorization server in this sample only
supports one flow, the value is not used; however, if you plan to build an
authorization server supporting multiple flows, use this value to determine
which flow to initiate. Additionally, =client_id= uniquely identifies the
client, and =redirect_url= is where the authorization code is sent.

The =auth= method of the authorization server accepts these parameters, and
renders a page describing what the client is requesting access to:

#+begin_src python
@app.route('/auth')
def auth():
  # Describe the access request of the client and ask user for approval
  client_id = request.args.get('client_id')
  redirect_url = request.args.get('redirect_url')

  if None in [ client_id, redirect_url ]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not verify_client_info(client_id, redirect_url):
    return json.dumps({
      "error": "invalid_client"
    })

  return render_template('AC_grant_access.html',
                         client_id = client_id,
                         redirect_url = redirect_url)
#+end_src

If users are OK with the requirements, they can sign in with their
credentials. Sensitive information, such as the user credentials, is handled
solely by the authorization server, thus protects the users (resource
owners). Note that in this step the authorization server also verifies if the
request from the client (redirect URL) matches its claims during the
registration.

**** Returning an authorization code
The authorization server processes the credentials user provided with the
signin method; if the credentials are all correct, this method generates an
authorization code and redirects user back to the client with the code
attached:

#+begin_src python
@app.route('/signin', methods = ['POST'])
def signin():
  # Issues authorization code
  username = request.form.get('username')
  password = request.form.get('password')
  client_id = request.form.get('client_id')
  redirect_url = request.form.get('redirect_url')

  if None in [ username, password, client_id, redirect_url ]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not verify_client_info(client_id, redirect_url):
    return json.dumps({
      "error": "invalid_client"
    })

  if not authenticate_user_credentials(username, password):
    return json.dumps({
      'error': 'access_denied'
    }), 401

  authorization_code = generate_authorization_code(client_id, redirect_url)

  url = process_redirect_url(redirect_url, authorization_code)

  return redirect(url, code = 303)
#+end_src

Authorization code is generated with the =generate_authorization_code= method:

#+begin_src python
def generate_authorization_code(client_id, redirect_url):
  #f = Fernet(KEY)
  authorization_code = f.encrypt(json.dumps({
    "client_id": client_id,
    "redirect_url": redirect_url,
  }).encode())

  authorization_code = base64.b64encode(authorization_code, b'-_').decode().replace('=', '')

  expiration_date = time.time() + CODE_LIFE_SPAN

  authorization_codes[authorization_code] = {
    "client_id": client_id,
    "redirect_url": redirect_url,
    "exp": expiration_date
  }

  return authorization_code
#+end_src

For authorization codes, this sample encrypts a JSON string containing the
fields =client_id=, and =redirect_url= with Fernet, a symmetric encryption
method. It is also OK to produce authorization codes of other formats, as long
as it fits the following criteria:

- Expires after a period of time (10 minutes, for instance)
- Bounds to =client_id= and =redirect_url=


Additionally, one authorization code can only be used once, which implies that
you need to keep a record of authorization codes issued. The code snippet above
stores them, along with their respective expiration dates, in memory with a
dictionary, to keep the sample as simple as possible; in your implementation,
however, you should switch to other data storage solutions, such as [[https://memcached.org/][memcached]]
or [[https://redis.io/][Redis]].

After the authorization code is generated, users are redirected back to the
client with the code embedded in the request.

**** Exchanging the authorization code for an access token
The client receives the authorization code at the callback/ path. The code is
then sent back to the authorization server, along with =client_id=,
=client_secret= and =redirect_url=, in exchange for the access token:

#+begin_src python
@app.route('/callback')
def callback():
  # Accepts the authorization code and exchanges it for access token
  authorization_code = request.args.get('authorization_code')

  if not authorization_code:
    return json.dumps({
      'error': 'No authorization code is received.'
    }), 500

  r = requests.post(TOKEN_PATH, data = {
    "grant_type": "authorization_code",
    "authorization_code": authorization_code,
    "client_id" : CLIENT_ID,
    "client_secret" : CLIENT_SECRET,
    "redirect_url": REDIRECT_URL
  })

  if r.status_code != 200:
    return json.dumps({
      'error': 'The authorization server returns an error: \n{}'.format(
        r.text)
    }), 500

  access_token = json.loads(r.text).get('access_token')

  response = make_response(redirect(url_for('main')))
  response.set_cookie('access_token', access_token)
  return response
#+end_src

For simplicity reasons, at the end of the method the access token is written to
the cookie when it is returned by the authorization server. In real world,
however, most developers prefer storing access token in [[https://developer.mozilla.org/en-US/docs/Web/API/Web_Storage_API][HTML Web Storage]] (for
web applications) or local storage (for mobile applications) instead. It is
worth pointing out that saving access tokens to cookies does not make OAuth 2.0
flows a variant of cookie-based authorization: tokens, though reside in
cookies, are never transferred via cookies; furthermore, components in the flow
can still verify the token independently without having to consult a data
source.

**** Validating the credentials and return an access token
The =exchange_for_token= method of the authorization server
(=auth_server/AC_auth_server.py=) listens for incoming authorization codes,
validates them and replies with an access token:

#+begin_src python
@app.route('/token', methods = ['POST'])
def exchange_for_token():
  # Issues access token
  authorization_code = request.form.get('authorization_code')
  client_id = request.form.get('client_id')
  client_secret = request.form.get('client_secret')
  redirect_url = request.form.get('redirect_url')

  if None in [ authorization_code, client_id, client_secret, redirect_url ]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not authenticate_client(client_id, client_secret):
    return json.dumps({
      "error": "invalid_client"
    }), 400

  if not verify_authorization_code(authorization_code, client_id, redirect_url):
    return json.dumps({
      "error": "access_denied"
    }), 400

  access_token = generate_access_token()

  return json.dumps({
    "access_token": access_token.decode(),
    "token_type": "JWT",
    "expires_in": JWT_LIFE_SPAN
  })
#+end_src

=authenticate_client= method, as its name implies, checks if =client_id= and
=client_secret= match. =verify_authorization_code= method, on the other hand,
confirms that the authorization code is valid. The former method is dummy in
the sample; it always returns True. You should replace them with verification
logic of your own. The latter method, however, is defined in
=auth_server/auth.py=:

#+begin_src python
def verify_authorization_code(authorization_code, client_id, redirect_url):
  #f = Fernet(KEY)
  record = authorization_codes.get(authorization_code)
  if not record:
    return False

  client_id_in_record = record.get('client_id')
  redirect_url_in_record = record.get('redirect_url')
  exp = record.get('exp')

  if client_id != client_id_in_record or \
     redirect_url != redirect_url_in_record:
    return False

  if exp < time.time():
    return False

  del authorization_codes[authorization_code]

  return True
#+end_src

Additionally, =generate_access_token= method is defined as follows:

#+begin_src python
def generate_access_token():
  payload = {
    "iss": ISSUER,
    "exp": time.time() + LIFE_SPAN,
  }

  access_token = jwt.encode(payload, private_key, algorithm = 'RS256')

  return access_token.decode()
#+end_src

This sample uses ~pyjwt~ package to generate JWTs. =iss= is the issuer of this
access token (=sample-auth-server=). =exp= is the expiration date of the access
token, which is set to 1800 seconds (=JWT_LIFE_SPAN=) . Every access token in this
sample is encrypted by a private key and can be decrypted by the corresponding
public key; in other words, every one can check the validity of your access
tokens, yet no one else can issue access tokens on your behalf, as long as the
private key is kept private.

**** Using the access token to access resources
After the access token is received and written to the cookie, the client can
use it to access the API server:

#+begin_src python
@app.route('/')
def main():
  # Retrieves a list of users
  access_token = request.cookies.get('access_token')

  r = requests.get(RES_PATH, headers = {
    'Authorization': 'Bearer {}'.format(access_token)
  })

  if r.status_code != 200:
    return json.dumps({
      'error': 'The resource server returns an error: \n{}'.format(
        r.text)
    }), 500

  users = json.loads(r.text).get('results')

  return render_template('users.html', users = users)
#+end_src

As said earlier, instead of being embedded in the cookie, the access token is
transferred as a part of the Authorization header of the HTTP request.

The =get_user= method from =API_server/API_server.py= extracts the access token
from the header and verifies it with the =verify_access_token= method:

#+begin_src python
def verify_access_token(access_token):
  try:
    decoded_token = jwt.decode(access_token.encode(), public_key,
                               issuer = ISSUER,
                               algorithm = 'RS256')
  except (jwt.exceptions.InvalidTokenError,
          jwt.exceptions.InvalidSignatureError,
          jwt.exceptions.InvalidIssuerError,
          jwt.exceptions.ExpiredSignatureError):
    return False

  return True
#+end_src

We use the ~pyjwt~ package to verify JWTs as well. It checks the signature of
the JWT and makes sure that values of the =iss= and =exp= fields are
valid. Custom fields (if any) are included in the decoded token and can be
manually verified.

*** Important notes
- For simplicity reasons, this sample uses HTTP connection. In your
  implementation though, you should always use HTTPS. The commented out code in
  the sample,

  #+begin_example
  #context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
  #context.load_cert_chain(‘domain.crt’, ‘domain.key’)
  #app.run(port = 5000, debug = True, ssl_context = context)
  #+end_example

  allows applications to serve contents via HTTPS with a private key and a
  self-signed certificate when running locally. It is likely that your browser
  will issue a warning using this approach though, as, obviously, self-signed
  certificates cannot be trusted.

- OAuth2 requires that clients register with the authorization server before
  using the authorization flow. Registration process itself is not considered a
  part of the OAuth 2.0 flow and is up to developers to design and implement
  it. This sample makes the following assumptions:

  1. The client has registered with the authorization server.

  2. The client has received its client ID and client secret provided by the
     authorization server.

- Access tokens in this sample only contains information regarding its issuer
  and expiration date. Depending on your use case, it might be necessary to
  pose more restrictions. Common fields to implement in the access token
  include audience (destinations where access token can reach) and scopes
  (level of access that the token grants).

- When an error occurred, as you can see from the code, OAuth2 regulated that
  authorization server should respond with =HTTP 400 Bad Request= (unless
  specified otherwise) with the following parameters: =error=,
  =error_description= (optional) and =error_uri= (optional). See the
  specification for more information regarding error messages.

- This sample uses client ID and client secret to verify clients and transfers
  them in the body of HTTP requests. OAuth2 specification does not have a set
  method for client verifications though, you may switch to a different
  approach in your authorization flow.

** Article---Building a Basic Authorization Server using Authorization Code Flow (PKCE)
:PROPERTIES:
:cite:     https://medium.com/@ratrosy/building-a-basic-authorization-server-using-authorization-code-flow-pkce-3155e843466
:author:   Ratros Y.
:date:     May 25, 2018
:END:
This document is part of the Understanding OAuth2 and Building a Basic
Authorization Server of Your Own guide. It discusses in detail how
Authorization Code flow works.

*** Before you begin
The sample code in this document uses Python 3 and the flask framework. It is
for demonstration purposes only. The code is designed to demonstrate the
authorization process in an easy-to-understand manner; it does not necessarily
represent the best practices in development.

**** Setting up your environment

**** Downloading the code
Download the source code [[https://github.com/michaelawyu/auth-server-sample][here]].

The sample includes the following files:

| Path                                 | Notes                                                                                              |
|--------------------------------------+----------------------------------------------------------------------------------------------------|
| =auth_server/AC_PKCE_auth_server.py= | An authorization server responsible for issuing access tokens in the Authorization Code flow.      |
| =auth_server/private.pem=            | A private key for generating access tokens. You should replace this key file with one of your own. |
| =auth_server/auth.py=                | Includes method(s) for generating access tokens and more.                                          |
| =auth_server/templates/auth.py=      | An HTML template for preparing the access request page.                                            |
| =API_server/API_server.py=           | A simple API server offering access to a list of users.                                            |
| =API_server/public.pem=              | A public key for verifying access tokens. You should replace this key file with one of your own.   |
| =API_server/auth.py=                 | Includes method(s) for verifying access tokens and more.                                           |
|--------------------------------------+----------------------------------------------------------------------------------------------------|

**** Running the code
Run the code separately as follows:

#+begin_example
python AC_auth_server.py
python API_server.py
#+end_example

The authorization server listens at =127.0.0.1:5001= and the API server is
available at =127.0.0.1:5002=.

*** How the Authorization Code flow with PKCE works

**** Redirecting users to the sign-in page provided by the authorization server
The flow starts with a mobile app prompting users to sign in with the
authorization server. The app then generates a code verifier, which should be a
cryptographically strong random string using only alphanumeric characters, dash
(=-=), dot (=.=), underscore (=_=) and tilde (=~=). Its length should be no
less than 43 characters and no more than 128 characters.

Android developers can use the ~java.security.SecureRandom~ class to prepare the
code verifier:

#+begin_src java
SecureRandom random = new SecureRandom();
byte bytes[] = new byte[64];
random.nextBytes(bytes);
String codeVerifier = Base64.encodeToString(random, Base64.URL_SAFE | Base64.NO_WRAP | Base64.NO_PADDING);
#+end_src

Note that in the end the random string is encoded in =Base64URL= so that it
includes only the permissible characters.

iOS developers can use the [[https://developer.apple.com/documentation/security/1399291-secrandomcopybytes][SecRandomCopyBytes]] method in the [[https://developer.apple.com/documentation/security/][Security Framework]]
to prepare the code verifier (Swift):

#+begin_src c
var buffer = [UInt8](repeating: 0, count: 64)
_ = SecRandomCopyBytes(kSecRandomDefault, buffer.count, &buffer)
let codeVerifier = Data(bytes: buffer).base64EncodedString()
                                      .replacingOccurrences(of: "+", with: "-")
                                      .replacingOccurrences(of: "/", with: "-")
                                      .replacingOccurrences(of: "=", with: "-")
                                      .trimmingCharacters(in: .whitespaces)
#+end_src

Note that in the end the random string is encoded in Base64 with unsupported
characters replaced.

Next, prepare the code verifier’s corresponding code challenge. Code challenge
is merely the SHA-256 hashed value of the code verifier, which should also be
Base64URL encoded.

Android developers can use the java.security.MessageDigest class to prepare the
code challenge:

#+begin_src java
byte[] codeVerifierBytes = codeVerifier.getBytes(“US-ASCII”);
MessageDigest md = MessageDigest.getInstance("SHA-256");
md.update(codeVerifierBytes);
byte[] codeChallengeBytes = md.digest();
String codeChallenge = Base64.encodeToString(codeChallengeBytes, Base64.URL_SAFE | Base64.NO_WRAP | Base64.NO_PADDING);
#+end_src

iOS developers need to add the CommonCrypto library to your bridging header
first before running the code below. You can also use third-party pure Swift
libraries to prepare code challenages, such as [[https://github.com/krzyzanowskim/CryptoSwift][CryptoSwift]].

#+begin_src c
let codeVerifierBytes = codeVerifier.data(using: .ascii)!
var buffer = [UInt8](repeating: 0, count: Int(CC_SHA256_DIGEST_LENGTH))
codeVerifierBytes.withUnsafeBytes {
  _ = CC_SHA256($0, CC_LONG(codeVerifierBytes.count), &buffer)
}
let codeChallengeBytes = Data(bytes: buffer)
let codeChallenge = codeChallengeBytes.base64EncodedString()
                                      .replacingOccurrences(of: "+", with: "-")
                                      .replacingOccurrences(of: "/", with: "_")
                                      .replacingOccurrences(of: "=", with: "")
                                      .trimmingCharacters(in: .whitespaces)
#+end_src

Save the code verifier and the code challenge somewhere safe. Prompt users to
sign in with another platform, then open the browser in the environment (Chrome
for Android, Safari for iOS, etc.) and redirect users to the authorization
server. Pass the following parameters in the query string: =response_type=,
=client_id=, =code_challenge=, =code_challenge_method= and =redirect_url=.

The value of =response_type=, =code=, indicates the initialization of the
authorization code flow. Since the authorization server in this sample only
supports one flow, the value is not used; however, if you plan to build an
authorization server supporting multiple flows, refer to this value to
determine which flow to initiate.

=code_challenge= is the value you just prepared. In this sample it is generated
using =SHA-256= algorithm, thus you should use =S256= as the value of
=code_challenge_method=. PKCE specification allows two possible values for
=code_challenge_method=, =S256= and =plain=, the latter of which should only be
used when =SHA256= is not supported on target devices. Authorization server in
this sample only supports =SHA256=, thus the value of =code_challenge_method= is
not used; however, if you plan to support the plain method as well, refer to
this value to determine how the code challenge should be verified.

Additionally, =client_id= uniquely identifies the client, and =redirect_url= is
where the authorization code is sent. Set up Android App Link (for Android) or
Apple URL Scheme (for iOS) so that the redirection can be intercepted by your
app.

In the end, the final URL should look like:

#+begin_example
http://[YOUR_AUTH_SERVER_ADDRESS]/auth?
response_type=code&
client_id=sample-client-id&
code_challenge=xyz&
code_challenge_method=S256&
redirect_url=[YOUR_APP_URL]/callback
#+end_example

The =auth= method of the authorization server accepts these parameters, and
renders a page describing what the client is requesting access to:

#+begin_src python
@app.route('/auth')
def auth():
  # Describe the access request of the client and ask user for approval
  client_id = request.args.get('client_id')
  redirect_url = request.args.get('redirect_url')
  code_challenge = request.args.get('code_challenge')

  if None in [ client_id, redirect_url, code_challenge ]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not verify_client_info(client_id, redirect_url):
    return json.dumps({
      "error": "invalid_client"
    })

  return render_template('AC_PKCE_grant_access.html',
                         client_id = client_id,
                         redirect_url = redirect_url,
                         code_challenge = code_challenge)
#+end_src

If users are OK with the requirements, they can sign in with their
credentials. Sensitive information, such as the user credentials, is handled
solely by the authorization server, thus protects the users (resource owners)
from possible identity theft. Note that in this step the authorization server
also verifies if the request from the client (redirect URL) matches its claims
during the registration.

You do not need to start an Android or iOS project to try this sample out
though. Instead, you can prepare a code verifier and its corresponding code
challenge in Python and visit the authorization server directly in your
browser:

- Prepare the code verifier and the code challenge:

  #+begin_src python
  import base64
  import hashlib
  import secrets

  random = secrets.token_bytes(64)
  code_verifier = base64.b64encode(random, b'-_').decode().replace('=', '')

  m = hashlib.sha256()
  m.update(code_verifier.encode())
  d = m.digest()
  code_challenge = base64.b64encode(d, b'-_').decode().replace('=', '')
  #+end_src

  Write down the value of =code_verifier= and =code_challenge=.

- Open a new browser window and visit the address below:

  #+begin_example
  https://127.0.0.1:5001/auth?
  response_type=code&
  client_id=sample-acpkce-client&
  redirect_url=https://www.google.com&
  code_challenge=[CODE_CHALLENGE]&
  code_challenge_method=S256
  #+end_example

  Replace =[CODE_CHALLENGE]= with the value of your own. You should see a page
  asking you to sign to grant =sample-acpkece-client= access. Sign in with any
  username and password. You will be redirected to google.com. The address
  looks like:
  : https://www.google.com/?authorization_code=[YOUR_AUTHORIZATION_CODE]

  Write down the value of =authorization_code=.

**** Returning an authorization code
The authorization server processes the credentials user provided with the
=signin= method; if the credentials are all correct, this method generates an
authorization code and redirects user back to the client with the code
attached:

#+begin_src python
@app.route('/signin', methods = ['POST'])
def signin():
  # Issues authorization code
  username = request.form.get('username')
  password = request.form.get('password')
  client_id = request.form.get('client_id')
  redirect_url = request.form.get('redirect_url')
  code_challenge = request.form.get('code_challenge')

  if None in [username, password, client_id, redirect_url, code_challenge]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not verify_client_info(client_id, redirect_url):
    return json.dumps({
      "error": "invalid_client"
    })

  if not authenticate_user_credentials(username, password):
    return json.dumps({
      'error': 'access_denied'
    }), 401

  authorization_code = generate_authorization_code(client_id, redirect_url,
                                                   code_challenge)

  url = process_redirect_url(redirect_url, authorization_code)

  return redirect(url, code = 303)
#+end_src

Authorization code is generated with the =generate_authorization_code= method:

#+begin_src python
def generate_authorization_code(client_id, redirect_url, code_challenge):
  #f = Fernet(KEY)
  authorization_code = f.encrypt(json.dumps({
    "client_id": client_id,
    "redirect_url": redirect_url,
  }).encode())

  authorization_code = base64.b64encode(authorization_code, b'-_').decode().replace('=', '')

  expiration_date = time.time() + CODE_LIFE_SPAN

  authorization_codes[authorization_code] = {
    "client_id": client_id,
    "redirect_url": redirect_url,
    "exp": expiration_date,
    "code_challenge": code_challenge
  }

  return authorization_code
#+end_src

For authorization codes, this sample encrypts a JSON string containing the
fields =client_id=, and =redirect_url= with Fernet, a symmetric encryption method. It
is also OK to produce authorization codes of other formats, as long as it fits
the following criteria:

- Expires after a period of time (10 minutes, for instance)

- Bounds to =client_id= and =redirect_url=


Additionally, one authorization code can only be used once, which implies that
you need to keep a record of authorization codes issued. The code snippet above
stores them, along with their respective expiration dates, in memory with a
dictionary, in order to keep the sample as simple as possible; in your
implementation, however, you should switch to other data storage solutions,
such as [[https://memcached.org/][memcached]] or [[https://redis.io/][Redis]].

**** Exchanging the authorization code for an access token
After your app successfully receives an authorization code, immediately send it
back to authorization server, together with your client ID, redirect URL and
code verifier, in exchange for an access token.

You can use ~cURL~ to simulate such a call:

#+begin_example
curl -d "grant_type=authorization_code&
client_id=sample-acpkce-client&
authorization_code=[AUTHORIZATION_CODE]&
code_verfier=[CODE_VERIFIER]&
redirect_url=https://www.google.com"
-X POST 'https://127.0.0.1:5001/token'
#+end_example

Replace =[AUTHORIZATION_CODE]= and =[CODE_VERIFIER]= with values of your
own. Note that this request includes parameters =grant_type=, =client_id=,
=code_verifier=, =authorization_code= and =redirect_url=.

Write down the returned value of =access_token=.

**** Validating the credentials and return an access token
The =exchange_for_token= method of the authorization server
(=auth_server/AC_PKCE_auth_server.py=) listens for incoming authorization
codes, validates them and replies with an access token:

#+begin_src python
@app.route('/token', methods = ['POST'])
def exchange_for_token():
  # Issues access token
  authorization_code = request.form.get('authorization_code')
  client_id = request.form.get('client_id')
  code_verifier = request.form.get('code_verifier')
  redirect_url = request.form.get('redirect_url')

  if None in [ authorization_code, client_id, code_verifier, redirect_url ]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not verify_authorization_code(authorization_code, client_id, redirect_url,
                                   code_verifier):
    return json.dumps({
      "error": "access_denied"
    }), 400

  access_token = generate_access_token()
  return json.dumps({
    "access_token": access_token,
    "token_type": "JWT",
    "expires_in": JWT_LIFE_SPAN
  })
#+end_src

The =verify_authorization_code= method confirms that the authorization code is
valid:

#+begin_src python
def verify_authorization_code(authorization_code, client_id, redirect_url,
                              code_verifier):
  #f = Fernet(KEY)
  record = authorization_codes.get(authorization_code)
  if not record:
    return False

  client_id_in_record = record.get('client_id')
  redirect_url_in_record = record.get('redirect_url')
  exp = record.get('exp')
  code_challenge_in_record = record.get('code_challenge')

  if client_id != client_id_in_record or \
     redirect_url != redirect_url_in_record:
    return False

  if exp < time.time():
    return False

  code_challenge = generate_code_challenge(code_verifier)
  if code_challenge != code_challenge_in_record:
    return False

  del authorization_codes[authorization_code]

  return True
#+end_src

Note that the code takes the code verifier, generates the corresponding code
challenge and matches it against the one passed by the client earlier.

Additionally, =generate_access_token= method is defined as follows:

#+begin_src python
def generate_access_token():
  payload = {
    "iss": ISSUER,
    "exp": time.time() + LIFE_SPAN,
  }

  access_token = jwt.encode(payload, private_key, algorithm = 'RS256')

  return access_token.decode()
#+end_src

This sample uses ~pyjwt~ package to generate JWTs. =iss= is the issuer of this
access token (=sample-auth-server=). =exp= is the expiration date of the access
token, which is set to 1800 seconds (=JWT_LIFE_SPAN=) after issuing. Every access
token in this sample is encrypted by a private key and can be decrypted by the
corresponding public key; in other words, every one can check the validity of
your access tokens, yet no one else can issue access tokens on your behalf, as
long as the private key is kept private.

**** Using the access token to access resources
After the access token is received and written to the cookie, the client can
use it to access the API server. Access token should be transferred as a part
of the Authorization header of the HTTP request. The header looks like:
: authorization: Bearer YOUR_ACCESS_TOKEN

You can use ~cURL~ to create the same request:
: curl --header "Authorization: Bearer [YOUR_ACCESS_TOKEN]" http://127.0.0.1:5002/users

Replace =[YOUR_ACCESS_TOKEN]= with the value you wrote down earlier. You should
see a list of users in the output.

The =get_user= method from =API_server/API_server.py= extracts the access token
from the header and verifies it with the =verify_access_token= method:

#+begin_src python
def verify_access_token(access_token):
  try:
    decoded_token = jwt.decode(access_token.encode(), public_key,
                               issuer = ISSUER,
                               algorithm = 'RS256')
  except (jwt.exceptions.InvalidTokenError,
          jwt.exceptions.InvalidSignatureError,
          jwt.exceptions.InvalidIssuerError,
          jwt.exceptions.ExpiredSignatureError):
    return False

  return True
#+end_src

We use the ~pyjwt~ package to verify JWTs as well. It checks the signature of the
JWT and makes sure that values of =iss= and =exp= are valid. Custom fields (if any)
are included in the decoded token and can be manually verified.

*** Important notes
- For simplicity reasons, this sample uses HTTP connection. In your
  implementation though, you should always use HTTPS connection. The commented
  out code in the sample,

  #+begin_example
  #context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
  #context.load_cert_chain(‘domain.crt’, ‘domain.key’)
  #app.run(port = 5000, debug = True, ssl_context = context)
  #+end_example

  allows applications to serve contents via HTTPS with a private key and a
  self-signed certificate when running locally. It is likely that your browser
  will issue a warning using this approach though, as, obviously, self-signed
  certificates cannot be trusted.

- OAuth2 requires that clients register with the authorization server before
  using the authorization flow. Registration process itself is not considered a
  part of the OAuth 2.0 flow and is up to developers to design and implement
  it. This sample makes the following assumptions:

  1. The client has registered with the authorization server.

  2. During registration, the client specified which resource servers it plans
     to access, what scopes it needs and the redirect URL it uses.

  3. The client has received its client ID provided by the authorization
     server.

- Access tokens in this sample only contains information regarding its issuer
  and expiration date. Depending on your use case, it might be necessary to
  pose more restrictions. Common fields to implement in the access token
  include audience (destinations where access token can reach) and scopes
  (level of access that the token grants).

- OAuth2 regulated that authorization server should respond with =HTTP 400 Bad
  Request= (unless specified otherwise) with the following parameters: =error=,
  =error_description= (optional) and =error_uri= (optional). See the
  specification for more information regarding error messages.

** Article---Building a Basic Authorization Server with Implicit Flow
:PROPERTIES:
:url:      https://medium.com/@ratrosy/building-a-basic-authorization-server-with-implicit-flow-3f474eb2a306
:date:     May 25, 2018
:author:   Ratros Y.
:END:
This document is part of the Understanding OAuth2 and Building a Basic
Authorization Server of Your Own guide. It discusses in detail how
Authorization Code flow works.

*** Before you begin
The sample code in this document uses Python 3 and the flask framework. It is
for demonstration purposes only. The code is designed to demonstrate the
authorization process in an easy-to-understand manner; it does not necessarily
represent the best practices in development.

**** Setting up your environment

**** Downloading the code

| Path                                               | Notes                                                                                              |
|----------------------------------------------------+----------------------------------------------------------------------------------------------------|
| =auth_server/Implicit_auth_server.py=              | An authorization server responsible for issuing access tokens in the Implicit flow.                |
| =auth_server/private.pem=                          | A private key for generating access tokens. You should replace this key file with one of your own. |
| =auth_server/auth.py=                              | Includes method(s) for generating access tokens and more.                                          |
| =auth_server/templates/Implicit_grant_access.html= | An HTML template for preparing the access request page.                                            |
| =API_server/API_server.py=                         | A simple API server offering access to a list of users.                                            |
| =API_server/public.pem=                            | A public key for verifying access tokens. You should replace this key file with one of your own.   |
| =API_server/auth.py=                               | Includes method(s) for verifying access tokens and more.                                           |
|----------------------------------------------------+----------------------------------------------------------------------------------------------------|

**** Running the code
Run the code separately as follows:

#+begin_example
python Implicit_auth_server.py
python API_server.py
#+end_example

The authorization server listens at 127.0.0.1:5001 and the API server is
available at 127.0.0.1:5002.

*** How the Implicit flow works

**** Redirecting users to the sign-in page provided by the authorization server
The flow starts with a single-page Javascript web app prompting users to sign
in with the authorization server. If the user agrees, the client opens a new
window in browser and redirect users to the authorization server. The following
parameters are passed along: =response_type=, =client_id= and
=redirect_url=. In other words, the redirect URL looks like this:

: http://[YOUR_AUTH_SERVER]/auth?response_type=token&client_id=sample-client-id&redirect_url=[YOUR_APP_URL]

The value of =response_type=, token, indicates the initialization of the
Implicit flow. Since the authorization server in this sample only supports one
flow, the value is not used; however, if you plan to build an authorization
server supporting multiple flows, use this value to determine which flow to
initiate. Additionally, =client_id= uniquely identifies the client, and
=redirect_url= is where the authorization code is sent.

The =auth= method of the authorization server accepts the parameters in the
query string, and renders a page asking users for approval:

#+begin_src python
@app.route('/auth')
def auth():
  # Describe the access request of the client and ask user for approval
  client_id = request.args.get('client_id')
  redirect_url = request.args.get('redirect_url')

  if None in [ client_id, redirect_url ]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not verify_client_info(client_id, redirect_url):
    return json.dumps({
      "error": "invalid_client"
    })

  return render_template('Implicit_grant_access.html',
                         client_id = client_id,
                         redirect_url = redirect_url)
#+end_src

If users are fine with the requirements, they can sign in with their
credentials. Sensitive information, such as the user credentials, is handled
solely by the authorization server, thus protects the users (resource
owners). Note that in this step the authorization server also verifies if the
request from the client (redirect URL) matches its claims during the
registration.

You do not need to develop a single-page Javascript app to try this sample out
though. Instead, open a new browser window and type in the address below:
: https://127.0.0.1:5001/auth?response_type=token&client_id=sample-implicit-client&redirect_url=https://www.google.com

You should see a page asking you to sign in to grant sample-implicit-client
access. Sign in with any username and password, and you will be redirected to
google.com. The address looks like:
: https://www.google.com/?access_token=[YOUR_ACCESS_TOKEN]&token_type=JWT&expires_in=1800

Write down the value of =access_token=.

**** Returning an access token
The authorization server processes the credentials user provided with the
=signin= method; if the credentials are all correct, it issues an access
token. Authorization code is not used in Implicit flow due to the fact that in
single-page Javascript web apps, users have access to the values being
processed behind the scenes by the browser, rendering authorization codes
meaningless.

#+begin_src python
@app.route('/signin', methods = ['POST'])
def signin():
  # Issues authorization code
  username = request.form.get('username')
  password = request.form.get('password')
  client_id = request.form.get('client_id')
  redirect_url = request.form.get('redirect_url')

  if None in [username, password, client_id, redirect_url]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not verify_client_info(client_id, redirect_url):
    return json.dumps({
      "error": "invalid_client"
    })  

  if not authenticate_user_credentials(username, password):
    return json.dumps({
      'error': 'access_denied'
    }), 401

  access_token = generate_access_token()

  print(process_redirect_url(redirect_url, {"1":"2"}))

  return redirect(process_redirect_url(redirect_url, {
    'access_token': access_token,
    'token_type': 'JWT',
    'expires_in': JWT_LIFE_SPAN
    }), code = 303)
#+end_src

This sample uses ~pyjwt~ package to generate JWTs. =iss= is the issuer of this
access token (=sample-auth-server=). =exp= is the expiration date of the access
token, which is set to 1800 seconds (=JWT_LIFE_SPAN=) after issuing. Every
access token in this sample is encrypted by a private key and can be decrypted
by the corresponding public key; in other words, every one can check the
validity of your access tokens, yet no one else can issue access tokens on your
behalf, as long as the private key is kept private.

**** Using the access token to access resources
After the access token is received and written to the cookie, the client can
use it to access the API server. Access token should be transferred as a part
of the Authorization header of the HTTP request. The header looks like:
: authorization: Bearer YOUR_ACCESS_TOKEN

You can use ~cURL~ to create the same request:
: curl --header "Authorization: Bearer [YOUR_ACCESS_TOKEN]" http://127.0.0.1:5002/users

Replace =[YOUR_ACCESS_TOKEN]= with the value you wrote down earlier. You should see
a list of users in the output.

The =get_user= method from =API_server/API_server.py= extracts the access token from
the header and verifies it with the =verify_access_token= method:

#+begin_src python
def verify_access_token(access_token):
  try:
    decoded_token = jwt.decode(access_token.encode(), public_key,
                               issuer = ISSUER,
                               algorithm = 'RS256')
  except (jwt.exceptions.InvalidTokenError,
          jwt.exceptions.InvalidSignatureError,
          jwt.exceptions.InvalidIssuerError,
          jwt.exceptions.ExpiredSignatureError):
    return False

  return True
#+end_src

We use the ~pyjwt~ package to verify JWTs as well. It checks the signature of
the JWT and makes sure that values of =iss= and =exp= are valid. Custom fields
(if any) are included in the decoded token and can be manually verified.

*** Important notes
- For simplicity reasons, this sample uses HTTP connection. In your
  implementation though, you should always use HTTPS connection. The commented
  out code in the sample,

  #+begin_example
  #context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
  #context.load_cert_chain(‘domain.crt’, ‘domain.key’)
  #app.run(port = 5000, debug = True, ssl_context = context)
  #+end_example

  allows applications to serve contents via HTTPS with a private key and a
  self-signed certificate when running locally. It is likely that your browser
  will issue a warning using this approach though, as, obviously, self-signed
  certificates cannot be trusted.

- OAuth2 requires that clients register with the authorization server before
  using the authorization flow. Registration process itself is not considered a
  part of the OAuth 2.0 flow and is up to developers to design and implement
  it. This sample makes the following assumptions:

  1. The client has registered with the authorization server.

  2. During registration, the client specified which resource servers it plans
     to access, what scopes it needs and the redirect URL it uses.

  3. The client has received its client ID provided by the authorization
     server.

- Access tokens in this sample only contains information regarding its issuer
  and expiration date. Depending on your use case, it might be necessary to add
  more checks. Common fields to implement in the access token include audience
  (destinations where access token can reach) and scopes (level of access the
  token grants).

- OAuth2 regulated that authorization server should respond with =HTTP 400 Bad
  Request= (unless specified otherwise) with the following parameters: =error=,
  =error_description= (optional) and =error_uri= (optional). See the specification
  for more information regarding error messages.

** Article---Building a Basic Authorization Server Using Resource Owner Password Credentials Flow
:PROPERTIES:
:cite:     https://medium.com/@ratrosy/building-a-basic-authorization-server-using-resource-owner-password-credentials-flow-a666d06900fb
:date:     May 25, 2018
:author:   Ratros Y.
:END:
This document is part of the Understanding OAuth2 and Building a Basic
Authorization Server of Your Own guide. It discusses in detail how Resource
Owner Password Credentials flow works.
*** Before you begin
The sample code in this document uses Python 3 and the flask framework. It is
for demonstration purposes only. The code is designed to demonstrate the
authorization process in an easy-to-understand manner; it does not necessarily
represent the best practices in development.

**** Setting up your environment
**** Downloading the code
Download the source code [[https://github.com/michaelawyu/auth-server-sample][here]].

The sample includes the following files:

| Path                               | Notes                                                                                              |
|------------------------------------+----------------------------------------------------------------------------------------------------|
| =client/ROPC_client.py=            | A client web application using the ROPC flow to access a list of users.                            |
| =client/public.pem=                | A public key for verifying access tokens. You should replace this key file with one of your own.   |
| =client/templates/ROPC_login.html= | An HTML template for preparing the login page.                                                     |
| =client/templates/users.html=      | An HTML template for preparing the results of user queries.                                        |
| =auth_server/ROPC_auth_server.py=  | An authorization server responsible for issuing access tokens in the ROPC flow.                    |
| =auth_server/private.pem=          | A private key for generating access tokens. You should replace this key file with one of your own. |
| =auth_server/auth.py=              | Includes method(s) for generating access tokens.                                                   |
| =API_server/API_server.py=         | A simple API server offering access to a list of users.                                            |
| =API_server/public.pem=            | A public key for verifying access tokens. You should replace this key file with one of your own.   |
| =API_server/auth.py=               | Includes method(s) for verifying access tokens and more.                                           |
|------------------------------------+----------------------------------------------------------------------------------------------------|

**** Running the code
Run the code as follows:

#+begin_example
python ROPC_client.py
python ROPC_auth_server.py
python API_server.py
#+end_example

Visit the client at http://127.0.0.1:5000. The authorization server listens at
=127.0.0.1:5001= and the API server is available at =127.0.0.1:5002=.

*** How the Resource Owner Password Credentials flow works

**** Prompting users to enter credentials
The flows starts with users visiting the path =/login=. The following code in
=client/ROPC_client.py= presents a page at the =/login= path where users can
enter their credentials:

#+begin_src python
@app.route('/login')
def login():
  # Presents the login page
  return render_template('ROPC_login.html')
#+end_src

**** Sending the credentials to authorization server
The login page is configured to send the credentials to the path
=/request_token= upon submission. Code below collects the credentials, and POST
them to the authorization server:

#+begin_src python
@app.route('/request_token', methods = ['POST'])
def request_token():
  # Requests access token from the authorization server
  username = request.form.get('username')
  password = request.form.get('password')
  r = requests.post(AUTH_PATH, data = {
    'grant_type': 'password',
    'username': username,
    'password': password,
    'client_id': CLIENT_ID,
    'client_secret': CLIENT_SECRET,
  })

  if r.status_code != 200:
    return json.dumps({
      'error': 'The authorization server returns an error: \n{}'.format(
        r.text)
    }), 500

  contents = json.loads(r.text)
  access_token = contents.get('access_token')

  # Writes access token to the cookie
  response = make_response(redirect(url_for('main')))
  response.set_cookie('access_token', access_token)

  return response
#+end_src

Along with the credentials (=username= and =password=) goes the fields
=grant_type=, =client_id= and =client_secret=.

=grant_type= is required by OAuth 2.0, whose value, =password=, indicates the
initialization of the Resource Owner Password Credentials flow. Since the
authorization server in this sample only supports one flow, the value is not
used; however, if you plan to build an authorization server supporting multiple
flows, use this value to determine which flow to initiate. The other fields,
=client_id= and =client_secret=, as specified earlier, uniquely identify the
client.

For simplicity reasons, at the end of the method the access token is written to
the cookie when it is returned by the authorization server. In real world,
however, many developers prefer storing access token in [[https://developer.mozilla.org/en-US/docs/Web/API/Web_Storage_API][HTML Web Storage]] (for
web applications) or local storage (for mobile applications) instead. It is
worth pointing out that saving access tokens to cookies does not make OAuth 2.0
flows a variant of cookie-based authorization: tokens, though now reside in
cookies, are never transferred via cookies.

**** Validating the credentials and return an access token
The =auth= method of the authorization server
(=auth_server/ROPC_auth_server.py=) listens for incoming user credentials,
validates them and replies with an access token:

#+begin_src python
@app.route('/auth', methods = ['POST'])
def auth():
  # Issues access token
  username = request.form.get('username')
  password = request.form.get('password')
  client_id = request.form.get('client_id')
  client_secret = request.form.get('client_secret')

  if None in [username, password, client_id, client_secret]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not authenticate_user_credentials(username, password):
    return json.dumps({
      "error": "access_denied"
    }), 401

  if not authenticate_client(client_id, client_secret):
    return json.dumps({
      "error": "invalid_client"
    }), 400

  access_token = generate_access_token()
  return json.dumps({
    "access_token": access_token,
    "token_type": "JWT",
    "expires_in": LIFE_SPAN
  })
#+end_src

=authenticate_user_credentials= method, as its name implies, checks if the
username and the password match. =authenticate_client= method, on the other
hand, confirms if the client is registered with the authorization server. Both
methods are dummy methods in the sample; they always return =True=. You should
replace them with verification logic of your own.

The method for building access tokens, =generate_access_token=, is defined as
follows:

#+begin_src python
def generate_access_token():
  payload = {
    "iss": ISSUER,
    "exp": time.time() + LIFE_SPAN,
  }

  access_token = jwt.encode(payload, private_key, algorithm = 'RS256')

  return access_token.decode()
#+end_src

This sample uses the ~pyjwt~ package to generate JWTs. =iss= is the issuer of
this access token (=sample-auth-server=); =exp= is the expiration date of the
access token, which is set to 1800 seconds (=LIFE_SPAN=) . Every access token
in this sample is encrypted by a private key (=auth_server/private.pem=) and
can be decrypted by its corresponding public key (=client/public.pem= and
=API_server/public.pem=); in other words, every one can check the validity of
your access tokens, yet no one else can issue access tokens on your behalf, as
long as the private key is kept private.

**** Using the access token to access resources
After the access token is received and written to the cookie, the client can
then use it to access the API server:

#+begin_src python
@app.route('/')
def main():
  # Retrieves a list of users
  access_token = request.cookies.get('access_token')
  r = requests.get(RES_PATH, headers = {
    'Authorization': 'Bearer {}'.format(access_token)
  })

  if r.status_code != 200:
    return json.dumps({
      'error': 'The resource server returns an error: \n{}'.format(
        r.text)
    }), 500

  contents = json.loads(r.text)
  users = contents.get('results')
  return render_template('users.html', users = users)
#+end_src

As said earlier, instead of being embedded in the cookie, the access token is
transferred as a part of the Authorization header of the HTTP request.

The =get_user= method from =API_server/API_server.py= extracts the access token
from the header and verifies it with the =verify_access_token= method:

#+begin_src python
def verify_access_token(access_token):
  try:
    decoded_token = jwt.decode(access_token.encode(), public_key,
                               issuer = ISSUER,
                               algorithm = 'RS256')
  except (jwt.exceptions.InvalidTokenError,
          jwt.exceptions.InvalidSignatureError,
          jwt.exceptions.InvalidIssuerError,
          jwt.exceptions.ExpiredSignatureError):
    return False

  return True
#+end_src

We use the ~pyjwt~ package to verify JWTs as well. It checks the signature of
the JWT and makes sure that values of the =iss= and =exp= fields are
valid. Custom fields (if any) are included in the decoded token and can be
manually verified.

*** Important Notes
- For simplicity reasons, servers in this sample uses HTTP connection. In your
  implementation though, you should always use HTTPS. The following commented
  out code in the sample,

  #+begin_example
  #context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
  #context.load_cert_chain(‘domain.crt’, ‘domain.key’)
  #app.run(port = 5000, debug = True, ssl_context = context)
  #+end_example

  allows the server to serve contents via HTTPS with a private key and a
  self-signed certificate when running locally. It is likely that your browser
  will issue a warning using this approach though, as, obviously, self-signed
  certificates cannot be easily trusted.

- OAuth2 requires that clients register with the authorization server before
  using the authorization flow. Registration process itself is not considered a
  part of the OAuth 2.0 flow and is up to developers themselves to design and
  implement it. This sample makes the following assumptions:

  1. The client has registered with the authorization server.

  2. The client has received its client ID and client secret provided by the
     authorization server.

- Access tokens in this sample only contains information regarding its issuer
  and expiration date. Depending on your use case, it might be necessary to
  pose more restrictions. Common fields to implement in the access token
  include =audience= (destinations where access token can reach) and =scopes=
  (level of access that the token grants).

- When an error occurred, OAuth2 regulated that authorization server should
  respond with =HTTP 400 Bad Request= (unless specified otherwise) with the
  following parameters: =error=, =error_description= (optional) and =error_uri=
  (optional). See the specification for more information regarding error
  messages.

- This sample uses client ID and client secret to verify clients and transfers
  them in the body of HTTP requests. OAuth2 specification does not have a set
  method for client verifications though, you may switch to a different
  approach in your authorization flow.

** Article---Building a Basic Authorization Server using Client Credentials Flow
:PROPERTIES:
:url:      https://medium.com/@ratrosy/building-a-basic-authorization-server-using-client-credentials-flow-db353d6debdf
:author:   Ratros Y.
:date:     May 25, 2018
:END:
This document is part of the Understanding OAuth2 and Building a Basic
Authorization Server of Your Own guide. It discusses in detail how Client
Credentials flow works.

*** Before you begin
The sample code in this document uses Python 3 and the flask framework. It is
for demonstration purposes only. The code is designed to demonstrate the
authorization process in an easy-to-understand manner; it does not necessarily
represent the best practices in development.

**** Setting up your environment

**** Downloading the code
Download the source code [[https://github.com/michaelawyu/auth-server-sample][here]].

The sample includes the following files:

| Path                            | Notes                                                                                              |
|---------------------------------+----------------------------------------------------------------------------------------------------|
| =auth_server/CC_auth_server.py= | An authorization server responsible for issuing access tokens in the Client Credentials flow.      |
| =auth_server/private.pem=       | A private key for generating access tokens. You should replace this key file with one of your own. |
| =auth_server/auth.py=           | Includes method(s) for generating access tokens and more.                                          |
| =API_server/API_server.py=      | A simple API server offering access to a list of users.                                            |
| =API_server/public.pem=         | A public key for verifying access tokens. You should replace this key file with one of your own.   |
| =API_server/auth.py=            | Includes method(s) for verifying access tokens and more.                                           |
|---------------------------------+----------------------------------------------------------------------------------------------------|

**** Running the code
Run the code separately as follows:

#+begin_example
python CC_auth_server.py
python API_server.py
#+end_example

The authorization server listens at 127.0.0.1:5001 and the API server is
available at 127.0.0.1:5002.

*** How the Client Credentials flow works

**** Sending the credentials to authorization server
To request an access token, the client must pass its identification, the client
ID and the client secret, to the authorization server. It should send a HTTP
request to the authorization server with the following fields in the body:
=grant_type=, =client_id= and =client_secret=.

=grant_type= is a required field in OAuth 2.0, and its value,
=client_credentials=, indicates the initialization of the Client Credentials
flow. Since the authorization server in this sample only supports one flow, the
value is not used; however, if you plan to build an authorization server
supporting multiple flows, use this value to determine which flow to
initiate. The other fields, =client_id= and =client_secret=, as specified
earlier, uniquely identifies the client.

You do not need to develop a background service to try this sample out
though. Instead, you can use ~cURL~ to send the same request:

#+begin_example
curl -d "grant_type=client_credentials&
client_id=sample-cc-client&
client_secret=sample-client-secret"
-X POST 'https://127.0.0.1:5001'
#+end_example

The output should look like:

#+begin_src js
{"access_token":"[YOUR_ACCESS_TOKEN]",
 "token_type":"JWT",
 "expires_in":1800}
#+end_src

Write down the returned access token.

**** Validating the credentials and return an access token
The =auth= method of the authorization server (=auth_server/CC_auth_server.py=)
listens for incoming client credentials, validates them and replies with an
access token:

#+begin_src python
@app.route('/auth', methods = ['POST'])
def auth():
  # Issues access token
  client_id = request.form.get('client_id')
  client_secret = request.form.get('client_secret')

  if None in [client_id, client_secret]:
    return json.dumps({
      "error": "invalid_request"
    }), 400

  if not authenticate_client(client_id, client_secret):
    return json.dumps({
      "error": "invalid_client"
    }), 400

  access_token = generate_access_token()
  return json.dumps({
    "access_token": access_token,
    "token_type": "JWT",
    "expires_in": LIFE_SPAN
  })
#+end_src

The =authenticate_client= method, confirms that the client is registered with the
authorization server. It is a dummy method in the sample and always returns
=True=. You should replace it with verification logic of your own.

The method for building access tokens, =generate_access_token=, is defined as
follows:

#+begin_src python
def generate_access_token():
  payload = {
    "iss": ISSUER,
    "exp": time.time() + LIFE_SPAN,
  }

  access_token = jwt.encode(payload, private_key, algorithm = 'RS256')

  return access_token.decode()
#+end_src

This sample uses the ~pyjwt~ package to generate JWTs. =iss= is the issuer of
this access token (=sample-auth-server=); =exp= is the expiration date of the
access token, which is set to 1800 seconds (=LIFE_SPAN=) . Every access token
in this sample is encrypted by a private key (=auth_server/private.pem=) and
can be decrypted by its corresponding public key (=client/public.pem= and
=API_server/public.pem=); in other words, every one can check the validity of
your access tokens, yet no one else can issue access tokens on your behalf, as
long as the private key is kept private.

**** Using the access token to access resources
After the access token is received and written to the cookie, the client can
then use it to access the API server. The access token should be transferred in
the header of the HTTP request. The header looks like:
: Authorization: Bearer [YOUR_ACCESS_TOKEN]

You can use ~cURL~ to create the same request:
: curl --header "Authorization: Bearer [YOUR_ACCESS_TOKEN]" http://127.0.0.1:5002/users

Replace =[YOUR_ACCESS_TOKEN]= with the value you wrote down earlier. You should
see a list of users in the output.

The =get_user= method from =API_server/API_server.py= extracts the access token
from the header and verifies it with the =verify_access_token= method:

#+begin_src python
def verify_access_token(access_token):
  try:
    decoded_token = jwt.decode(access_token.encode(), public_key,
                               issuer = ISSUER,
                               algorithm = 'RS256')
  except (jwt.exceptions.InvalidTokenError,
          jwt.exceptions.InvalidSignatureError,
          jwt.exceptions.InvalidIssuerError,
          jwt.exceptions.ExpiredSignatureError):
    return False

  return True
#+end_src

We use the ~pyjwt~ package to verify JWTs as well. It checks the signature of the
JWT and makes sure that values of iss and exp are valid. Custom fields (if any)
are included in the decoded token and can be manually verified.

*** Important Notes
- For simplicity reasons, servers in this sample uses HTTP connection. In your
  implementation though, you should always use HTTPS. The following commented
  out code in the sample,

  #+begin_example
  #context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
  #context.load_cert_chain(‘domain.crt’, ‘domain.key’)
  #app.run(port = 5000, debug = True, ssl_context = context)
  #+end_example

  allows the server to serve contents via HTTPS with a private key and a
  self-signed certificate when running locally. It is likely that your browser
  will issue a warning using this approach though, as, obviously, self-signed
  certificates cannot be easily trusted.

- OAuth2 requires that clients register with the authorization server before
  using the authorization flow. Registration process itself is not considered a
  part of the OAuth 2.0 flow and is up to developers to design and implement
  it. This sample makes the following assumptions:

  1. The client has registered with the authorization server.

  2. The client has received its client ID and client secret provided by the
     authorization server.

- Access tokens in this sample only contains information regarding its issuer
  and expiration date. Depending on your use case, it might be necessary to
  pose more restrictions. Common fields to implement in the access token
  include audience (destinations where access token can arrive at) and scopes
  (level of access that the token grants).

- When an error occurred, as you can see from the code, OAuth2 regulated that
  authorization server should respond with =HTTP 400 Bad Request= (unless
  specified otherwise) with the following parameters: =error=,
  =error_description= (optional) and =error_uri= (optional). See the
  specification for more information regarding error messages.

- This sample uses client ID and client secret to verify clients and transfers
  them in the body of HTTP requests. OAuth2 specification does not have a set
  method for client verifications though, you may use a different approach in
  your authorization flow.

** Article---Understanding OAuth2 and Deploying a Basic OAuth2 Authorization Service to Cloud Functions
This tutorial explains the basics of OAuth 2.0 and how to deploy an OAuth2
authorization service in Node.js to [[https://cloud.google.com/functions/][Google Cloud Functions]].

Google Cloud Functions is an event-driven serverless compute platform. It
offers one of the simplest ways to run code in the cloud and provides
developers with automatic scaling, high availability and fault tolerance. As a
part of the computing solutions on Google Cloud Platform, your Cloud Functions
can easily integrate with other Google Cloud services.

*** Objectives
- Understand the basics of OAuth 2 and the architecture of the project

- Deploy the code to Cloud Functions

*** Costs
This tutorial uses billable components of Google Cloud Platform, including
- Google Cloud Functions

- Google Cloud Datastore


Use the [[https://cloud.google.com/products/calculator/][Pricing Calculator]] to generate a cost estimate based on your projected
usage. Depending on the actual usage, you might be eligible for [[https://cloud.google.com/free/][Google Cloud
Free Tier]].

*** Before You Begin
1. Select a project from [[https://console.cloud.google.com/][Google Cloud Console]]. If you have never used Google
   Cloud Platform before, sign up or log in with your existing Google account,
   then follow the on-screen instructions to start using Google Cloud Platform.

2. [[https://cloud.google.com/billing/docs/how-to/modify-project#enable_billing_for_a_project][Enable billing]] for your account.

3. [[https://console.cloud.google.com/flows/enableapi?apiid=cloudfunctions&redirect=https://cloud.google.com/functions/quickstart][Enable the Cloud Functions API.]]

4. [[https://cloud.google.com/sdk/][Install the Google Cloud SDK]].

5. Windows Developers Only: Install cURL.

6. Create the following entities in Cloud Datastore:

   - Go to [[https://console.cloud.google.com/datastore][Cloud Datastore Entities Page]] in Google Cloud Console.

   - Click =Create Entity=. Cloud Datastore may ask you to pick a location to
     store your data; select one of the locations and click =Next=.

   - Type =user= for Kind.

   - Click =Add Property=.

   - Add a property =username= of the =String= type with the value
     =sample-user=. Click =Done=.

   - Add a property =password= of the =String= type with the value
     =sample-password=. Click =Done=.

   - Click =Create=.

   - Repeat the steps above and create 5 =client= kind entities, with the
     following properties:

*** Concepts

**** OAuth 2.0
OAuth 2.0 ([[https://tools.ietf.org/html/rfc6479][RFC 6479]]) is a widely used authorization framework enabling
applications to access resources in all kinds of services. More specifically,
OAuth 2.0 allows arbitrary clients (for example, a highly trusted first-party
mobile app or a less trusted third-party web app) to access user’s (resource
owner’s) resources on resource servers via authorization servers in a secure,
reliable, and efficient manner.

**** Authorization Flows
OAuth 2.0 specification defines 4 types of authorization flows:

- Authorization Code

- Resource Owner Password Credentials

- Implicit

- Client Credentials


Implicit and Client Credentials are flows typically reserved for special types
of clients:

| Client Type                                                         | Flow        |
|---------------------------------------------------------------------+-------------|
| Single-page Javascript Web Applications (for example, Google Fonts) | Implicit    |
| Non-interactive programs for machine-to-machine communications      | Client      |
| (for example, background services and daemons)                      | Credentials |
|---------------------------------------------------------------------+-------------|

As for other clients, depending on their trustworthiness, they can use the
following flows:

| Client Type                                           | Flow                                |
|-------------------------------------------------------+-------------------------------------|
| Highly trusted apps (first-party apps)                | Authorization Code or               |
|                                                       | Resource Owner Password Credentials |
| Less trusted apps                                     | Authorization Code                  |
| (third-party apps requesting access to your platform) |                                     |
|-------------------------------------------------------+-------------------------------------|

This tutorial deploys a basic authorization server supporting all of the four
flows; you can, however, tailor the code and drop the support for some of them
based on your use case.

***** Authorization Code

[[file:./resources/oauth2_authorization_code_flow-50.png]]

The Authorization Code flow includes the following steps:

1. The client prepares a link to the authorization server and opens the link
   for user in a user agent (browser). The link includes information that
   allows the authorization server to identify and respond to the client.

2. User enters their credentials on the new page.

3. Credentials are sent to authorization server via the user agent (browser).

4. The authorization server validates the credentials and redirects user back
   to the client with an authorization code.

5. The client talks with the authorization server, confirms its identify and
   exchanges the authorization code for an access token and optionally a
   refresh token.

6. The client uses the access token to access resources on the resource server.


Note that due to security concerns, even though both mobile app clients and web
app clients can use the authorization code flow, their approaches to identify
themselves in the flow are different. Web app clients use client IDs and client
secrets, while mobile app clients need to adopt the [[https://tools.ietf.org/html/rfc7636][Proof Key for Code Exchange
(PKCE)]] technique and utilize code challenges and code verifiers.

PKCE specification requires client generate a code verifier first, then prepare
a code challenge based on the code verifier. Usually, code verifier is a
cryptographically strong random long string (43–128 characters) and code
challenge should be its SHA-256 hash. Both should be Base64URL encoded. Client
first sends code challenge to the authorization server; after the authorization
code is issued, client uses code verifier together with authorization code to
request access token from authorization server. The authorization server then
verifies the code challenge using the code verifier and decides if an access
token can be granted.

Authorization Code flow requires that clients be able to interact with a user
agent (browser) in the environment.

***** Resource Owner Password Credentials

[[file:./resources/oauth2_password_credentials_flow-50.png]]

The Resource Owner Password Credentials flow includes the following steps:

1. The client prompts user to enter their credentials (for instance, a
   username/password combination).

2. The client sends the credentials and its own identification to the
   authorization server. The authorization server validates the information,
   then returns an access token and optionally a refresh token.

3. The client uses the access token to access resources on the resource server.


Resource Owner Password Credentials flow requires that clients be highly
trustworthy. In most cases, the client should be a first-party app.

***** Implicit
Implicit flow, as said earlier, is designed for single-page Javascript
apps. This flow is vastly similar to the Authorization Code flow, except for
the part involving authorization code. Due to security concerns, in this flow
the client no longer receives an authorization code from the authorization
server; instead, after the user agent successfully transfers credentials, the
authorization server returns access tokens directly to the client. Refresh
tokens are not allowed in the Implicit flow.

[[file:./resources/oauth2_implicit_flow-50.png]]

***** Client Credentials
Client Credentials flow, on the other hand, is closer to the Resource Owner
Password Credentials flow. Clients in this flow use client IDs and secrets to
identify themselves, and exchange them for access tokens with the authorization
server. You should not use refresh tokens in this flow either.

[[file:./resources/oauth2_client_credentials_flow-50.png]]

**** JWT
Tokens play an important part in OAuth 2.0. There are two types of tokens:
access tokens and refresh tokens. Anyone with a valid access token can access
protected resources; usually it is short-lived so that even if there is a
security breach and the access token is leaked, the damage can be quickly
controlled. When an access token expires, developers can use an optional
refresh token to request a new access token without having to ask the user to
enter their credentials again.

It is up to developers themselves to choose the format of token for their OAuth
2.0 authorization service. This tutorial uses [[https://tools.ietf.org/html/rfc7519][JWT (JSON Web Token)]], a
self-contained format allowing servers to validate tokens without having to
inquire a data source.

A JWT includes three parts:

- A header describing the type of the token and the hashing algorithm it uses

- A payload containing the data

- A signature for verifying the token


You can use many hashing algorithms with JWT and the payload offers a variety
of pre-defined fields (also known as [[https://tools.ietf.org/html/rfc7519#section-4.1][registered claim names]]). This Beginner’s
Guide uses the [[https://en.wikipedia.org/wiki/RSA_%2528cryptosystem%2529][RS256]] (RSA Signature with SHA-256) algorithm and specifies two
registered claims in the payload: =exp= (when does the token expire), and =iss=
(who issues the token). Aside from the supported claims, you can also define
your own claims in the payload, such as the scope of the token.

Every time a JWT arrives at a server, the system first parses the JWT, and
verifies if the algorithm specified in the header is supported; then it checks
the signature to make sure that the JWT is valid, and at last, confirms that
registered claims (if exist) are valid. In the case of this guide, it means
making sure that the JWT hasn’t expired (=exp=), and comes from an expected
origin (=iss=). Custom claims, such as scopes, can be extracted from the token
and manually validated.

**** Client Registration
OAuth 2.0 requires that clients register with the authorization server
beforehand. The registration process is not considered as a part of the
authorization flow and developers can implement it as they see
fit. Additionally, your OAuth 2.0 authorization service must be able to verify
the identity of clients. This tutorial uses client IDs and client secrets for
client authentication.

*** Understanding the Architecture

[[file:./resources/oauth2_architecture-50.png]]

This tutorial deploys 3 Cloud Functions. The token function is responsible for
issuing access tokens while the auth function and the signin function work
together to grant authorization codes. More specifically,

- Clients in the Resource Owner Password Credentials flow exchange user
  credentials for access token with the token function

- Clients in the Authorization Code flow first request an authorization code
  from function auth and signin, then exchange it for access token with the
  token function

- Clients in the Implicit flow directly request access token from function auth
  and signin

- Clients in the Client Credentials flow exchange client credentials for access
  token with the token function

*** Downloading the Code
Download the code [[https://github.com/michaelawyu/auth-server-sample/tree/master/GCF/code][here]].

The sample includes the following files:

| File         | Notes                                                                                              |
|--------------+----------------------------------------------------------------------------------------------------|
| auth.pug     | A [[https://github.com/pugjs/pug][pug]] HTML template for preparing the access request page.                                         |
| function.js  | Functions to deploy.                                                                               |
| package.json | [[https://docs.npmjs.com/files/package.json][Project metadata]].                                                                                  |
| private.pem  | A private key for generating access tokens. You should replace this key file with one of your own. |
| public.pem   | A public key for verifying access tokens. You should replace this key file with one of your own.   |
|--------------+----------------------------------------------------------------------------------------------------|

**** Deploying the Code
Deploy the functions using the following commands. It may take a few minutes to
finish.

#+begin_example
gcloud beta functions deploy token - trigger-http
gcloud beta functions deploy auth - trigger-http
gcloud beta functions deploy signin - trigger-http
#+end_example

Your functions are available at

#+begin_example
https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/token
https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/auth
https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/signin
#+end_example

Replace =[GCP_REGION]= and =[PROJECT_ID]= with values of your own. Your
function addresses are also available in the output of the =gcloud beta
functions deploy= command.

You can always view the details of deployed functions via [[https://console.cloud.google.com/functions][Cloud Console]].

*** Testing the Code

**** Authorization Code
1. Open your browser and visit
   #+begin_example
   https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/auth?
   response_type=code&
   client_id=sample-ac-client&
   redirect_url=https://www.google.com
   #+end_example

   Replace =[GCP_REGION]= and =[PROJECT_ID]= with values of your own. Note that
   parameters =response_type=, =client_id=, and =redirect_url= are added to the
   address.

2. Sign in with =sample-username= and =sample-password=. You will be redirected to
   =google.com=. The address should look like:
   : https://www.google.com/?authorization_code=[YOUR_AUTHORIZATION_CODE]

   Write down the returned authorization code.

3. Run command

   #+begin_example
   curl -d “grant_type=authorization_code&
   client_id=sample-ac-client&
   client_secret=sample-client-secret&
   authorization_code=[AUTHORIZATION_CODE]&
   redirect_url=https://www.google.com"
   -X POST ‘https://us-central1-testbed-195403.cloudfunctions.net/token'
   #+end_example

   Replace =[AUTHORIZATION_CODE]= with the value of your own. Note that this
   request includes parameters =grant_type=, =client_id=, =client_secret=,
   =authorization_code= and =redirect_url=.

   The output should look like:

   #+begin_src js
   {"access_token":"[YOUR_ACCESS_TOKEN]",
    "token_type”:"JWT",
    "expires_in":1800000}
   #+end_src

   The =access_token= attribute in the returned JSON file is the issued access
   token.

**** Authorization Code (PKCE)
1. Generate a code verifier and its code challenge. Open the node interactive
   shell (node) and run the following code:

   #+begin_src js
   // You might need to install package crypto with npm i -g crypto first
   const crypto = require('crypto');
   var code_verifier = crypto.randomBytes(64)
                         .toString('base64')
                         .replace(/\+/g, '-')
                         .replace(/\//g, '_')
                         .replace(/=/g, '');
   var code_challenge = crypto.createHash('sha256')
                         .update(code_verifier)
                         .digest()
                         .toString('base64')
                         .replace(/\+/g, '-')
                         .replace(/\//g, '_')
                         .replace(/=/g, '');
   #+end_src

   Write down the values of =code_verifier= and =code_challenge=.

2. Open your browser and visit:

   #+begin_example
   https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/auth?
   response_type=code&
   client_id=sample-acpkce-client&
   redirect_url=https://www.google.com&code_challenge=[CODE_CHALLENGE]&code_challenge_method=S256
   #+end_example

   Replace =[GCP_REGION]=, =[PROJECT_ID]= and =[CODE_CHALLENGE]= with values of your
   own. Note that parameters =response_type=, =client_id=, =redirect_url=, =code_challenge=
   and =code_verifier= are added to the address.

3. Sign in with =sample-username= and =sample-password=. You will be redirected to
   =google.com=. The address should look like:

   : https://www.google.com/?authorization_code=[YOUR_AUTHORIZATION_CODE]

   Write down the returned authorization code.

4. Run command:

   #+begin_example
   curl -d "grant_type=authorization_code&
   client_id=sample-acpkce-clientauthorization_code=[AUTHORIZATION_CODE]&
   code_verfier=[CODE_VERIFIER]&
   redirect_url=https://www.google.com"
   -X POST 'https://us-central1-testbed-195403.cloudfunctions.net/token'
   #+end_example

   Replace =[AUTHORIZATION_CODE]= and =[CODE_VERIFIER]= with values of your
   own. Note that this request includes parameters =grant_type=, =client_id=,
   =code_verifier=, =authorization_code= and =redirect_url=.

   The output should like:

   #+begin_src js
   {"access_token":"[YOUR_ACCESS_TOKEN]",
    "token_type":"JWT","expires_in":1800000}
   #+end_src

   The =access_token= attribute in the returned JSON file is the issued access
   token.

**** Implicit
1. Open your browser and visit:

   #+begin_example
   https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/auth?
   response_type=token&
   client_id=sample-implicit-client&
   redirect_url=https://www.google.com
   #+end_example

   Replace =[GCP_REGION]= and =[PROJECT_ID]= with values of your own. Note that
   parameters =response_type=, =client_id=, and =redirect_url= are added to the
   address.

2. Sign in with =sample-username= and =sample-password=. You will be redirected to
   =google.com=. The address should look like:
   : https://www.google.com/?access_token=[YOUR_ACCESS_TOKEN]&token_type=JWT&expires_in=1800000

   The value of =access_token= is the issued access token.

**** Resource Owner Password Credentials
1. Run command

   #+begin_example
   curl -d “grant_type=password&
   client_id=sample-ropc-client&
   username=sample-username&
   password=sample-password&
   client_secret=sample-client-secret”
   -X POST ‘https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/token'
   #+end_example

   Replace =[GCP_REGION]= and =[PROJECT_ID]= with values of your own. Note that
   this request includes parameters =grant_type=, =client_id=, =client_secret=,
   username, and password.

   The output should like:

   #+begin_src js
   {"access_token":"[YOUR_ACCESS_TOKEN]",
    "token_type":"JWT","expires_in":1800000}
   #+end_src

   The =access_token= attribute in the returned JSON file is the issued access
   token.

**** Client Credentials
1. Run command

   #+begin_example
   curl -d "grant_type=client_credentials&
   client_id=sample-cc-client&
   client_secret=sample-client-secret"
   -X POST 'https://[GCP_REGION]-[PROJECT_ID].cloudfunctions.net/token'
   #+end_example

   The output should like:

   #+begin_src js
   {"access_token":"[YOUR_ACCESS_TOKEN]",
    "token_type":"JWT","expires_in":1800000}
   #+end_src

   The =access_token= attribute in the returned JSON file is the issued access
   token.

*** Understanding the Code

**** =auth= Function
The =auth= function is responsible for presenting a page where users can
authorize clients to access their information:

#+begin_src js
exports.auth = (req, res) => {
  console.log(req.query)
  switch (req.query.response_type) {
    case ('code'):
      if (req.query.code_challenge && req.query.code_challenge_method) {
        handleACPKCEAuthRequest(req, res);
      } else if (!req.query.code_challenge &&
                 !req.query.code_challenge_method) {
        handleACAuthRequest(req, res);
      } else {
        res.status(400).send(JSON.stringify({
          'error': 'invalid_request',
          'error_description': 'Required parameters are missing in the request.'
        }))
      }
      break;

    case ('token'):
      handleImplicitAuthRequest(req, res);
      break;

    default:
      res.status(400).send(JSON.stringify({
        'error': 'invalid_request',
        'error_description': 'Grant type is invalid or missing.'
      }));
      break;
  }
}
#+end_src

Requests with =response_type= set to code and have parameter =code_challenge= and
=code_challenge_method= present initiate the Authorization Code (PKCE) flow and are
processed by function =handleACPKCEAuthRequest=:

#+begin_src js
function handleACPKCEAuthRequest (req, res) {
  if (req.query.client_id      === undefined ||
      req.query.redirect_url   === undefined ||
      req.query.code_challenge === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('redirect-url', '=', req.body.redirect_url)
    .filter('acpkce-enabled', '=', true)

  datastore
    .runQuery(clientQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client/redirect URL.')
      }
    })
    .then(() => {
      const html = pug.renderFile(path.join(__dirname, 'auth.pug'), {
        response_type: 'code',
        client_id: req.query.client_id,
        redirect_url: req.query.redirect_url,
        code_challenge: req.query.code_challenge
      });
      res.status(200).send(html);
    })
    .catch(msg => {
      if (msg === 'Invalid client/redirect URL.') {
        res.status(400).send(JSON.stringify({
          'error': 'access_denied',
          'error_description': msg
        }))
      } else {
        throw msg
      }
    })
}
#+end_src

This function first checks if all the required parameters (=client_id=,
=redirect_url=, =code_challenge=) are present, then makes sure that the client
ID and the redirect URL exist in the database and the client is allowed to
initiate the flow, and at last renders a page where user can sign in with their
account. The user credentials, along with other information, are POST to
=/signin=. Note that in this sample parameter =code_challenge_method=, though
required, is not used, as it is assumed that all code challenges are hashed
using SHA-256.

Requests with =response_type= set to code but do not have parameters
=code_challenge= and =code_challenge_method= initiate the Authorization Code
flow and are processed by function =handleACAuthRequest=; and requests with the
=token= response type are sent to function =handleImplicitAuthRequest=. These
two functions are largely the same as =handleACPKCEAuthRequest=:

#+begin_src js
function handleACAuthRequest (req, res) {
  if (req.query.client_id      === undefined ||
      req.query.redirect_url   === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('redirect-url', '=', req.body.redirect_url)
    .filter('ac-enabled', '=', true)

  datastore
    .runQuery(clientQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client/redirect URL.')
      }
    })
    .then(() => {
      const html = pug.renderFile(path.join(__dirname, 'auth.pug'), {
        response_type: 'code',
        client_id: req.query.client_id,
        redirect_url: req.query.redirect_url,
        code_challenge: req.query.code_challenge
      });
      res.status(200).send(html);
    })
    .catch(msg => {
      if (msg === 'Invalid client/redirect URL.') {
        res.status(400).send(JSON.stringify({
          'error': 'access_denied',
          'error_description': msg
        }))
      } else {
        throw msg
      }
    })
}
#+end_src

#+begin_src js
function handleImplicitAuthRequest (req, res) {
  if (req.query.client_id      === undefined ||
      req.query.redirect_url   === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('redirect-url', '=', req.body.redirect_url)
    .filter('implicit-enabled', '=', true)

  datastore
    .runQuery(clientQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client/redirect URL.')
      }
    })
    .then(() => {
      const html = pug.renderFile(path.join(__dirname, 'auth.pug'), {
        response_type: 'code',
        client_id: req.query.client_id,
        redirect_url: req.query.redirect_url,
        code_challenge: req.query.code_challenge
      });
      res.status(200).send(html);
    })
    .catch(msg => {
      if (msg === 'Invalid client/redirect URL.') {
        res.status(400).send(JSON.stringify({
          'error': 'access_denied',
          'error_description': msg
        }))
      } else {
        throw msg
      }
    })
}
#+end_src

**** =signin= Function
The =signin= function receives user credentials and redirects user back to the
client with an authorization code (or an access token, in the case of Implicit
flow):

#+begin_src js
exports.signin = (req, res) => {
  switch (req.body.response_type) {
    case ('code'):
      if (!req.body.code_challenge) {
        handleACSigninRequest(req, res);
      } else {
        handleACPKCESigninRequest(req, res);
      }
      break;

    case ('token'):
      handleImplictSigninRequest(req, res);
      break;

    default:
      res.status(400).send(JSON.stringify({
        'error': 'invalid_request',
        'error_description': 'Grant type is invalid or missing.'
      }));
      break;
  }
}
#+end_src

Similar to the =auth= function, =signin= uses functions
=handleACPKCESigninRequest=, =handleACSigninRequest= and
=handleImplictSigninRequest= to process requests from the Authorization Code
with PKCE flow, the Authorization Code flow and the Implicit flow respectively.

The first two functions are similar to each other; both of them issue an
authorization code after all the security checks are passed:

#+begin_src js
function handleACPKCESigninRequest (req, res) {
  if (req.body.username       === undefined ||
      req.body.password       === undefined ||
      req.body.client_id      === undefined ||
      req.body.redirect_url   === undefined ||
      req.body.code_challenge === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const userQuery = datastore
    .createQuery('user')
    .filter('username', '=', req.body.username)
    .filter('password', '=', req.body.password)

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('redirect-url', '=', req.body.redirect_url)
    .filter('acpkce-enabled', '=', true)

  datastore
    .runQuery(userQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid user credentials.')
      }
    })
    .then(() => {
      return datastore.runQuery(clientQuery)
    })
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client and/or redirect URL.')
      }
    })
    .then(() => {
      const authorizationCode = fernetToken
        .encode(JSON.stringify({
          'client_id': req.body.client_id,
          'redirect_url': req.body.redirect_url
        }))
        .toString('base64')
        .replace(/\+/g, '-')
        .replace(/\//g, '_')
        .replace(/=/g, '');

      const exp = Date.now() + CODE_LIFE_SPAN;

      const codeKey = datastore.key(['authorization_code', authorizationCode])
      const data = {
        'client_id': req.body.client_id,
        'redirect_url': req.body.redirect_url,
        'exp': exp,
        'code_challenge': req.body.code_challenge
      }

      return Promise.all([
        datastore.upsert({ key: codeKey, data: data }),
        Promise.resolve(authorizationCode)
      ])
    })
    .then(results => {
      res.redirect(appendQuery(req.body.redirect_url, {
        authorization_code: results[1]
      }))
    })
}
#+end_src

#+begin_src js
function handleACSigninRequest (req, res) {
  if (req.body.username       === undefined ||
      req.body.password       === undefined ||
      req.body.client_id      === undefined ||
      req.body.redirect_url   === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const userQuery = datastore
    .createQuery('user')
    .filter('username', '=', req.body.username)
    .filter('password', '=', req.body.password)

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('redirect-url', '=', req.body.redirect_url)
    .filter('ac-enabled', '=', true)

  datastore
    .runQuery(userQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid user credentials.')
      }
    })
    .then(() => {
      return datastore.runQuery(clientQuery)
    })
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client and/or redirect URL.')
      }
    })
    .then(() => {
      const authorizationCode = fernetToken
        .encode(JSON.stringify({
          'client_id': req.body.client_id,
          'redirect_url': req.body.redirect_url
        }))
        .toString('base64')
        .replace(/\+/g, '-')
        .replace(/\//g, '_')
        .replace(/=/g, '');

      const exp = Date.now() + CODE_LIFE_SPAN;

      const key = datastore.key(['authorization_code', authorizationCode])
      const data = {
        'client_id': req.body.client_id,
        'redirect_url': req.body.redirect_url,
        'exp': exp
      }

      return Promise.all([
        datastore.upsert({ key: key, data: data }),
        Promise.resolve(authorizationCode)
      ])
    })
    .then(results => {
      res.redirect(appendQuery(req.body.redirect_url, {
        authorization_code: results[1]
      }))
    })
}
#+end_src

Note that the generated authorization code is stored in the database with
=client_id=, =redirect_url= and =exp=; those values are used in later steps.

=handleImplictSigninRequest=, on the other hand, returns an access token if
everything looks alright:

#+begin_src js
function handleImplictSigninRequest (req, res) {
  if (req.body.username       === undefined ||
      req.body.password       === undefined ||
      req.body.client_id      === undefined ||
      req.body.redirect_url   === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const userQuery = datastore
    .createQuery('user')
    .filter('username', '=', req.body.username)
    .filter('password', '=', req.body.password)

   const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('redirect-url', '=', req.body.redirect_url)
    .filter('implicit-enabled', '=', true)

  datastore
    .runQuery(userQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid user credentials.')
      }
    })
    .then(() => {
      return datastore.runQuery(clientQuery)
    })
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client and/or redirect URL.')
      }
    })
    .then(() => {
      const token = jwt.sign({}, privateKey, {
          algorithm: 'RS256',
          expiresIn: JWT_LIFE_SPAN,
          issuer: ISSUER
        })
      res.redirect(appendQuery(req.body.redirect_url, {
        access_token: token,
        token_type: 'JWT',
        expires_in: JWT_LIFE_SPAN
      }))
    })
}
#+end_src

This sample uses the
=[[https://www.npmjs.com/package/jsonwebtoken%2529][jsonwebtoken]]= library to
prepare JWTs. The JWT is built using the RS256 algorithm, which involves a
private/public key pair. The token itself is protected by the private key; as
long as the private key is safe, no one else can issue access tokens on your
behalf. However, anyone can use the public key to decrypt the JWT and verify
its validity, without having to request your authorization server for help.

**** =token= Function
The =token= function, as its name implies, is responsible for issuing tokens:

#+begin_src js
exports.token = (req, res) => {
  switch (req.body.grant_type) {
    case 'password':
      handleROPCTokenRequest(req, res);
      break;

    case 'authorization_code':
      if (req.body.client_secret && !req.body.code_verifier) {
        handleACTokenRequest(req, res);
        break;
      }
      if (req.body.code_verifier) {
        handleACPKCETokenRequest(req, res);
        break;
      }
      res.status(400).send(JSON.stringify({
        'error': 'invalid_request',
        'error_description': 'Client secret and code verifier are exclusive' +
                             'to each other.'
      }));
      break;

    case 'client_credentials':
      handleCCTokenRequest(req, res);
      break;

    default:
      res.status(400).send(JSON.stringify({
        'error': 'invalid_request',
        'error_description': 'Grant type is invalid or missing.'
      }));
      break;
  }
};
#+end_src

Parameter =grant_type= determines how the access token is granted. Requests
with grant type =password= come from clients in the Resource Owner Password
Credentials flow and are processed by function =handleROPCTokenRequest=:

#+begin_src js
function handleROPCTokenRequest (req, res) {
  if (req.body.username      === undefined ||
      req.body.password      === undefined ||
      req.body.client_id     === undefined ||
      req.body.client_secret === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('client-secret', '=', req.body.client_secret)
    .filter('ropc-enabled', '=', true)

  const userQuery = datastore
    .createQuery('user')
    .filter('username', '=', req.body.username)
    .filter('password', '=', req.body.password)

  datastore
    .runQuery(clientQuery)
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid client credentials.');
      }
    })
    .then(() => datastore.runQuery(userQuery))
    .then(result => {
      if (result[0].length === 0) {
        return Promise.reject('Invalid user credentials.')
      }
    })
    .then(() => {
      const token = jwt.sign({}, privateKey, {
          algorithm: 'RS256',
          expiresIn: JWT_LIFE_SPAN,
          issuer: ISSUER
        })
      res.status(200).send(JSON.stringify({
          access_token: token,
          token_type: 'JWT',
          expires_in: JWT_LIFE_SPAN
        }))
    })
    .catch(msg => {
      if (msg === 'Invalid client credentials.' ||
          msg === 'Invalid user credentials.') {
        res.status(400).send(JSON.stringify({
          'error': 'access_denied',
          'error_description': msg
        }))
      } else {
        throw msg
      }
    })
}
#+end_src

Grant type =client_credentials= are reserved for clients in the Client
Credentials flow. Function =handleCCTokenRequest= handles these requests:

#+begin_src js
function handleCCTokenRequest (req, res) {
  if (req.body.client_id     === undefined ||
      req.body.client_secret === undefined) {
    return res.status(400).send(JSON.stringify({
      error: 'invalid_request',
      error_description: 'Required parameters are missing in the request.'
    }))
  }

  const clientQuery = datastore
    .createQuery('client')
    .filter('client-id', '=', req.body.client_id)
    .filter('client-secret', '=', req.body.client_secret)
    .filter('cc-enabled', '=', true)

  datastore
    .runQuery(clientQuery)
    .then(result => {
      if (result[0].length === 0) {
        return res.status(400).send(JSON.stringify({
          error: 'access_denied',
          error_description: 'Invalid client credentials.'
        }));
      } else {
        const token = jwt.sign({}, privateKey, {
          algorithm: 'RS256',
          expiresIn: JWT_LIFE_SPAN,
          issuer: ISSUER
        })
        res.status(200).send(JSON.stringify({
          access_token: token,
          token_type: 'JWT',
          expires_in: JWT_LIFE_SPAN
        }))
      }
    });
}
#+end_src

Last but not least, both Authorization Code flow and Authorization Code with
PKCE flow use the grant type =authorization_code=, with the former handled by
=handleACTokenRequest= and the latter =handleACPKCETokenRequest=:

#+begin_src js
function handleACTokenRequest (req, res) {
  if (req.body.client_id          === undefined ||
      req.body.client_secret      === undefined ||
      req.body.authorization_code === undefined ||
      req.body.redirect_url       === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  const clientQuery = datastore
      .createQuery('client')
      .filter('client-id', '=', req.body.client_id)
      .filter('client-secret', '=', req.body.client_secret)
      .filter('ac-enabled', '=', true)
  
  datastore
    .runQuery(clientQuery)
    .then(clientQueryResult => {
      if (clientQueryResult[0].length === 0) {
        return Promise.reject('Invalid client credentials.')
      }
    })
    .then(() => {
      return verifyAuthorizationCode(req.body.authorization_code, 
                                     req.body.client_id,
                                     req.body.redirect_url)
    })
    .then(() => {
      const token = jwt.sign({}, privateKey, {
          algorithm: 'RS256',
          expiresIn: JWT_LIFE_SPAN,
          issuer: ISSUER
        })
      res.status(200).send(JSON.stringify({
          access_token: token,
          token_type: 'JWT',
          expires_in: JWT_LIFE_SPAN
        }))
    })
    .catch(msg => {
      if (msg === 'Invalid client credentials.'             ||
          msg === 'Invalid authorization code.'             ||
          msg === 'Client ID does not match the record.'    ||
          msg === 'Redirect URL does not match the record.' ||
          msg === 'Authorization code expired.') {
        res.status(400).send(JSON.stringify({
          'error': 'access_denied',
          'error_description': msg
        }))
      } else {
        throw msg
      }
    })
}
#+end_src

#+begin_src js
function handleACPKCETokenRequest (req, res) {
  if (req.body.client_id          === undefined ||
      req.body.authorization_code === undefined ||
      req.body.redirect_url       === undefined ||
      req.body.code_verifier      === undefined) {
    return res.status(400).send(JSON.stringify({
      'error': 'invalid_request',
      'error_description': 'Required parameters are missing in the request.'
    }))
  }

  verifyAuthorizationCode(req.body.authorization_code,
                          req.body.client_id,
                          req.body.redirect_url, 
                          req.body.code_verifier)
    .then(() => {
      const token = jwt.sign({}, privateKey, {
          algorithm: 'RS256',
          expiresIn: JWT_LIFE_SPAN,
          issuer: ISSUER
        })
      res.status(200).send(JSON.stringify({
          access_token: token,
          token_type: 'JWT',
          expires_in: JWT_LIFE_SPAN
        }))
    })
    .catch(msg => {
      if (msg === 'Invalid authorization code.'             ||
          msg === 'Client ID does not match the record.'    ||
          msg === 'Redirect URL does not match the record.' ||
          msg === 'Authorization code expired.'             ||
          msg === 'Code verifier does not match code challenge.') {
        res.status(400).send(JSON.stringify({
          'error': 'access_denied',
          'error_description': msg
        }))
      } else if (msg === 'Code challenge does not exist.') {
        res.status(400).send(JSON.stringify({
          'error': 'invalid_request',
          'error_description': msg
        }))
      } else {
        throw msg
      }
    })
}
#+end_src

Authorization code is verified with =verifyAuthorizationCode=. Note that you do
not have to decrypt the authorization code; verifying the values of =client_id=
and =redirect_url= from the request against the values on the record should
suffice.

#+begin_src js
function verifyAuthorizationCode(authorizationCode, clientId, redirectUrl,
                                 codeVerifier = undefined) {
  const transaction = datastore.transaction();
  const key = datastore.key(['authorization_code', authorizationCode])

  return transaction
    .run()
    .then(() => transaction.get(key))
    .then(result => {
      const entry = result[0]
      if (entry === undefined ) {
        return Promise.reject('Invalid authorization code.')
      }

      if (entry.client_id !== clientId) {
        return Promise.reject('Client ID does not match the record.')
      }

      if (entry.redirect_url !== redirectUrl) {
        return Promise.reject('Redirect URL does not match the record.')
      }

      if (entry.exp <= Date.now()) {
        return Promise.reject('Authorization code expired.')
      }

      if (codeVerifier         !== undefined &&
          entry.code_challenge !== undefined) {

        let codeVerifierBuffer = new Buffer(codeVerifier);
        let codeChallenge = crypto
                              .createHash('sha256')
                              .update(codeVerifierBuffer)
                              .digest()
                              .toString('base64')
                              .replace(/\+/g, '-')
                              .replace(/\//g, '_')
                              .replace(/=/g, '');
        if (codeChallenge !== entry.code_challenge) {
          return Promise.reject('Code verifier does not match code challenge.');
        }
      } else if (codeVerifier         === undefined ||
                 entry.code_challenge === undefined) {
        // Pass
      } else {
        return Promise.reject(
          'Code challenge or code verifier does not exist.');
      }

      return transaction.delete(key)
    })
    .then(() => transaction.commit())
    .catch(msg => {
      transaction.rollback()
      throw msg
    })
}
#+end_src

*** Sidenotes
- This tutorial uses Cloud Datastore, a highly scalable NoSQL database, to
  store user credentials, client information and authorization codes. It is
  also possible to use other data storage solutions, such as memcached, Redis,
  and Cloud SQL; however, you should not store any important information
  in-memory with Cloud Functions.

- This tutorial assumes that client has registered with your service and
  provided its redirect URL. Additionally, the authorization service requires a
  full match between the redirect URL in the request and the redirect URL on
  the record. In reality, however, it is common for developers to add
  additional values in the redirect URL to keep states during transition; if
  your use case requires variable redirect URLs, you should drop the full match
  restriction.

- Access tokens in this sample only contains information regarding its issuer
  and expiration date. Depending on your use case, it might be necessary to
  pose more restrictions. Common fields to implement in the access token
  include =audience= (destinations where access token is allowed to arrive) and
  =scopes= (level of access that the token grants).

- You can also use the =jsonwebtoken= library to verify JWTs. See its
  documentation for more information.

*** Cleaning Up
After you have finished this tutorial, you can clean up the resources you
created on Google Cloud Platform so that you will not be billed for them in the
future. To clean up, you can delete the whole project or delete the Cloud
Functions you deployed.

**** Deleting the Project
Visit the [[https://console.cloud.google.com/cloud-resource-manager][Manage resources menu]]. Select the project you used for this tutorial
and click =Delete=. Note that once the project is deleted, the project ID
cannot be reused.

If you have Cloud SDK installed in the system, you can also [[https://cloud.google.com/sdk/gcloud/reference/projects/delete][use the gcloud
command-line to delete a project]].

**** Deleting the Functions
Go to the [[https://console.cloud.google.com/functions][Cloud Functions Overview]] page. Select the functions you would like to
remove and click =Delete=.

** Article---eBay REST API OAuth2-Plain English Edition
:PROPERTIES:
:url:      https://medium.com/@abeflansburg/ebay-rest-api-oauth2-plain-english-edition-1d102a9f719c
:author:   Abe Flansburg
:date:     Sep 25, 2018
:END:
eBay offers two methods for obtaining User Tokens which an app would use to
authenticate calls. Let me outline both methods and provide some basic examples
with JS — keep in mind I typically develop a separate backend with Node.JS and
my "front-end" is React, however most of the tools I use have a vanilla JS
equivalent.

*** Client credentials grant
This is, admittedly, the easiest to implement, albeit least desirable, method
as it allows access to a very limited number of scopes within the eBay
API. This is assumably because it is less secure and has fewer "legs". I won’t
go into too much detail, but with this request the =client_id= and
=client_secret= are Base64 encoded and passed in the header of a POST request,
while the request body contains the grant type of =client_credentials=, the
RuName-value (retrieved from the developer portal) and the required scope. As I
mentioned before, the available scopes are very, very limited for this type of
authentication.

*** Authorization code grant
The authorization code grant provides authentication for a much broader scope
within the eBay REST API and is 3-legged in its implementation. Here are the
steps---in (hopefully) plain English (so I can validate the title for this
publication):

1. Your app redirects the user to a page (hosted by eBay) where they login with
   their account credentials. Note: This URI also contains your =client_id= and
   the API scopes you plan to work with and is provided in the eBay dev portal
   labeled /Your branded eBay Production Sign In (OAuth)/

   #+begin_example
   https://auth.ebay.com/oauth2/authorize?
   client_id=TestAcct-0123-4567–890d-a1bcde23456&
   response_type=code&
   redirect_uri=Test_Account-TestAcct-0123-4-dxluzra&
   scope=https://api.ebay.com/oauth/api_scope%20
   https://api.ebay.com/oauth/api_scope/sell.marketing.readonly%20
   https://api.ebay.com/oauth/api_scope/sell.marketing
   #+end_example

2. eBay redirects the user back to your application to a URI you have provided
   beforehand with an authorization code appended.

   #+begin_example
   https://localhost:3000?code=<authentication code>
   #+end_example

3. Your application parses the authorization code from the URI and uses it to
   make a POST call to the eBay API for an access token. (Don’t forget to
   Base64 encode your =client_id= and =client_secret=. With Node.js, I use the
   ~btoa~ npm package along with ~qs~ to compose my request using ~fetch~.

   #+begin_src js
   fetch(‘https://api.ebay.com/identity/v1/oauth2/token', {
     method: ‘post’,
     headers: {
     ‘Content-Type’: ‘application/x-www-form-urlencoded’,
     ‘Authorization’: ‘Basic ‘ + btoa(`${clientId}:${clientSecret}`)
     },
     body: qs.stringify({
     grant_type: “authorization_code”,
     // parsed from redirect URI after returning from eBay,
     code: authCode,
     // this is set in your dev account, also called RuName
     redirect_uri: ‘Test_Account-TestAcc-0123–4-abcdefg’
     })
    })
    .then(response => response.json())
    .catch(err => console.log(err));
   #+end_src

4. eBay returns the access token which is used to make subsequent calls to the
   eBay API. A refresh token and associated expiry time (in seconds) is
   returned in this response.

   #+begin_src js
   {
       "access_token": "v^1.1#i^1#p^3#r^1...XzMjRV4xMjg0",
       "expires_in": 7200,
       "refresh_token": "v^1.1#i^1#p^3#r^1...zYjRV4xMjg0",
       "refresh_token_expires_in": 47304000,
       "token_type": "User Access Token"
    }
   #+end_src

5. Use the refresh token to refresh the access token when it expires---you know
   when to do this when your call to the API returns a status code of =401= and
   the following body:

   #+begin_src js
   {
       “errors”:[
       {
          “errorId”:1001,
          “domain”:”OAuth”,
          “category”:”REQUEST”,
          “message”:”Invalid access token”,
          “longMessage”:”Invalid access token. Check the value of the Authorization HTTP request header.”
       }
       ]
   }
   #+end_src

*** Terms to Understand:
- =client_id= ::

                 Called App ID in the "Key Sets" of the developer portal

- =client_secret= ::

     Called Cert ID in the "Key Sets" section of the dev portal

- =RuName= ::

              Redirect URL name
              : Test_Account-TestAcc-0123–4-abcdefg

- authorization code ::

     code used to request access token

- access token ::

                  token used to authenticate requests to the eBay API

- refresh token ::
                   token used to refresh the access token when it expires

** Article---The Beginner’s Guide to OAuth Dancing
:PROPERTIES:
:url:      https://medium.com/typeforms-engineering-blog/the-beginners-guide-to-oauth-dancing-4b8f3666de10
:date:     Jun 19, 2018
:author:   Anabella Spinelli
:END:
Let’s start with the basics: OAuth stands for Open Authorization. It’s a
process through which an application or website can access private data from
another website.

This other website usually works only as a trusted identity provider. It gives
the requesting app some basic information about you so that they can create a
profile. This way, you don’t have to fill in a boring sign-up form and deal
with yet another password.

You’ve already used this at least a gazillion times, in fact you use it every
time you clicked in “Log in with Facebook / Google / GitHub / etc.” You are
shown a consent screen displaying which information from your (let’s say)
Facebook profile you’re allowing that-hot-new-app.com to read (and sometimes,
write!). After that, since that-hot-new-app.com trusts the identity provided by
Facebook, they can create a profile for you on their database.

The communication between that-hot-new-app.com and Facebook usually ends
here. This is why your profile picture won’t change all across the Internet if
you change it on Facebook. They just never go back to Facebook and ask for
updated data.

*** When marimba rhythms start to play
There’s another purpose for building this kind of mechanism, one with way more
potential: using the provider as a service provider. This means communicating
with it regularly to supply enhanced features for your users. A nice example of
this is Relive, a service that connects with different sports tracking apps to
create Earth view videos of your run or ride. Every time you finish an
activity, Relive prompts you offering to create a video from it. If you say
yes, they’ll process it and notify you when it’s ready for social media
bragging… I mean sharing.

There’s really no technical difference between these two usages. That’s why you
should be cautious about where you log in with your social media or
Google/Gmail account (let’s call it YourFavoriteIdentityProvider).

But don’t be afraid, just bear in mind that you’re authorizing your account to
provide that-hot-new-app.com with that information detailed in the consent
screen, potentially in a recurrent basis. Be aware of the permissions you
grant, and make sure you know how to disable them whenever you don’t feel
trusting anymore. For instance, if you are using your Google account for
accessing that-hot-new-app.com but don’t want to allow that anymore, just go to
https://myaccount.google.com/security#connectedapps and disable their
access. All the main identity providers offer control over this.

*** All right, but how do you dance the OAuth?
Before you land on that-hot-new-app.com and even click on “Log in with
YourFavoriteIdentityProvider”, someone, probably a developer, has to create an
application on the provider’s site. This is a way of registering
that-hot-new-app.com, so that later the provider knows who’s asking for private
data.

In this step, the developer will set up some information about the application:

- the application’s name
- the application’s website and most importantly:
- a redirect URI. The provider will use this to tell the requesting app that
  the user said yes 💍the application’s name the application’s website


Once the app is registered, the provider will give that-hot-new-app.com a
clientId and a clientSecret which will be used in the communications between
them. They work sort of like a username and password for the application.

Apart from that, the developer would have to find out what kind of data does
the provider give access to, and how it’s segmented. These “segments” are known
as scopes and they define access rights, usually separated in read/write
categories. So for example, that-hot-new-app.com can request for "profile:read"
and "contacts:read" scopes. This means they can read whatever the provider
assigns to the "profile" and "contacts"” segments. Other things won’t be
visible, for instance, your posts or what content you like.

Well, just to make things simple for now on, let’s say that
that-hot-new-app.com is a website that integrates with Typeform. You definitely
want in on that, and quick, so on their website you click on “Log in with
Typeform” to get right into the action. What’s next?

Here’s a nice diagram to use as a map for the whole thing. It may look a bit
complicated but don’t worry, we’ll examine each step up next.

[[file:./resources/oauth_dance-50.png]]

*** Authorize---the first step in the OAuth dance
So, you take the initiative and click on “Connect with Typeform”. Here,
that-hot-new-app.com (THNA from now on, ’cause I’m getting tired of writing
dash-separated words) will redirect you to Typeform’s authorize endpoint
(=/oauth/authorize=) and provide:

- their clientId (remember, that’s THNA’s username)

- their desired scopes (or access rights)

- and their redirect URI again (Typeform already knows it, but we send it again
  as an extra layer of security)


That URL will look something like this:
: https://api.typeform.com/oauth/authorize?
: client_id=yourClientId&
: scope=accounts:read+forms:read+results:read

Typeform will use this information to generate a consent screen where you can
review what sort of things you’re authorizing THNA to see and do.

Once you have thoroughly read what you’re consenting to and happily click on
“Allow”, Typeform send a temporary code to the redirect URI, like so:
: https://that-hot-new-app.com/auth/redirect?code=xxxXXXxxxXXXxxx

*** Token---it takes 2 to tangOAuth
All this back and forth feels like someone’s taking you for a tango spin,
right?

The second step of the OAuth dance is when THNA receives that code, and
exchanges it for an OAuth Token.

So THNA takes that code and sends it back again to Typeform, along with the
redirect URI (yes, again!), and the client secret (that’s the app’s password!).

As reward for a dance well danced, THNA will get a shiny OAuth Token ✨ which
it can use to interact with Typeform on behalf of the user, that is… you!

*** Stay with me, sway with me
From now on, in every request THNA makes to Typeform on your behalf they’ll
have to include an Authorization header with that access token. With it,
Typeform (or any other provider) can identify:

- who’s asking for the data (in this case, THNA)

- who’s the data about (you!)

- and also make sure they have the correct authorization to access that data
  (only what you consented to).

*** Ready for the dance floor
So now that you know all the steps and spins of the OAuth dancing technique you
should be ready to create your own choreographies, I mean, integrations, and
make the Internet an even greater place.

If you have an idea to integrate with Typeform but you don’t really know where
to start, make sure you don’t miss our upcoming tutorial for setting up a
Node.js app using Typeform’s PassportJS strategy for authentication (or grab a
free Node.js Typeform integration boilerplate [[https://github.com/anabellaspinelli/typeform-oauth-boilerplate][here]]!)

* OpenID Connect
- https://openid.net/connect/
- [[http://tools.ietf.org/html/rfc6749][RFC 6749]]
- [[https://openid.net/specs/openid-connect-core-1_0.html#CodeFlowAuth][OpenID Connect Core 1.0]]


{{{heading(From the OIDC 1.0 Core Spec Abstract)}}}

#+cindex:OpenID Connect 1.0
#+cindex:OIDC spec
OpenID Connect 1.0 is a simple identity layer on top of the OAuth 2.0 protocol.
It enables Clients to verify the identity of the End-User based on the
authentication performed by an Authorization Server, as well as to obtain basic
profile information about the End-User in an interoperable and REST-like
manner.

This specification defines the core OpenID Connect functionality:
authentication built on top of OAuth 2.0 and the use of Claims to communicate
information about the End-User.  It also describes the security and privacy
considerations for using OpenID Connect.

** Identity & Authentication + OAuth 2.0 = OpenID Connect

OpenID Connect 1.0 is a simple identity layer on top of the OAuth 2.0
protocol. It allows Clients to verify the identity of the End-User based on the
authentication performed by an Authorization Server, as well as to obtain basic
profile information about the End-User in an interoperable and REST-like
manner.  OpenID Connect allows clients of all types, including Web-based,
mobile, and JavaScript clients, to request and receive information about
authenticated sessions and end-users.

OpenID Connect is an interoperable authentication protocol based on the OAuth
2.0 family of specifications. It uses straightforward REST/JSON message flows
with a design goal of "making simple things simple and complicated things
possible". It’s uniquely easy for developers to integrate, compared to any
preceding Identity protocol.

OpenID Connect lets developers authenticate their users across websites and
apps without having to own and manage password files. For the app builder, it
provides a secure verifiable, answer to the question: "What is the identity of
the person currently using the browser or native app that is connected to me?"

OpenID Connect allows for clients of all types, including browser-based
JavaScript and native mobile apps, to launch sign-in flows and receive
verifiable assertions about the identity of signed-in users.

{{{heading(What problem does OpenID Connect solve?)}}}

It lets app and site developers authenticate users without taking on the
responsibility of storing and managing passwords in the face of an Internet
that is well-populated with people trying to compromise your users’ accounts
for their own gain.

{{{heading(What does authentication mean?)}}}

The process of establishing and communicating that the person operating a
browser or native app is who they claim to be.

{{{heading(Are there live production deployments of OpenID Connect?)}}}

Yes. Some examples include Google, Gakunin (Japanese Universities Network),
Microsoft, Ping Identity, Nikkei Newspaper, Tokyu Corporation, mixi, Yahoo!
Japan and Softbank. There are also mature deployments underway by Working Group
participant organizations, such as Deutsche Telecom, AOL, and Salesforce.

For an example of OpenID Connect at work, look at [[https://developers.google.com/+/features/sign-in][Google+ Sign-In]], Google’s
flagship social-identity offering, which is entirely based on OpenID Connect.

[[https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_create_oidc.html][Creating OpenID Connect (OIDC) Identity Providers]]

[[https://aws.amazon.com/cognito/][Amazon Cognito]] Let Amazon Cognito handle authentication

[[https://aws.amazon.com/blogs/security/introducing-aws-single-sign-on/][Introducing AWS Single Sign-On]]

[[https://aws.amazon.com/blogs/security/building-an-app-using-amazon-cognito-and-an-openid-connect-identity-provider/][Building an App Using Amazon Cognito and an OpenID Connect Identity Provider]]
AWS now supports OpenID Connect (OIDC)

[[https://aws.amazon.com/blogs/aws/openid-connect-support/][OpenID Connect Support for Amazon Cognito]] Cognito takes the ID token that you
obtain from the OIDC identity provider and uses it to manufacture unique
Cognito IDs for each person who uses your app.

** Article---OpenID Connect Authorization Code Flow with AWS Cognito
:PROPERTIES:
:url:      https://medium.com/@robert.broeckelmann/openid-connect-authorization-code-flow-with-aws-cognito-246997abd11a
:author:   Robert Broeckelmann
:date:     Oct 26, 2018
:END:
AWS Cognito is a relatively new player in the identity space. It doesn’t
support the full OAuth2 or OpenID Connect specs, but, does support most of what
I would generally consider the important parts. This post will be the first in
a series about AWS services in the Identity and API Management spaces and how
they can be used together in common patterns that we’ve explored with other
technology stacks. In this post, we’ll do an AWS Cognito configuration overview
for an OpenID Connect application.
*** Overview
*** Assumptions
*** Cognito Setup
*** Create Application Definition
*** Important URLs for User Pool
*** Test With The OIDC + OAuth2 Debugger
*** See The User In Cognito
*** User Authentication
*** Summary
In this post, we looked at the AWS Cognito setup for an OpenID Connect client
application and demonstrated it working with OAuth2 + OIDC Debugger.

In subsequent posts, we’ll look at:

- AWS Cognito out-of-the-box native user registration and login.
- Demonstrate federated user registration and login with social login providers
  (Facebook, Google+), SAML2, and OpenID Connect.
- How to use access tokens issued from AWS Cognito with the AWS API Gateway.

** Article---An OpenID Connect Primer in Three Parts
:PROPERTIES:
:author:   Micah Silverman
:date:     2017-07-25
:END:

All the code used in this series can be found on:
- [[https://github.com/oktadeveloper/okta-oidc-flows-example][on github here]]


You can use the OIDC sample app to exercise the various flows and scopes
discussed throughout these posts.  It’s at:
-  https://okta-oidc-fun.herokuapp.com/


The entire final OIDC spec can be found:
- [[http://openid.net/specs/openid-connect-core-1_0.html][OIDC Spec]]


And you can learn more about OAuth 2.0 at:
- [[https://www.oauth.com/][oauth.com]]

*** Part 1---Identity-Claims-Tokens---Basics and History
- https://developer.okta.com/blog/2017/07/25/oidc-primer-part-1


You can see the various concepts and OIDC interactions covered at:
- https://okta-oidc-fun.herokuapp.com


The code that backs this is at:
- https://github.com/oktadeveloper/okta-oidc-flows-example


{{{heading(Introduction to OIDC)}}

This blog series presents a primer on OIDC.  First, it will review some key
concepts around OIDC and tokens.  Then, it will look at OIDC in action with
some specific code examples to highlight its value in the authentication and
authorization ecosystem.  Finally, it will dig into the guts of the different
token types and how to control what goes into them.

#+cindex:secure delegated access
#+cindex:authentication
#+cindex:authorization
What was wrong with OAuth 2.0?  To understand better, let’s first dispense with
the term, secure delegated access.  It’s too vague and has led to confusion
between authentication (authn) and authorization (authz).

Without secure, external authentication and authorization, you’d have to trust
that every application, and every developer not only had your best interests
and privacy in mind, but also knew how to protect your identity and was willing
to keep up with security best practices.  That’s a pretty tall order, right?
With OIDC, you can use a trusted external provider to prove to a given
application that you are who you say you are, without ever having to grant that
application access to your credentials.

OAuth 2.0 leaves a lot of details up to implementers.  For instance, it
supports scopes, but scope names are not specified.  It supports access tokens,
but the format of those tokens are not specified.  With OIDC, a number of
specific scope names are defined that each produce different results.  OIDC has
both access tokens and ID tokens.  An ID token must be JSON web token (JWT).
Since the specification dictates the token format, it makes it easier to work
with tokens across implementations.

**** Key Concepts---Scopes-Claims-Response Types

#+cindex:SAML
#+cindex:OAuth2
#+cindex:OIDC
- Security Assertion Markup Language (SAML) :: Original message exchange type

- OAuth2 :: Open, modern, RESTful approach to authorization using JSON

- Open ID Connect (OIDC) :: Secure, delegated access running on top of OAuth2

- Secure delegated access :: With OIDC, you can use a trusted external provider
     to prove to a given application that you are who you say you are, without
     ever having to grant that application access to your credentials.


Before we dive into the minutiae of OIDC, let’s take a step back and talk about
how we interact with it.

{{{heading(Primary Actors)}}}

There are two primary actors involved in all OIDC interactions:

#+cindex:OpenID Provider
#+cindex:OAuth2 server
#+cindex:authenticating end-user
#+cindex:Relying Party
#+cindex:OAuth2 application
#+cindex:authentication requests
1.  the OpenID Provider (OP)

   The OP is an /OAuth 2.0 server/ that is capable of authenticating the
   end-user and providing information about the result of the authentication
   and the end-user to the Relying Party.

2. the Relying Party (RP)

   The Relying Party is an /OAuth 2.0 application/ that “relies” on the OP to
   handle authentication requests.


{{{heading(Starting an OIDC Interaction)}}}

{{{subheading(Authorization Endpoint)}}}

#+cindex:authorization endpoint
Typically, you kick off an OIDC interaction by hitting an ~/authorization~
endpoint with an =HTTP GET=.  A number of query parameters indicate what you
can expect to get back after authenticating and what you’ll have access to
(authorization).

{{{subheading(Token Endpoint)}}}

#+cindex:token endpoint
#+cindex:tokens
Often, you’ll need to hit a ~/token~ endpoint with an =HTTP POST= to get tokens
which are used for further interactions.

{{{subheading(Introspect Endpoint)}}}

#+cindex:introspect endpoint
#+cindex:verify token
#+cindex:userinfo endpint
OIDC also has an ~/introspect~ endpoint for verifying a token, and a ~/userinfo~
endpoint for getting identity information about the user.

{{{heading(OIDC Metadata Mechanism)}}}

#+cindex:metqdata mechanism, OIDC
All of the above endpoints are the convention, but can be defined by the OP to
be anything.  One of the great improvements in OIDC is a metadata mechanism to
discover endpoints from the provider.  For instance, if you navigate to:

- https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/.well-known/openid-configuration

{{{noindent}}}you’ll get back a JSON formatted document with the metadata that
identifies all the available endpoints from the OP (Okta, in this case).

#+caption:Example JSON Metadata
#+name:example-metadata
#+begin_src js
  {
      "issuer":"https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7",
      "authorization_endpoint":"https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/authorize",
      "token_endpoint":"https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/token",
      "userinfo_endpoint":"https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/userinfo",
      "registration_endpoint":"https://micah.okta.com/oauth2/v1/clients",
      "jwks_uri":"https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/keys",
      "response_types_supported":["code",
                                  "id_token",
                                  "code id_token",
                                  "code token",
                                  "id_token token",
                                  "code id_token token"],
      "response_modes_supported":["query",
                                  "fragment",
                                  "form_post",
                                  "okta_post_message"],
      "grant_types_supported":["authorization_code",
                               "implicit",
                               "refresh_token",
                               "password"],
      "subject_types_supported":["public"],
      "id_token_signing_alg_values_supported":["RS256"],
      "scopes_supported":["openid",
                          "profile",
                          "email",
                          "address",
                          "phone",
                          "offline_access"],
      "token_endpoint_auth_methods_supported":["client_secret_basic",
                                               "client_secret_post",
                                               "client_secret_jwt",
                                               "private_key_jwt",
                                               "none"],
      "claims_supported":["iss",
                          "ver",
                          "sub",
                          "aud",
                          "iat",
                          "exp",
                          "jti",
                          "auth_time",
                          "amr",
                          "idp",
                          "nonce",
                          "name",
                          "nickname",
                          "preferred_username",
                          "given_name",
                          "middle_name",
                          "family_name",
                          "email",
                          "email_verified",
                          "profile",
                          "zoneinfo",
                          "locale",
                          "address",
                          "phone_number",
                          "picture",
                          "website",
                          "gender",
                          "birthdate",
                          "updated_at",
                          "at_hash",
                          "c_hash"],
      "code_challenge_methods_supported":["S256"],
      "introspection_endpoint":"https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/introspect",
      "introspection_endpoint_auth_methods_supported":["client_secret_basic",
                                                       "client_secret_post",
                                                       "client_secret_jwt",
                                                       "private_key_jwt",
                                                       "none"],
      "revocation_endpoint":"https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/revoke",
      "revocation_endpoint_auth_methods_supported":["client_secret_basic",
                                                    "client_secret_post",
                                                    "client_secret_jwt",
                                                    "private_key_jwt",
                                                    "none"],
      "end_session_endpoint":"https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/logout",
      "request_parameter_supported":true,
      "request_object_signing_alg_values_supported":["HS256",
                                                     "HS384",
                                                     "HS512",
                                                     "RS256",
                                                     "RS384",
                                                     "RS512",
                                                     "ES256",
                                                     "ES384",
                                                     "ES512"]
  }
#+end_src

***** What's a Scope
#+cindex:scope
/Scopes/ are space-separated lists of identifiers used to specify what access
privileges are being requested.  Valid scope identifiers are specified in
[[https://tools.ietf.org/html/rfc6749][RFC 6749]].

#+cindex:scope identifiers
#+cindex:@code{openid}
#+cindex:scopes
#+cindex:custom scopes
#+cindex:built-in scopes
OIDC has a number of built-in scope identifiers.  =openid= is a required scope.
All others---including custom scopes---are optional.  The built-in scopes are:

| scope   | purpose                                                          |
|---------+------------------------------------------------------------------|
| profile | requests access to default profile claims                        |
| email   | requests access to email and email_verified claims               |
| address | requests access to address claim                                 |
| phone   | requests access to phone_number and phone_number_verified claims |
|---------+------------------------------------------------------------------|

#+cindex:profile claims
#+cindex:claims, profile
The default profile claims are:

- name
- family_name
- given_name
- middle_name
- nickname
- preferred_username
- profile
- picture
- website
- gender
- birthdate
- zoneinfo
- locale
- updated_at


Notice how the scopes are tied to claims.

***** What's a Claim
#+cindex:claims
/Claims/ are name/value pairs that contain information about a user, as well
meta-information about the OIDC service.  The official definition from the spec
is a /“piece of information asserted about an Entity.”/

Here’s typical set of claims:

#+caption:Typical Set of Claims
#+name:typical-claims
#+begin_src js
  {
      "family_name": "Silverman",
      "given_name": "Micah",
      "locale": "en-US",
      "name": "Micah Silverman",
      "preferred_username": "micah.silverman@okta.com",
      "sub": "00u9vme99nxudvxZA0h7",
      "updated_at": 1490198843,
      "zoneinfo": "America/Los_Angeles"
  }
#+end_src

#+cindex:token
#+cindex:profile scope
A number of the profile claims are included above.  That’s because the request
for the user’s info was made using a /token/ that was obtained with the profile
scope.  In other words, a request is made that results in the issuance of a
token.  That token contains certain information based on the scopes specified
in the original request.

***** What's a Response Type
#+cindex:flows
#+cindex:response type
When working with OIDC, you’ll hear talk of various “flows”.  These flows are
used to describe different common authentication and authorization scenarios.
Considerations include the type of application (like web-based or native mobile
app), how you want to validate tokens (in the app or in the backend), and how
you want to access additional identity information (make another API call or
have it encoded right into a token).

{{{heading(Primary Flows)}}}

#+cindex:@code{response_type}
#+cindex:authorization request
There are three primary flows; these flows are controlled by the
=response_type= query parameter in the ~/authorization~ request.

1. Authorization Code

2. Implicit

3. Hybrid


{{{subheading(Front Channel vs Back Channel)}}}

#+cindex:front-channel
#+cindex:back-channel
When thinking of which flow to use, consider front-channel vs. back-channel
requirements.  Front-channel refers to a user-agent (such as a SPA or mobile
app) interacting directly with the OpenID provider (OP).  The implicit flow is
a good choice when front-channel communication is required.  Back-channel
refers to a middle-tier client (such as Spring Boot or Express) interacting
with the OP.  The authorization code flow is a good choice when back-channel
communication is required.

****** Authorization Code Flow

#+cindex:authorization code flow
#+cindex:client id
#+cindex:client secret
#+cindex:tokens
#+cindex:access_token
#+cindex:id_token
#+cindex:refresh token
*Authorization Code* flow uses response_type=code.  After successful
authentication, the response will contain a code value.  This code can later be
exchanged for an =access_token= and an =id_token=.  (Hang in for now, we’ll
talk about tokens in more depth later on.) This flow is useful where you have
“middleware” as part of the architecture.  The middleware has a /client id/ and
/client secret/, which is required to exchange the code for tokens by hitting
the ~/token~ endpoint.  These tokens can then be returned to the end-user
application, such as a browser, without the browser ever having to know the
client secret.  This flow allows for long-lived sessions through the use of
refresh tokens.  The only purpose of refresh tokens is to obtain new access
tokens to extend a user session.

****** Implicit Flow
#+cindex:implicit flow
*Implicit* flow uses response_type=id_token token or response_type=id_token.
After successful authentication, the response will contain an =id_token= and an
=access_token= in the first case or just an =id_token= in the second case.
This flow is useful when you have an app speaking directly to a backend to
obtain tokens with no middleware.  It does not support long-lived sessions.

****** Hybrid Flow
#+cindex:hybrid flow
*Hybrid* flow combines the above two in different combinations---whatever make
sense for the use case.  An example would be response_type=code id_token. This
approach enables a scenario whereby you can have a long lived session in an app
and get tokens back immediately from the ~/authorization~ endpoint.

**** All About Tokens
#+cindex:tokens
#+cindex:@code{id_token}
#+cindex:@code{access_token}
#+cindex:@code{refresh_token}
With the foundation of scopes, claims, and response types, we can now talk
about tokens! There are three types of tokens in OIDC:

1. id_token

2. access_token

3. refresh_token

***** ID Tokens

#+cindex:@code{id_token}
#+cindex:JWT
An =id_token= is a JWT, per the OIDC Specification.  This means that:

- identity information about the user is encoded right into the token and

- the token can be definitively verified to prove that it hasn’t been tampered
  with.


There’s a set of rules in the specification for validating an =id_token=.
Among the claims encoded in the =id_token= is an expiration (=exp=), which must
be honored as part of the validation process.  Additionally, the signature
section of JWT is used in concert with a key to validate that the entire JWT
has not been tampered with in any way.

{{{heading(A Brief History of JWTs)}}}

#+cindex:opaque tokens
In the beginning tokens were opaque---they carried no intrinsic information.
This was fine as the server knew the token and could look up any data related
to it, such as identity information.

#+cindex:token types
#+cindex:access tokens
#+cindex:refresh tokens
When the OAuth 2.0 spec was released in 2012, it defined token types (such as
access and refresh tokens), but it purposely avoided dictating the format of
these tokens.

#+cindex:JWT spec
#+cindex:claims
#+cindex:JWS
#+cindex:JWE
In 2015, the JWT spec was released.  It proposed the creation of tokens which
encoded other information.  This token could be used as an opaque identifier
and could also be inspected for additional information---such as identity
attributes.  It called these attributes /claims/.  The spec also includes
provisions for cryptographically signed JWTs (called JWSs) and encrypted JWTs
(called JWEs).  A signed JWT is particularly useful in application development
because you can have a high degree of confidence that the information encoded
into the JWT has not been tampered with.  By verifying the JWT within the
application, you can avoid another round trip to an API service.  It also
allows to enforce behavior, like expiration, because you know the exp claim has
not been altered.

There’s no direct relationship between JWT and OAuth 2.0.  However, many OAuth
2.0 implementers saw the benefits of JWTs and began using them as either (or
both) access and refresh tokens.

#+cindex:id_tokens
#+cindex:JWT
OIDC formalizes the role of JWT in mandating that ID Tokens be JWTs.  Many OIDC
implementers will also use JWTs for access and refresh tokens, but it is not
dictated by the spec.

***** Access Tokens
#+cindex:access tokens
#+cindex:bearer tokens
Access tokens are used as /bearer tokens/.

- Bearer Token :: the bearer can access authorized resources without further
                  identification.  Because of this, it’s important that bearer
                  tokens are protected.  If I can somehow get ahold of and
                  “bear” your access token, I can masquerade as you.  These
                  tokens usually have a short lifespan (dictated by its
                  expiration) for improved security.  That is, when the access
                  token expires, the user must authenticate again to get a new
                  access token limiting the exposure of the fact that it’s a
                  bearer token.


Although not mandated by the OIDC spec, Okta uses JWTs for access tokens as
(among other things) the expiration is built right into the token.

{{{heading(Userinfo Endpoint)}}}

OIDC specifies a ~/userinfo~ endpoint that returns identity information and
must be protected.  Presenting the access token makes the endpoint accessible.

#+begin_example
https://micah.oktapreview.com/oauth2/.../v1/userinfo \
Authorization:"Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6Ik93bFNJS3p3Mmt1Wk8zSmpnMW5Dc2RNelJhOEV1elY5emgyREl6X3RVRUkifQ..."

HTTP/1.1 200 OK
...

{
    "family_name": "Silverman",
    "given_name": "Micah",
    "groups": [
        "ABC123",
        "Everyone"
    ],
    "locale": "en-US",
    "name": "Micah Silverman",
    "preferred_username": "micah+okta@afitnerd.com",
    "sub": "...",
    "updated_at": 1490198843,
    "zoneinfo": "America/Los_Angeles"
}

http https://micah.oktapreview.com/oauth2/.../v1/userinfo
HTTP/1.1 400 Bad Request
WWW-Authenticate: Bearer error="invalid_request", error_description="The access token is missing."
...

https://micah.oktapreview.com/oauth2/.../v1/userinfo \
Authorization:"Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6Ik93bFNJS3p3Mmt1Wk8zSmpnMW5Dc2RNelJhOEV1elY5emgyREl6X3RVRUkifQ..."
HTTP/1.1 401 Unauthorized
WWW-Authenticate: Bearer error="invalid_token", error_description="The token has expired."
...
#+end_example

***** Refresh Tokens
#+cindex:refresh tokens
Refresh tokens are used to obtain new access tokens.  Typically, refresh tokens
will be long-lived while access tokens are short-lived.  This allows for
long-lived sessions that can be killed if necessary.

{{{heading(Typical Scenario)}}}

1. User logs in and gets back an access token and a refresh token

2. The application detects that the access token is expired

3. The application uses the refresh token to obtain a new access token

4. Repeat 2 and 3 until the refresh token expires

5. After the refresh token expires, the user must authenticate again


This approach strikes a balance between user experience and security.  Imagine
if the user is compromised in some way.  Or, their subscription expires.  Or,
they are fired.  At any point, the refresh token can be revoked by an admin.
Then, step three above will fail and the user will be forced to (attempt to)
establish a new session by authenticating.  If their account has been
suspended, they will not be able to authenticate.

***** Identifying Token Types
It can be confusing sometimes to distinguish between the different token
types. Here’s a quick reference:

#+cindex:ID tokens
1. ID tokens carry identity information encoded in the token itself, which must
   be a JWT

   #+cindex:access tokens
2. Access tokens are used to gain access to resources by using them as bearer
   tokens

   #+cindex:refresh tokens
3. Refresh tokens exist solely to get more access tokens

*** Part 2---OIDC In Action---The Mechanics
- https://developer.okta.com/blog/2017/07/25/oidc-primer-part-2

- [[https://okta-oidc-fun.herokuapp.com/][OIDC flow test site]]


In this post, we’ll dive into the mechanics of OIDC and see the various flows
in action.  The token(s) you get back from an OIDC flow and the contents of the
~/userinfo~ endpoint are a function of the flow type and scopes requested.  You
can see this live on the OIDC flow test site (see link above).  Here, you can
set different toggles for =scope= and =response_type=, which determines the
type of flow for your app.

Your use case will determine which flow to use. Are you building a SPA or
mobile app that needs to interact directly with the OpenID Provider (OP)?  Do
you have middleware, such as Spring Boot or Node.js Express that will interact
with the OP?  Below, we dig into some of the available flows and when it’s
appropriate to use them.

**** Authorization Code Flow
#+cindex:authorization code flow
#+cindex:flow, authorization code
The Authorization Code flow is covered in [[http://openid.net/specs/openid-connect-core-1_0.html#CodeFlowAuth][Section 3.1 of the OIDC spec]].

#+cindex:authorization endpoint
#+cindex:token endpoint
In short, a code is returned from the ~/authorization~ endpoint which can be
exchanged for ID and access tokens using the ~/token~ endpoint.  This is a
suitable approach when you have a middleware client connected to an OIDC OP and
don’t (necessarily) want tokens to ever come back to an end-user application,
such as a browser.  It also means the end-user application never needs to know
a secret key.

Here’s an example of how this flow gets started using Okta:

: https://okta-oidc-fun.herokuapp.com/continue?code=X7u1GvtPBgZ8ASkMa7zz&state=abrasive-yard-unarmed-fall

#+begin_example
https://micah.okta.com				# OKTA Tenant
  /oauth2/aus2yrcz7aMrmDAKZ1t7/v1/authorize?	# Authorization URL
  client_id=0oa2yrbf35Vcbom491t7&		# Client ID of OIDC application
  response_type=code&				# Code Flow
  scope=openid&					# openid scope requested
  state=little-room-greasy-pie&			# Random value; returned at end of flow
  nonce=b1e7b75d-6248-4fc7-bad0-ac5ae0f2e581&	# Random value; encoded into id_token
  redirect_uri=https%3A%2F%2Fokta-oidc-fun.herokuapp.com%2Fflow_result
#+end_example

#+cindex:authorization code
#+cindex:state string
After clicking =continue=, the server will redirect you to the =redirect_uri=
site and will provide you with an /authorization code/ and the =state= string,
which must be the same one you sent to it.

#+cindex:session
Behind the scenes, a session is established with a fixed =username= and
=password=.  If you deploy this app on your own (which you can easily do from
[[https://github.com/oktadeveloper/okta-oidc-flows-example#okta-openid-connect-fun][here]]), when you click the link you would be redirected to login and then
redirected back to this same page.

#+cindex:authorization code, exchange
#+cindex:@code{id_token}
#+cindex:@code{access_token}
#+cindex:tokens
The authorization code received on the redirect can now be exchanged for an
=id_token= and an =access_token= by the middle tier---a Spring Boot
application, in this case.  This middle tier will validate the state we sent in
the authorize request earlier and make a ~/token~ request using the Client
Secret to mint an =access_token= and =id_token= for the user.

**** Implicit Flow
The Implicit flow is covered in [[http://openid.net/specs/openid-connect-core-1_0.html#ImplicitFlowAuth][Section 3.2 of the OIDC spec]].

Essentially, access and ID tokens are returned directly from the
~/authorization~ endpoint.  The ~/token~ endpoint is not used.  This is a
suitable approach when working with a client (such as a Single Page Application
or mobile application) that you want to interact with the OIDC OP directly.

Here’s an example of how this flow gets started using Okta:

#+begin_example
  https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/authorize?
    client_id=0oa2yrbf35Vcbom491t7&
    response_type=id_token+token&
    scope=openid&
    state=shrill-word-accessible-iron&
    nonce=f8c658f0-1eb9-4f8d-8692-5da4e2f24cf0&
    redirect_uri=https%3A%2F%2Fokta-oidc-fun.herokuapp.com%2Fflow_result
#+end_example

#+cindex:@code{id_token}
#+cindex:@code{token}
#+cindex:@code{id_token+token}
#+cindex:response_type, implicit flow
#+cindex:identity information
#+cindex:bearer token
#+cindex:JWT, access token
It’s almost identical to the authorization code flow, except that the
=response_type= is either =id_token=, =token= or =id_token+token=.  An
=id_token= encodes /identity information/ and an =access_token (returned if
=token= is specified) is a /bearer token/ used to access resources.  Okta also
uses JWT for an =access_token=, which enables additional information to be
encoded into it.

Upon redirect to the =redirect_url=, the application can verify the =id_token=
locally.  Use the ~/introspect~ endpoint to verify the =access_token=.  It can
also use the =access=_token= as a/ bearer token/ to hit protected resources,
such as the ~/userinfo~ endpoint.

**** Hybrid Flow
#+cindex:hybrid flow
#+cindex:flow, hybrid
The Hybrid flow is covered in [[http://openid.net/specs/openid-connect-core-1_0.html#HybridFlowAuth][Section 3.3 of the OIDC spec]].

In this flow, some tokens are returned from the authorization endpoint
(~/authorize~) and others are returned from the token endpoint (~/token~).
This is a suitable approach when you want your end-user application to have
immediate access to short-lived tokens---such as the =id_token= for identity
information, and also want to use a backend service to exchange the
authorization code for longer-lived tokens using refresh tokens.  It’s a
combination of the authorization code and implicit code flows.  You can spot it
by looking at the =response_type=: it must contain =code= and one or both of
=id_token= and =token=:

#+begin_example
  https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/authorize?
    client_id=0oa2yrbf35Vcbom491t7&
    response_type=code+id_token+token&
    scope=openid&
    state=shrill-word-accessible-iron&
    nonce=f8c658f0-1eb9-4f8d-8692-5da4e2f24cf0&
    redirect_uri=https%3A%2F%2Fokta-oidc-fun.herokuapp.com%2Fflow_result
#+end_example

You are redirected back to the =redirect_uri= originally specified (with the
returned code, tokens and original state).

Here’s the response from the ~/userinfo~ endpoint using the =access_token= as a
bearer token:

#+begin_src js
  {
          "sub": "00u2yulup4eWbOttd1t7",
          "name": "Okta OIDC Fun",
          "locale": "en-US",
          "email": "okta_oidc_fun@okta.com",
          "preferred_username": "okta_oidc_fun@okta.com",
          "given_name": "Okta OIDC",
          "family_name": "Fun",
          "zoneinfo": "America/Los_Angeles",
          "updated_at": 1499922371,
          "email_verified": true
  }
#+end_src

**** Other OIDC Flows

#+cindex:Client Credentials flow
#+cindex:Resource Owner Password Credentials flow
There are two other flows:

- [[https://tools.ietf.org/html/rfc6749#section-4.4][Client Credentials Flow]]

- [[https://tools.ietf.org/html/rfc6749#section-4.3][Resource Owner Password Credentials]]


These flows do not require an external authentication provider.

*** Part 3---What's In A Token
- https://developer.okta.com/blog/2017/08/01/oidc-primer-part-3


In this third and final installment, we’ll look at what’s encoded into the
various types of tokens and how to control what gets put in them.

JWTs have the benefit of being able to carry information in them.  With this
information available to your app you can

- easily enforce token expiration and

- reduce the number of API calls.

- Additionally, since they’re cryptographically signed, you can verify that
  they have not been tampered with.


The source code that backs the site can be found at:
- https://github.com/oktadeveloper/okta-oidc-flows-example


{{{heading(OIDC Spec and Identity)}}}

#+cindex:identity
#+cindex:@code{id_token}
#+cindex:@code{/userinfo} endpoint
#+cindex:@code{access} token
There are two primary sources for information relating to identity as dictated
by the OIDC spec.  OKTA adds a third.

1. One source is the information encoded into the =id_token= JWT.

2. Another is the response from the ~/userinfo~ endpoint, accessible using an
   =access_token= as a =bearer= token.

3. At Okta, we’ve chosen to make our =access= tokens JWTs as well, which
   provides a third source of information.


{{{heading(Query Parameter Combinations)}}}

#+cindex:query parameters
#+cindex:authorization request
#+cindex:@code{id_token}
#+cindex:@code{/userinfo} endpoint
#+cindex:@code{response_type}
#+cindex:@code{scope}
There are a lot of combinations of query parameters in the ~/authorization~
request that determine what information will be encoded into an =id_token=.
The two query parameters that impact what will ultimately be found in returned
tokens and the ~/userinfo~ endpoint are:

- =response_type= and
- =scope=


**** OIDC Response Types
#+cindex:response types
In the following examples, we use only the scopes =openid= (required) and
=email=.  We’ll also work with the /implicit flow/, since that gives us back
tokens immediately.

{{{heading(Response Type of Token)}}}

Sending a =response_type= of 'token' will yield an =access_token= from the
response.  A particular format is not required in the OIDC spec for access
tokens, but at Okta we use JWTs.

So, given this request:

#+begin_example
  https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/authorize?
    client_id=0oa2yrbf35Vcbom491t7&
    response_type=token&
    scope=openid+email&
    state=aboard-insect-fresh-smile&
    nonce=c96fa468-ca1b-46f0-8974-546f23f9ee6f&
    redirect_uri=https%3A%2F%2Fokta-oidc-fun.herokuapp.com%2Fflow_result
#+end_example

{{{noindent}}}you will get the following =access_token= back:

#+begin_src js
  {
          "active": true,
          "scope": "openid email",
          "username": "okta_oidc_fun@okta.com",
          "exp": 1501531801,
          "iat": 1501528201,
          "sub": "okta_oidc_fun@okta.com",
          "aud": "test",
          "iss": "https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7",
          "jti": "AT.upPJqU-Ism6Fwt5Fpl8AhNAdoUeuMsEgJ_VxJ3WJ1hk",
          "token_type": "Bearer",
          "client_id": "0oa2yrbf35Vcbom491t7",
          "uid": "00u2yulup4eWbOttd1t7"
  }
#+end_src

#+cindex:resource information
This is mainly /resource/ information, including an expiration (=exp=) and a
user id (=uid=).

#+cindex:identity information
#+cindex:@code{/userinfo} endpoint
#+cindex:@code{access_token}, bearer token
If we want to get /identity/ information for the user, we must hit the
/userinfo endpoint using the =access_token= as a =bearer= token.  Here’s what
that looks like using HTTPS:

#+begin_example
  http https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/userinfo \
    Authorization:"Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6Ik93bFNJS3p3Mmt1Wk8zSmpnMW5Dc2RNelJhOEV1elY5emgyREl6X3RVRUkifQ..."

  HTTP/1.1 200 OK
  ...
  {
          "sub": "00u2yulup4eWbOttd1t7",
          "email": "okta_oidc_fun@okta.com",
          "email_verified": true
  }
#+end_example

We get back the =sub=, =email= and =email_verified= claims.  This is because of
the default =scope= = =openid+email= from the original request.

{{{heading(Response Type of ID Token)}}}

#+cindex:@code{response_type} of 'id_token'
Here is another request with =response_type= of 'id_token':

#+begin_example
  https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/authorize?
    client_id=0oa2yrbf35Vcbom491t7&
    response_type=id_token&
    scope=openid+email&
    state=aboard-insect-fresh-smile&
    nonce=c96fa468-ca1b-46f0-8974-546f23f9ee6f&
    redirect_uri=https%3A%2F%2Fokta-oidc-fun.herokuapp.com%2Fflow_result
#+end_example

The response is a JWT (as required by the OIDC spec) with this information
encoded into it:

#+begin_src js
  {
          "sub": "00u2yulup4eWbOttd1t7",
          "email": "okta_oidc_fun@okta.com",
          "ver": 1,
          "iss": "https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7",
          "aud": "0oa2yrbf35Vcbom491t7",
          "iat": 1501528456,
          "exp": 1501532056,
          "jti": "ID.4Mmzy2kj5_B8nGZ_PT4dt8-fzu1tA2W3C5dbEF-N6Us",
          "amr": [
                  "pwd"
          ],
          "idp": "00o1zyyqo9bpRehCw1t7",
          "nonce": "c96fa468-ca1b-46f0-8974-546f23f9ee6f",
          "email_verified": true,
          "auth_time": 1501528157
  }
#+end_src

#+cindex:identity information
Notice that we have the =sub= and =emailclaims= encoded directly in the JWT.
In this type of /implicit/ flow, we have no =bearer= token to use against the
~/userinfo~ endpoint, so the /identity/ information is baked right into the
JWT.

{{{heading(Response Types of Both ID Token and Access Token)}}}

Here, we are requesting both an =id_token= and an =access_token= in the
response.

#+begin_example
  https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/authorize?
    client_id=0oa2yrbf35Vcbom491t7&
    response_type=id_token+token&
    scope=openid+email&
    state=aboard-insect-fresh-smile&
    nonce=c96fa468-ca1b-46f0-8974-546f23f9ee6f&
    redirect_uri=https%3A%2F%2Fokta-oidc-fun.herokuapp.com%2Fflow_result
#+end_example

Our =access_token= has the same claims as before.  The =id_token= has the
following:

#+begin_src js
  {
          "sub": "00u2yulup4eWbOttd1t7",
          "email": "okta_oidc_fun@okta.com",
          "ver": 1,
          "iss": "https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7",
          "aud": "0oa2yrbf35Vcbom491t7",
          "iat": 1501528536,
          "exp": 1501532136,
          "jti": "ID.fyybPizTmYLoQR20vlR7mpo8WTxB7JwkxplMQom-Kf8",
          "amr": [
                  "pwd"
          ],
          "idp": "00o1zyyqo9bpRehCw1t7",
          "nonce": "c96fa468-ca1b-46f0-8974-546f23f9ee6f",
          "auth_time": 1501528157,
          "at_hash": "T7ij7o69gBtjo6bAJvaVBQ"
  }
#+end_src

Notice that there’s *less* information in the =id_token= this time (in this
case, there’s no =email_verified= claim).  Because we also requested the
=access_token=, it’s expected that we will get the rest of the available
/identity/ information (based on scope) from the ~/userinfo~ endpoint.  In this
case, it yields the same information as before when we only requested the
=access_token=.

**** OIDC Scopes
#+cindex:scopes, available
Combining all the available scopes with all the possible response types yields
a large set of information to present: 48 combinations, to be exact.  First,
I’ll enumerate what each scope yields and then we’ll look at a few real world
examples combining =request_type= and =scope=.

The first thing to note is that the different scopes have an impact on the
information encoded in an =id_token= and returned from the ~/userinfo~
endpoint.  Here’s a table of scopes and resultant claims.  More information can
be found in [[http://openid.net/specs/openid-connect-core-1_0.html#ScopeClaims][Section 5.4 of the OIDC Spec]].

| scope       | resultant claim                                                            |
|-------------+----------------------------------------------------------------------------|
| openid      | required for all OIDC flows                                                |
| profile     | name, family_name, given_name, middle_name, nickname, preferred_username   |
| (continued) | profile, picture, website, gender, birthdate, zoneinfo, locale, updated_at |
| email       | email, email_verified                                                      |
| address     | address                                                                    |
| phone       | phone_number, phone_number_verified                                        |
|-------------+----------------------------------------------------------------------------|

Let’s try each of our implicit flows with all the possible (default) scope
types.

{{{heading(Response Type of Token)}}}

#+begin_example
  https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/authorize?
    client_id=0oa2yrbf35Vcbom491t7&
    response_type=token&
    scope=openid+profile+email+address+phone&
    state=aboard-insect-fresh-smile&
    nonce=c96fa468-ca1b-46f0-8974-546f23f9ee6f&
    redirect_uri=https%3A%2F%2Fokta-oidc-fun.herokuapp.com%2Fflow_result
#+end_example

The only difference in the resultant =access_token= compared to before is that
all the scopes are encoded into the =scp= array claim.

This time, when I use the =access_token= to hit the ~/userinfo~ endpoint, I get
back more information:

#+begin_example
  http https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/userinfo \
    Authorization:"Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6Ik93bFNJS3p3Mmt1Wk8zSmpnMW5Dc2RNelJhOEV1elY5emgyREl6X3RVRUkifQ..."
  HTTP/1.1 200 OK
  ...
  {
          "sub": "00u2yulup4eWbOttd1t7",
          "name": "Okta OIDC Fun",
          "locale": "en-US",
          "email": "okta_oidc_fun@okta.com",
          "preferred_username": "okta_oidc_fun@okta.com",
          "given_name": "Okta OIDC",
          "family_name": "Fun",
          "zoneinfo": "America/Los_Angeles",
          "updated_at": 1499922371,
          "email_verified": true
  }
#+end_example

Note: While it’s not the complete list of claims defined from =profile= scope,
it’s all the claims for which my user in Okta has a value.

{{{heading(Response Type of ID Token)}}}

Let’s try just the =id_token= implicit flow (still with all the default
scopes):

#+begin_example
  https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/authorize?
    client_id=0oa2yrbf35Vcbom491t7&
    response_type=id_token&
    scope=openid+profile+email+address+phone&
    state=aboard-insect-fresh-smile&
    nonce=c96fa468-ca1b-46f0-8974-546f23f9ee6f&
    redirect_uri=https%3A%2F%2Fokta-oidc-fun.herokuapp.com%2Fflow_result
#+end_example

Here’s what’s encoded into the =id_token= I get back:

#+begin_src js
  {
          "sub": "00u2yulup4eWbOttd1t7",
          "name": "Okta OIDC Fun",
          "locale": "en-US",
          "email": "okta_oidc_fun@okta.com",
          "ver": 1,
          "iss": "https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7",
          "aud": "0oa2yrbf35Vcbom491t7",
          "iat": 1501532222,
          "exp": 1501535822,
          "jti": "ID.Zx8EclaZmhSckGHOCRzOci2OaduksmERymi9-ad7ML4",
          "amr": [
                  "pwd"
          ],
          "idp": "00o1zyyqo9bpRehCw1t7",
          "nonce": "c96fa468-ca1b-46f0-8974-546f23f9ee6f",
          "preferred_username": "okta_oidc_fun@okta.com",
          "given_name": "Okta OIDC",
          "family_name": "Fun",
          "zoneinfo": "America/Los_Angeles",
          "updated_at": 1499922371,
          "email_verified": true,
          "auth_time": 1501528157
  }
#+end_src

All the (available) /identity/ information is encoded right into the token,
since I don’t have a bearer token to hit the ~/userinfo~ endpoint with.

{{{heading(Response Type of Both Token and ID Token)}}}

Finally, let’s try the last variant of the Implicit Flow:
=response_type= = =id_token+token=:

#+begin_example
  https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/authorize?
    client_id=0oa2yrbf35Vcbom491t7&
    response_type=code+id_token+token&
    scope=openid+profile+email+address+phone&
    state=aboard-insect-fresh-smile&
    nonce=c96fa468-ca1b-46f0-8974-546f23f9ee6f&
    redirect_uri=https%3A%2F%2Fokta-oidc-fun.herokuapp.com%2Fflow_result
#+end_example

In this case, we have some of the claims encoded into the =id_token=:

#+begin_src js
  {
          "sub": "00u2yulup4eWbOttd1t7",
          "name": "Okta OIDC Fun",
          "email": "okta_oidc_fun@okta.com",
          "ver": 1,
          "iss": "https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7",
          "aud": "0oa2yrbf35Vcbom491t7",
          "iat": 1501532304,
          "exp": 1501535904,
          "jti": "ID.1C2NQext2hM0iJy55cLc_Ryc45urVYC1wJ0S-KebkpI",
          "amr": [
                  "pwd"
          ],
          "idp": "00o1zyyqo9bpRehCw1t7",
          "nonce": "c96fa468-ca1b-46f0-8974-546f23f9ee6f",
          "preferred_username": "okta_oidc_fun@okta.com",
          "auth_time": 1501528157,
          "at_hash": "GB5O9CpSSOUSfVZ9CRekRg",
          "c_hash": "mRNStYQm-QU4rwcfv88VKA"
  }
#+end_src

If we use the resultant =access_token= to hit the ~/userinfo~ endpoint, in this
case, we get back:

#+begin_example
  http https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/userinfo Authorization:"Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6Ik93bFNJS3p3Mmt1Wk8zSmpnMW5Dc2RNelJhOEV1elY5emgyREl6X3RVRUkifQ..."
  HTTP/1.1 200 OK
  ...
  {
          "sub": "00u2yulup4eWbOttd1t7",
          "name": "Okta OIDC Fun",
          "locale": "en-US",
          "email": "okta_oidc_fun@okta.com",
          "preferred_username": "okta_oidc_fun@okta.com",
          "given_name": "Okta OIDC",
          "family_name": "Fun",
          "zoneinfo": "America/Los_Angeles",
          "updated_at": 1499922371,
          "email_verified": true
  }
#+end_example

This rounds out all the identity information that was requested in the scopes.

**** Custom Scopes and Claims
#+cindex:custom scopes, claims
The OIDC spec accommodate custom scopes and claims. The ability to include
custom claims in a token (which is cryptographically verifiable) is an
important capability for identity providers.  Okta’s implementation provides
support for this.

Click =Add Claim= to bring up a dialog.

#+cindex:Expression Language, Okta
A custom claim is defined using Okta’s [[https://developer.okta.com/reference/okta_expression_language/][Expression Language]].  Unique to Okta,
the expression language is a flexible way to describe rules for building a
property to include (or not) in custom claims.

**** Verifying Tokens

{{{heading(Verifying Access Tokens)}}}

Access tokens can be verified by hitting the ~/introspect~ endpoint.  For an
active token, you get a response like this:

#+begin_example
  http --auth <OIDC Client ID>:<OIDC Client Secret> -f POST \
  https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/introspect \
  token=eyJhbGciOiJSUzI1NiIsImtpZCI6Ik93bFNJS3p3Mmt1Wk8zSmpnMW5Dc2RNelJhOEV1elY5emgyREl6X3RVRUkifQ...
  HTTP/1.1 200 OK
  ...

  {
      "active": true,
      "aud": "https://afitnerd.com/test",
      "client_id": "xdgqP32nYN148gn3gJsW",
      "exp": 1498517509,
      "fullName": "Micah Silverman",
      "iat": 1498513909,
      "iss": "https://micah.oktapreview.com/oauth2/aus9vmork8ww5twZg0h7",
      "jti": "AT.JdXQPAuh-JTqhspCL8nLe2WgbfjcK_-jmlp7zwaYttE",
      "scope": "openid profile",
      "sub": "micah+okta@afitnerd.com",
      "token_type": "Bearer",
      "uid": "00u9vme99nxudvxZA0h7",
      "username": "micah+okta@afitnerd.com"
  }
#+end_example

Since it requires the OIDC client ID and secret, this operation would typically
be done in an application server where it’s safe to have those credentials.
You would not want something like an end-user web or mobile application to have
access to the OIDC client secret.

If the token parameter is invalid or expired, the ~/introspect~ endpoint
returns this:

#+begin_example
  http --auth <OIDC Client ID>:<OIDC Client Secret> -f POST \
  https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/introspect \
  token=bogus
  HTTP/1.1 200 OK
  ...
  {
      "active": false
  }
#+end_example

{{{heading(Verifying ID Tokens)}}}

#+cindex:JWK endpoint
#+cindex:crypto key
#+cindex:well-known endpoint
#+cindex:API discovery
ID tokens can be verified using the [[https://tools.ietf.org/html/rfc7517][JWK]] endpoint.  JWK is a JSON data structure
that represents a crypto key.  The JWK endpoint is exposed from the OIDC “well
known” endpoint used for API discovery.  This returns a lot of information.
Here’s an excerpt:

#+begin_example
  http https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/.well-known/openid-configuration
  HTTP/1.1 200 OK
  ...
  {
      "authorization_endpoint": "https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/authorize",
          ...
      "introspection_endpoint": "https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/introspect",
          ...
      "issuer": "https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7",
      "jwks_uri": "https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/keys",
          ...
      "userinfo_endpoint": "https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/userinfo"
  }
#+end_example

#+cindex:@code{/keys} endpoint
Some of the endpoints, such as ~/userinfo~ and ~/authorize~, should look
familiar by now.  The one we’re interested in is the ~/keys~ endpoint shown in
=jwks_uri=.

#+begin_example
  http https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7/v1/keys
  HTTP/1.1 200 OK
  ...
  {
      "keys": [
          {
              "alg": "RS256",
              "e": "AQAB",
              "kid": "cbkhWG0YmFsGiNO1LEkWSEszDCTNfwvJPpXxuVf_kX0",
              "kty": "RSA",
              "n": "g2XQgdyc5P6F4K26ioKiUzrdgfy90eBgIbcrKkspKZmzRJ3CIssv69f1ClJvT784J-...",
              "use": "sig"
          }
      ]
  }
#+end_example

Notice the =kid= claim.  It matches the =kid= claim in the header from our
=id_token=:

#+begin_example
  {
   "typ": "JWT",
   "alg": "RS256",
   "kid": "cbkhWG0YmFsGiNO1LEkWSEszDCTNfwvJPpXxuVf_kX0"
  }
#+end_example

We can also see that the algorithm used is =RS256=.  Using the public key found
in the =n= claim along with a security library, we can confirm that the ID
token has not been tampered with.  All of this can be done safely on an
end-user SPA, mobile app, etc.

Here’s a Java example that uses the claims from the jwks_uri above to verify an
id_token:

- https://github.com/dogeared/JWKTokenVerifier

#+begin_example
  java -jar target/jwk-token-verifier-0.0.1-SNAPSHOT-spring-boot.jar \
  eyJhbGciOiJSUzI1NiIsImtpZCI6Ik93bFNJS3p3Mmt1Wk8zSmpnMW5Dc2RNel... \
  g2XQgdyc5P6F4K26ioKiUzrdgfy90eBgIbcrKkspKZmzRJ3CIssv69f1ClJvT784J-... \
  AQAB

  Verified Access Token
  {
    "header" : {
      "alg" : "RS256",
      "kid" : "cbkhWG0YmFsGiNO1LEkWSEszDCTNfwvJPpXxuVf_kX0"
    },
    "body" : {
      "ver" : 1,
      "jti" : "AT.LT9cRL_Kzd3T8Izw_ONZxHJ5xGBPD0m13iiEIDK_Nbw",
      "iss" : "https://micah.okta.com/oauth2/aus2yrcz7aMrmDAKZ1t7",
      "aud" : "test",
      "iat" : 1501533536,
      "exp" : 1501537136,
      "cid" : "0oa2yrbf35Vcbom491t7",
      "uid" : "00u2yulup4eWbOttd1t7",
      "scp" : [ "openid" ],
      "sub" : "okta_oidc_fun@okta.com"
    },
    "signature" : "ZV_9tYxt4v4bp9WEEDu038b7v_OHsbMZw13daR1s5_tI56oayBgJlnqf-..."
  }
#+end_example

If any part of the id_token JWT had been tampered with, you would see this
instead:

: io.jsonwebtoken.SignatureException: JWT signature does not match locally computed signature.

Verifying JWT’s using the ~/introspect~ endpoint and using JWKs is a powerful
component of OIDC.  It allows for a high degree of confidence that the token
has not been tampered in any way.  And, because of that, information contained
within---such as expiration ---can be safely enforced.

**** Advantages of OpenID Connect

Here is what I consider to be the important takeaways:

- OIDC formalizes a number of things left open in OAuth 2.0.  Things like:
  specific token formats (id_token) and specific scopes and claims.

- There’s explicit support for Authentication and Authorization.  OAuth 2.0 was
  always presented purely as an authorization framework, but people would get
  confused with certain flows that allowed for authentication.

- There’s a clear separation between identity (id_token and /userinfo) and
  access to resources (access_token).

- The different flows provide clean use case implementations for mobile apps,
  SPAs, and traditional web apps.

- It’s inherently flexible. It’s easy to provide custom scopes and claims and
  to dictate what information should be encoded into tokens beyond the default
  specification.

** Article---Implement the OAuth 2.0 Authorization Code with PKCE Flow
:PROPERTIES:
:url:      https://developer.okta.com/blog/2019/08/22/okta-authjs-pkce
:author:   Micah Silverman
:date:     August 22, 2019
:END:

- [[https://tools.ietf.org/html/rfc7636][PKCE Specification --- RFC 7636
]]

#+cindex:Single Page Apps
Most developers can attest that as user experience goes up, security goes down.
Single Page Apps (SPAs) offer a great user experience in the browser as they
enable interactivity without full page transitions.  But securing SPAs is
challenging since there may not be a backend (like a .NET or Spring Boot) app
and the browser is an inherently insecure environment.

#+cindex:OpenID Connect
#+cindex:Implicit Flow
#+cindex:Proof Key for Code Exchange
#+cindex:PKCE
So, how do you protect your SPA in such a hostile environment?  When SPAs were
new and browsers as well as providers were more limited in their capabilities,
OAuth 2.0 and its sister standard, OpenID Connect (OIDC) offered an approach
called the Implicit flow.  This flow has always had problems inherent to it and
these problems are exacerbated by the advanced capabilities focused on user
experience in browsers.  Today, /Proof Key for Code Exchange/ (PKCE) provides a
modern solution for protecting SPAs.

OIDC is a thin identity layer for authentication and Single Sign-On that rides
on top of OAuth 2.0, an authorization framework.  In this post, you’ll learn
some foundational concepts of OIDC and OAuth2.  You’ll be guided through a
simple SPA example written in Vue.js that starts with the older (now
deprecated) Implicit flow and then shows the more secure Authorization Code
with PKCE flow.

*** OpenID Connect and OAuth 2.0 Overview

{{{heading(In the Beginning There Was Nothing)}}}

In the beginning, there were siloed web sites that didn’t talk to each other,
and it was sad.  Sites like Yelp started wanting access to the contact
information you had in your Google Contacts.  So, Yelp naturally collected your
Google username and password so that it could access your contacts.  You gave
Yelp your permission, so this was all good, Yes?

No!  With your username and password, Yelp could access your email, your
docs---everything you had in Google---not just your contacts.  And, worse, Yelp
had to store your password in a way that it could use it in plaintext and there
was no standard way to revoke your consent to Yelp to access your Google
account.

{{{heading(Then Came OAuth)}}}

#+cindex:OAuth
The world needed an authorization framework that would allow you to grant
access to specific information without you sharing your password.  Cue OAuth.
Three revisions later, we’re at OAuth 2.0 (there was 1.0 and 1.0a before it)
and all’s right with the world.

{{{heading(The OAuth Flow)}}}

#+cindex:OAuth Flow
#+cindex:Client Application
#+cindex:Access Token
#+cindex:Authorization Server
#+cindex:Resource Server
Now, an application like Yelp (a /Client Application/) can request an /Access
Token/ from a service like Google (an /Authorization Server/).  You (the
/Resource Owner/) log into Google with your credentials and give your /Consent/
to Yelp to access your contacts (and only your contacts).  /Access Token/ in
hand, Yelp makes a request of the Google Contacts API (the /Resource Server/)
and gets your contacts.  Yelp never sees your password and never has access to
anything more than you’ve consented to.  And, you can withdraw your consent at
any time.

{{{heading(Then Came OpenID Connect)}}}

#+cindex:identity
#+cindex:OpenID Connect
#+cindex:OIDC
In this new world of consent and authorization, only one thing was missing:
identity.  Cue OpenID Connect.

#+cindex:Identity Token

#+cindex:Identity Token
#+cindex:JWT
OIDC is a thin layer on top of OAuth 2.0 that introduces a new type of token:
the /Identity Token/.  Encoded within these cryptographically signed tokens in
JWT format, is information about the authenticated user.  This opened the door
to a new level of interoperability and single sign-on.

{{{heading Authorization Code Flow}}}

#+cindex:Authorization Code Flow
OAuth (and by extension OIDC) uses a number of defined Flows to manage the
interactions between the Client App, the Authorization Server and the Resource
Server.  The most secure of these is the Authorization Code Flow.  This flow is
meant to be kicked off from your browser and goes like this:

1. Yelp wants access to your contacts. It presents a button to link your Google
   Contacts.

2. When you click the button, you’re redirected to Google where you login with
   your username and password (if you’re not already logged in).

3. Google shows you a screen telling you that Yelp would like read-only access
   to your contacts.

4. Once you give your consent, Google redirects back to Yelp, via your browser,
   with a temporary code (called an authorization code)

5. Using this code along with a secret, Yelp contacts Google to trade it for an
   Access Token

6. Google validates the code and if all checks out, issues an Access Token with
   limited capabilities (read-only access to your contacts) to Yelp

7. Yelp then presents the Access Token to the Google Contacts API

8. Google Contacts API validates the token and, if the request matches the
   capabilities identified by the token, returns your contact list to Yelp


[[file:resources/authorization_code-50.png]]

#+cindex:client secret
Notice step 8 in the diagram.  In addition to the code, Yelp must present a
secret that has been assigned by Google, which is how Google validates Yelp as
a client.

This flow is great for web apps, but it’s not safe to store a secret in a SPA
app, since anyone can view source code in the browser and gain access to that
secret.  In the early days of OAuth 2.0, without better options, the Implicit
flow provided a mechanism to get ID and Access tokens from the Authorization
server.  PKCE represents a better option now, but let’s first visit the
Implicit flow to see why it’s less secure.

*** Why You Should Never Use the Implicit Flow Again
#+cindex:impicit flow
The OAuth 2.0 specification included the Implicit Flow at a time when browser
support for SPAs was much more limited.  In particular, JavaScript did not have
access to browser history or local storage.  Also, most providers did not allow
cross-site POST requests to a /token endpoint, which is a requirement of the
Authorization Code flow.

{{{heading(The Implicit Flow)}}}

[[file:resources/implicit-flow-50.png]]

Notice that after you authenticate, the Authorization Server (like Google)
responds directly with tokens.  This means that the tokens are in your browser’s
address bar as a result of the redirect. That’s problematic since Google can’t
definitively know that your browser (the intended recipient) actually received
the response. It’s also problematic because modern browsers can do browser
history syncing and they support browser extensions that could be actively
scanning for tokens in the browser address bar. Leaking tokens is a big
security risk.

#+cindex:deprecate, Implicit Flow
These security issues led to a reassessment of the value of the Implicit flow,
and in November of 2018, new guidance was released that effectively deprecated
this flow.  Additional specs that speak to [[https://oauth.net/2/oauth-best-practice/][updated guidelines for security with
OAuth 2.0]] in general and [[https://oauth.net/2/browser-based-apps/][security for web apps]] in particular were put forward
this year as well.

#+cindex:Proof Key for Code Exchange
#+cindex:PKCE
If you can’t (or shouldn’t) use the Implicit flow, then what?  It turns out
there’s an extension to the Authorization Code flow that’s been in use for some
time with Mobile and Native apps.  That’s /Proof Key for Code Exchange/ or PKCE
(pronounced “pixie”).

*** Use PKCE to Make Your Apps More Secure
PKCE has its own separate specification.  It enables apps to use the most
secure of the OAuth 2.0 flows---the Authorization Code flow---in public or
untrusted clients.  It accomplishes this by doing some setup work before the
flow and some verification at the end of the flow to effectively utilize a
dynamically-generated secret.  This is crucial since it’s not safe to have a
fixed secret in a public client (like a SPA app in your browser).

PKCE was originally created for mobile and native applications because, at the
time, both browsers and most providers were not capable of supporting PKCE.
That is no longer the case.

{{{heading(How PKCE Works)}}}

#+cindex:random value
#+cindex:Code Verifier
#+cindex:Code Challenge
PKCE works by having the app generate a random value at the beginning of the
flow called a Code Verifier.  The app hashes the Code Verifier and the result
is called the Code Challenge.  The app then kicks off the flow in the normal
way, except that it includes the Code Challenge in the query string for the
request to the Authorization Server.

The Authorization Server stores the hashed value (the Code Challenge) for later
verification and, after the user authenticates, redirects back to the app with
an authorization code.

The app makes the request to exchange the code for tokens, only it sends the
Code Verifier instead of a fixed secret.  Now the Authorization Server can hash
the Code Verifier and compare it to the hashed value it stored earlier.  This
is an effective, dynamic stand-in for a fixed secret.  Assuming the hashed
value matches, the Authorization Server will return the tokens.

{{{What the PKCE Flow Looks Like}}}

[[file:resources/pkce-flow-50.png]]

To see the difference between the Implicit flow and the Authorization Code with
PKCE flow, there’s a sample on [[https://github.com/oktadeveloper/okta-auth-js-pkce-example][GitHub]] that you can follow along with.

*** Create an OIDC Application on Okta

First, let’s get an OpenID Connect application setup in Okta.

{{{heading(Create an OIDC Application)}}}

#+cindex:application, OKTA
#+cindex:OKTA developer account
Before you can run the code, you need to create an OIDC application on Okta. If
you don’t have an Okta developer account, create one at
[[https://developer.okta.com/signup][developer.okta.com/signup]].

1. From your Okta admin console, in the top menu, click on *Applications*.

2. Click the green *Add Application* button

3. Select *Single-Page App* application, and click *Next*

4. Give the app a Name.  Any name.  I used “My SPA”.

5. Change the value for Login redirect URIs to http://localhost:8080/callback

6. Check *Authorization Code* (and leave *Implicit* clicked)

7. Click *Done*

8. Take note of the *Client ID* at the bottom of the page.  You’ll need these
   in the next section.


*NOTE*: The demo app uses both the Implicit flow and the Authorization Code
with PKCE flow for demonstration purposes.  For your production app, you would
uncheck the Implicit checkbox and check the Authorization Code checkbox.

That’s it on the Okta side.  You just configured an OAuth 2.0 + OIDC identity
provider.  Congrats!

**** Run the Vue.js App
You can grab the code from the [[https://github.com/oktadeveloper/okta-auth-js-pkce-example][GitHub repository]].

1. Open up the project in your favorite editor and update the top of
   ~auth/index.js~ with the values you captured earlier for =ISSUER= and
   =CLIENT_ID=.

2. Build the application:
   : npm install
   : npm run serve

3. Browse to: http://localhost:8080 and you’ll see this simple app.  The home
   page is not protected in any way.  The navigation at the top includes both a
   link to =Profile (implicit)= and =Profile (pkce)=.  The idea here is that in
   order to look at your profile, you’ll need to authenticate first.

4. I recommend you use an incognito window to exercise the app.  First, click
   =Profile (implicit)= and confirm that you’re redirected to Okta, can
   authenticate and that you see the resultant profile screen.

5. Next, click =Logout= and click =Profile (pkce)=. Login once again and you
   should see the profile information screen as above.


Let’s see what’s going on under the hood to better understand why the PKCE
approach is better.

**** Dive Into How the Implicit Flow Works
Log out once again.  Open the developer tools pane (CMD + option + i on mac)
and click the =Sources= tab.  Expand ~webpack:// > . > src > auth > index.js~.
Set a breakpoint by clicking in the margin inside the callback function.

Click =Profile (implicit)= and login.  The app should pause at the breakpoint
you’ve set.  Click the =Network= tab and locate the ~/authorize~ call.  It will
look something like this (formatted for easier reading):

#+begin_example
  https://dev-micah.okta.com/oauth2/default/v1/authorize?
  client_id=0oapu4btsL2xI0y8y356
  &redirect_uri=http://localhost:8080/callback
  &response_type=id_token token
  &response_mode=fragment
  &state=SU8nskju26XowSCg3bx2LeZq7MwKcwnQ7h6vQY8twd9QJECHRKs14OwXPdpNBI58
  &nonce=Ypo4cVlv0spQN2KTFo3W4cgMIDn6sLcZpInyC40U5ff3iqwUGLpee7D4XcVGCVco
  &scope=openid profile email
#+end_example

Notice the value for =response_type= is =id_token= token.  This is what
indicates the request is using the /Implicit/ flow and that the expectation is
that an =id_token= and an =access_token= will be returned directly.

Take a look in your browser’s URL address bar.  Because you’ve paused at the
breakpoint, you have an opportunity to capture what’s there before it changes.
It will look something like this (formatted for easier reading):

#+begin_example
http://localhost:8080/callback#
id_token=eyJraWQiOiI3bFV0aGJyR2hWVmx...
&access_token=eyJraWQiOiI3bFV0aGJyR2...
&token_type=Bearer
&expires_in=3600
&scope=profile+openid+email
&state=SU8nskju26XowSCg3bx2LeZq7MwKcwnQ7h6vQY8twd9QJECHRKs14OwXPdpNBI58
#+end_example

Both the =id_token= and the =access_token= values are right there.  This means
they’re in your browser history and any mischievous browser extensions could
access these values.  Click the button that looks like an old school tape
recorder play icon to allow the browser to continue.

Let’s see how the Authorization Code with PKCE flow gives you a better security
footing.

**** Replace Implicit Flow with PKCE
Logout again and repeat the process, only this time, click on =Profile (pkce)=.
Locate the ~/authorize~ call again on the network tab.  It will look something
like this:

#+begin_example
https://dev-micah.okta.com/oauth2/default/v1/authorize?
client_id=0oapu4btsL2xI0y8y356&
redirect_uri=http://localhost:8080/callback&
response_type=code&
response_mode=fragment&
state=MdXrGikS5LACsWs2HZFqS7IC9zMC6F9thOiWDa5gxKRqoMf7bCkTetrrwKw5JIAA&
nonce=iAXdcF77sQ2ejthPM5xZtytYUjqZkJTXcHkgdyY2NinFx6y83nKssxEzlBtvnSY2&
code_challenge=elU6u5zyqQT2f92GRQUq6PautAeNDf4DQPayyR0ek_c&
code_challenge_method=S256&
scope=openid profile email
#+end_example

Notice that the =response_type= is code, meaning that we expect the result of
the request to be an authorization code.  This is how you would construct an
authorize call for the ordinary Authorization Code flow.  However, there’s also
the inclusion of the =code_challenge= and the =code_challenge_method= which the
okta-auth-js library has automatically prepared in advance.  This is the PKCE
extension in action.

Take a look in your browser’s URL address bar as before:

#+begin_example
http://localhost:8080/callback#
code=ZIhxKbQyh-vC32deCWpM&
state=MdXrGikS5LACsWs2HZFqS7IC9zMC6F9thOiWDa5gxKRqoMf7bCkTetrrwKw5JIAA
#+end_example

This time, you should see the code parameter.  While this does end up in your
browser history, it has three advantages from a security perspective over
having the tokens in your browser history:

1. It’s very short lived (60 seconds with Okta)

2. It can only be used once to be exchanged for tokens

3. It can only be exchanged for tokens using a secret (the code verifier
   created by the okta-auth-js library earlier), which malicious browser
   extensions would not have access to.


You may be wondering just how our current code handles exchanging the code for
tokens.  This is handled internally by the okta-auth-js library without
additional coding on your part.

Let the code execution continue as before. Look on the Network tab and locate
the ~/token~ call.  It will look something like this:

#+begin_example
POST https://dev-micah.okta.com/oauth2/ausneyiq5fyDfRMvZ356/v1/token

client_id=0oapu4btsL2xI0y8y356&
code_verifier=7073d688b6dcb02b9a2332e0792be265b9168fda7a6&
redirect_uri=http%3A%2F%2Flocalhost%3A8080%2Fcallback&
grant_type=authorization_code&
code=AyfnwMyCi2S9-op2xToh
#+end_example

The =client_id=, =code_verifier= (stand-in for a fixed secret) and code are
validated by Okta and if everything checks, tokens are returned.

Notice that the request is a =POST=.  The response is returned on the same
channel (as opposed to a redirect response with the Implicit flow) and, as
such, that response will not be in your browser history.

*NOTE*: The authorization code returned in the /authorize step is only valid
for 60 seconds.  If you waited too long at the breakpoint in the debugger,
you’ll need to start over.

Here’s what the valid response looks like:

#+begin_src js
{
    "token_type":   "Bearer",
    "expires_in":   3600,
    "access_token": "eyJraWQiOiI3bFV0aGJyR2hWVmx...",
    "id_token":     "eyJraWQiOiI3bFV0aGJyR2hWVmx...",
    "scope":        "profile openid email"
}
#+end_src

The fact that the tokens never end up in your browser history makes the PKCE
approach much more secure than the Implicit flow.

**** PKCE vs Implicit---A Closer Look
The code example does some fancy footwork to support both the Implicit and
Authorization Code with PKCE flows.  This is not something you’d likely do in a
production application.  But, it’s worth looking at the mechanism of how this
code works and to highlight how easy it is to switch from the Implicit flow to
the Authorization Code with PKCE flow when you use the okta-auth-js library.

When you click either of the =Profile= links in the =nav= bar, the
~validateAccess~ function is called by virtue of the middleware processing
capabilities of the ~Vue.js~ router.  Here’s the router definition:

#+begin_src js
  export default new Router({
    mode: 'history',
    base: process.env.BASE_URL,
    routes: [
      { path: '/', name: 'home', component: Home },
      { path: '/callback', component: callback },
      { path: '/profile', redirect: '/profile/authorization_code' },
      { path: '/profile/:mode', beforeEnter: validateAccess, component: Profile },
      { path: '/logout', component: logout }
    ]
  })
#+end_src

Notice the =beforeEnter= parameter for the ~/profile/:mode~ path.  The =:mode=
will either be =authorization_code= or =implici= and matches the technical name
of the flow in use.  Flows are called /grants/ in the specification.

Take a look at the ~validateAccess~ function in the ~auth/index.js~ folder:

#+begin_src js
  export function validateAccess(to, from, next) {
      getIdToken()
      .then(function(token) {
          if (token) {
              next();
          } else {
              oktaAuth.tokenManager.clear();
              // implicit or pkce?
              var grantParam = to.path.substring(to.path.lastIndexOf('/') + 1);
              var grantType = (responseTypes[grantParam]) ? grantParam : AUTH_CODE_GRANT_TYPE
              loginOkta(grantType);
          }
      })
      .catch(console.error);
  }
#+end_src

This code attempts to retrieve the =idToken= from the okta-auth-js token
manager.  If found, the ~next()~ function call allows the router to proceed to
the profile page.

If the =idToken= is not found, then the grant type (flow) is extracted from the
path.  The ~loginOkta~ function is then called with the retrieved grantType.

#+begin_src js
  export function loginOkta(grantType) {
      oktaAuth.options.grantType = grantType;
      oktaAuth.token.getWithRedirect({
          responseType: responseTypes[grantType],
          scopes: ['openid', 'profile', 'email']
      });
  }
#+end_src

The ~loginOkta~ function sets the =grantType= and the =responseType= in the
okta-auth-js library which is how this code supports both flows dynamically.

The last little bit of trickery is in the callback function with these lines of
code:

#+begin_src js
  export function callback() {
      // detect code
      var grantType = (window.location.href.indexOf('code=') > 0) ?
          AUTH_CODE_GRANT_TYPE : IMPLICIT_GRANT_TYPE;
      oktaAuth.token.parseFromUrl()
      .then((tokens) => {
          ...
          router.push('/profile/' + grantType);
      })
      .catch(console.error);
  }
#+end_src

The =grantType= is detected from the response url by looking for the presence
of a code= parameter.  =grantType= is used further down in the ~router.push~
call.  By virtue of how the ~Vue.js~ and the router work, navigating to the
specific profile url will cause the proper item in the nav to be highlighted.

The call to ~oktaAuth.token.parseFromUrl()~ extracts the tokens from the url in
the case of the Implicit flow OR automatically calls the ~/token~ endpoint to
exchange the code for tokens in the case of the Authorization Code with PKCE
flow.

Hopefully it’s now crystal clear why you want to use the Authorization Code
with PKCE flow over the (now deprecated) Implicit flow.  The good news is that
if you’ve already used the okta-auth-js library, a few tweaks to your existing
code should be all that’s required to switch flows!

** Article---Authentication with AWS Amplify and Android--3rd Party OIDC Providers
:PROPERTIES:
:url:      https://itnext.io/authentication-with-aws-amplify-and-andro-3rd-party-oidc-providers-df4beaf4110d
:author:   Adrian Hall
:date:     Oct 15, 2018
:END:
This will be an in-depth series on authentication with AWS Amplify. Here are
the topics I am going to cover, and I will update each blog with the links as I
complete the articles.

- The basics — a username/password system.
  : https://medium.com/@FizzyInTheHall/authentication-with-aws-amplify-and-android-the-basics-34f55ddf3759

- Customizing the UI.
  : https://itnext.io/authentication-with-aws-amplify-and-android-customizing-the-ui-2c36e888b200

- Authenticating with Facebook.
  : https://itnext.io/authentication-with-aws-amplify-facebook-login-878ce4df6e82

- Authenticating with Google.
  : https://itnext.io/authentication-with-aws-amplify-google-login-878aaf11f2d4

- Using third-party authentication providers.

- Using Time-based One-time passwords (TOTP).
  : Using Time-based One-time passwords (TOTP)

- Using Biometric authentication.
  : https://itnext.io/authentication-with-aws-amplify-and-android-integrating-biometrics-924f36c7b9c1

- Doing fraud protection and analytics.
  : https://itnext.io/authentication-with-aws-amplify-and-android-fraud-protection-and-analytics-55761ad5c708


In the last two articles, I’ve covered Facebook and Google — probably the most
important authentication providers that there are out there and for which there
is specific support in Amazon Cognito. However, that is not always the
case. You might want to authenticate against Salesforce, GitHub, or other
OpenID Connect (OIDC) providers — providers that aren’t directly supported by
Amazon Cognito. In fact, you could [[https://www.scottbrady91.com/OpenID-Connect/Getting-Started-with-oidc-provider][write your own OIDC provider]], although I
would not recommend it. Use a service!

So, what’s involved?

1. Set up authentication with the provider of choice.

2. Configure Amazon Cognito to federate with the provider.

3. When you receive an authentication token from the provider, pass it to the
   Amazon Cognito identity pool for federation.


Sound familiar? It’s exactly the same as the process we used for Facebook and
Google.

In this article, I’m going to set up Auth0 as an authentication source. Auth0
is an OIDC compliant authentication provider that aggregates other providers
(like Google and Facebook). It’s main advantage for this purpose, however, is
that it is very developer friendly.

*** Step 1---Set up authentication with the provider of choice
All authentication providers require you to register with them. This is the
process:

- Go to [[https://auth0.com/][auth0.com]] and click on the Login button to authenticate.

- If this is your first time, you’ll be asked to register through a simple and
  short process. Eventually, you will land on your dashboard.

- Click New Application

- Give your application a name, select the Native button, then click Create.

- Click Settings. Make a note of the Domain and Client ID. You will need these
  later.

- Add the following string to the Allowed Callback URLs, then click Save
  Changes:
  : https://DOMAIN.auth0.com/android/PACKAGE/callback


Here DOMAIN is the Domain of your application (you just made a note of it) and
PACKAGE is the root package for your app. You can find PACKAGE as the
android.applicationId within the app-level build.gradle or the package
parameter on the application node within the AndroidManifest.xml file.

Yes, Auth0 is truly that quick and easy to set up. In many respects, it’s much
easier to get started than Google or Facebook, since they’ve done most of the
work for you. Now, let’s get started on the client side. Open up your project
in Android Studio.

Add the following strings to your strings.xml file:

#+begin_example
<!-- Auth0 SDK -->
<string name="com_auth0_client_id">CLIENT-ID</string>
<string name="com_auth0_domain">DOMAIN.auth0.com</string>
#+end_example

The Client ID and Domain are from the Settings page for your application from
the Auth0 console.

Next ...

*** Step 2---Configure Amazon Cognito identity pools
The AWS Amplify CLI provides a simplified process for configuring the back end
if you are using one of the supported paths. Generic OIDC providers is
definitely off the beaten path, so how do we configure Amazon Cognito to use an
OIDC provider when it’s not supported?

...

*** Step 3---Federate with the Identity Pool
Given that we are using the same process as for both the Facebook and Google
authentication providers, this should be familiar now. First...

*** Common Errors

*** Wrap Up
This is the last of the primary authentication methods that we will cover. In
the next article, I’m going to cover TOTP (Time-based one-time passwords) for
Amazon Cognito user pools, including configuration and usage.

Until then, you can find the code for this article [[https://gitlab.com/adrianhall/aws-mobile-android-kotlin-photos/tree/auth0-auth][on my repository]].
** Article---Building a Custom UI for Authentication with AWS Amplify
:PROPERTIES:
:url:      https://itnext.io/building-a-custom-ui-for-authentication-with-aws-amplify-fa13bdbd4d1d
:date:     Mar 29, 2018
:author:   Adrian Hall
:END:
In my [[*Article---Implement Authentication in a React Native App with AWS Amplify][last post]], I introduced the basic form of authentication, hooked onto a
button and using the default UI. The default UI does not include any
branding. When you are creating your own app, you will want to use your
backgrounds, colors, fonts and logos. You will want to create your own
=Authenticator= component that deals with this for you. Fortunately, AWS
Amplify makes this simple.

Authentication follows a state diagram. You start unauthenticated and sitting
at the sign-in screen. As you perform authentication operations (sign-in,
submit-mfa, sign-up, confirm-signup, etc.), you transition from one state to
another, gathering and mutating the authentication data and communicating with
Amazon Cognito along the way. The =Authenticator= component is a state
management system that displays the right component based on the state and
allows the underlying component to sign-in:

#+begin_src js
import React from 'react';
import ForgotPassword from './ForgotPassword';
import SignUp from './SignUp';
import SignIn from './SignIn';

class Authenticator extends React.Component {
  static defaultProps = {
    initialState: 'default',
    initialData: {},
    onAuthenticated: (authData) => { console.log(`onAuthenticated(${JSON.stringify(authData, null, 2)}`); }
  };

  constructor(props) {
    super(props);
    this.state = {
      authState: this.props.initialState,
      authData: this.props.initialData,
    };
  }

  onAuthStateChange(newState, newData) {
    const data = Object.assign({}, this.state.authData, newData);
    this.setState({ authState: newState, authData: data });
    if (newState === 'authenticated') {
      this.props.onAuthenticated(data);
    }
  }

  render() {
    const props = {
      authData: this.state.authData,
      authState: this.state.authState,
      onAuthStateChange: (s,d) => this.onAuthStateChange(s,d)
    };

    switch (this.state.authState) {
      case 'forgotPassword':
        return <ForgotPassword {...props}/>;
      case 'signUp':
        return <SignUp {...props} />;
      case 'signIn':
      default:
        return <SignIn {...props} />;
    };
  }
}

export default Authenticator;
#+end_src

In this particular component (which models the requirements of user pools in
Amazon Cognito), we need to model three different screens — =SignIn=, =SignUp=
and =ForgotPassword=. Each one is passed the current state and the current
authentication data blob (which is made up of return values from Amazon
Cognito).

*** The SignUp component

*** The SignIn Component

*** Other things you can do

Wherever your needs take you, you can implement it with the AWS Amplify
library. Learn more about the [[https://aws.github.io/aws-amplify][AWS Amplify library on GitHub]]. You can find the
example code I use here in my [[https://github.com/adrianhall/blog-code/tree/master/awsmobilecognitocustomui][my GitHub repository]].

** Article---Implement Authentication in a React Native App with AWS Amplify
:PROPERTIES:
:url:      https://medium.com/@FizzyInTheHall/implement-authentication-in-a-react-native-app-with-aws-amplify-313b8326339a
:date:     Mar 27, 2018
:author:   Adrian Hall
:END:
Todays blog is on mobile authentication. If there is one topic that comes up
over and over, it’s how to ensure that only my users can access their
data. Security and Data Privacy are hugely important topics, and rightly
so. How do I do this easily?

Fortunately, [[https://aws.amazon.com/mobile][AWS Mobile]] has been hard at work on making this simple, so let’s
get right to it with setting up a backend. If you have an AWS account (they are
free — you only pay for your consumption, not for having an account), then you
can set up the awsmobile CLI to make configuring things easy. I’m going to
assume you have already set up the [[https://facebook.github.io/react-native/docs/getting-started.html][React Native CLI]] on your system and
installed the AWS CLI as well. Installing the awsmobile CLI is a snap:
* Amazon Cognito
“Simple and Secure User Sign-Up, Sign-In, and Access Control”

- [[https://aws.amazon.com/cognito/][Amazon Cognito]]
- [[https://docs.aws.amazon.com/cognito/latest/developerguide/what-is-amazon-cognito.html][AWS Documentation-Amazon Cognito-Developer Guide]]


“Spend your time creating great apps.  Let Amazon Cognito handle
authentication.”

#+cindex:Cognito
#+cindex:Amazon Cognito
Amazon Cognito lets you add user sign-up, sign-in, and access control to your
web and mobile apps quickly and easily.  Amazon Cognito scales to millions of
users and supports sign-in with social identity providers, such as Facebook,
Google, and Amazon, and enterprise identity providers via SAML 2.0.

{{{heading(Amazon Cognito provides:)}}}

- authentication
- authorization
- user management


{{{noindent}}}for your web and mobile apps.  Your users can sign in directly
with a user name and password, or through a third party such as:

- Facebook
- Amazon
- Google
- Apple


** About Cognito

{{{heading(Secure and scalable user directory)}}}

#+cindex:user pools
Amazon Cognito User Pools provide a secure user directory that scales to
hundreds of millions of users.  As a fully managed service, User Pools are easy
to set up without any worries about standing up server infrastructure.

- [[https://docs.aws.amazon.com/cognito/latest/developerguide/getting-started-with-cognito-user-pools.html][Cognito User Pools]]


{{{heading(Social and enterprise identity federation)}}}

#+cindex:social identity providers
#+cindex:Google
#+cindex:Facebook
#+cindex:Amazon
#+cindex:Active Directory
#+cindex:SAML
#+cindex:federation
With Amazon Cognito, your users can sign in through social identity providers
such as Google, Facebook, and Amazon, and through enterprise identity providers
such as Microsoft Active Directory via SAML.

- [[https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pools-identity-federation.html][Federation]]


{{{heading(Standards-based authentication)}}}

#+cindex:OAuth
#+cindex:SAML
#+cindex:OpenID Connect
#+cindex:standards based authentication
#+cindex:authentication
Amazon Cognito User Pools is a standards-based Identity Provider and supports
identity and access management standards, such as Oauth 2.0, SAML 2.0, and
OpenID Connect.

- [[https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools.html][standards-based authentication]]


{{{heading(Security for your apps and users)}}}

#+cindex:multi-factor authentication
#+cindex:encryption
#+cindex:HIPAA
#+cindex:compliance, security
#+cindex:security
Amazon Cognito supports multi-factor authentication and encryption of
data-at-rest and in-transit.  Amazon Cognito is HIPAA eligible and PCI DSS,
SOC, ISO/IEC 27001, ISO/IEC 27017, ISO/IEC 27018, and ISO 9001 compliant.

- [[https://aws.amazon.com/compliance/][security and compliance]]


{{{heading(Access control for AWS resources)}}}

#+cindex:access control
#+cindex:backend resources
#+cindex:users
#+cindex:roles
Amazon Cognito provides solutions to control access to backend resources from
your app.  You can define roles and map users to different roles so your app
can access only the resources that are authorized for each user.

- [[https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-identity.html][controlling access to AWS resources]]


{{{heading(Easy integration with your app)}}}

#+cindex:sign-in
#+cindex:sign-up
#+cindex:access control
With a built-in UI and easy configuration for federating identity providers,
you can integrate Amazon Cognito to add user sign-in, sign-up, and access
control to your app in minutes.  You can customize the UI to put your company
branding front and center for all user interactions.

- [[https://docs.aws.amazon.com/cognito/latest/developerguide/getting-started.html][integrate Amazon Cognito with your app]]

** Main Components of Cognito

#+cindex:user pools
#+cindex:identity pools
The two main components of Amazon Cognito are:

- user pools :: user directories that provide sign-up and sign-in options for
                your app users

- identity pools :: enable you to grant your users access to other AWS services


{{{noindent}}}You can use identity pools and user pools separately or together.

{{{subheading(An Amazon Cognito user pool and identity pool used together)}}}

See the diagram for a common Amazon Cognito scenario.  Here the goal is to

- *authenticate* your user, and

- then *grant* your user access to another AWS service.


{{{heading(Steps)}}}

1. In the first step your app user *signs in* through a /user pool/ and receives
  /user pool tokens/ after a successful authentication.

2. Next, your app *exchanges* the user pool tokens for /AWS credentials/ through
  an /identity pool/.

3. Finally, your app user can then use those /AWS credentials/ to access other
  AWS services such as Amazon S3 or DynamoDB.


#+caption:User Pools and Identity Pools
#+name:user-pools-and-identity-pools
[[file:resources/scenario-cup-cib2.png][file:/usr/local/dev/programming/Security/Security-Info/resources/scenario-cup-cib2.png]]

** Features of Amazon Cognito

*** User Pools

A /user pool/ is a user directory in Amazon Cognito.  With a user pool, your
users can sign in to your web or mobile app through Amazon Cognito, or federate
through a third-party identity provider (IdP).  Whether your users sign in
directly or through a third party, all members of the user pool have a
directory profile that you can access through an SDK.

User pools provide:

- Sign-up and sign-in services.

- A built-in, customizable web UI to sign in users.

- Social sign-in with Facebook, Google, Login with Amazon, and Sign in with
  Apple, and through SAML and OIDC identity providers from your user pool.

- User directory management and user profiles.

- Security features such as multi-factor authentication (MFA), checks for
  compromised credentials, account takeover protection, and phone and email
  verification.

- Customized workflows and user migration through AWS Lambda triggers.

*** Identify Pools

With an /identity pool/, your users can obtain temporary AWS credentials to
access AWS services, such as Amazon S3 and DynamoDB.  Identity pools support
anonymous guest users, as well as the following identity providers that you can
use to authenticate users for identity pools:

- Amazon Cognito user pools

- Social sign-in with Facebook, Google, Login with Amazon, and Sign in with
  Apple

- OpenID Connect (OIDC) providers

- SAML identity providers

- Developer authenticated identities


To save user profile information, your identity pool needs to be integrated
with a user pool.

** Getting Started with Amazon Cognito

{{{heading(It Really Is This Easy)}}}

#+caption:Sign in users and get back tokens using the SDKs and a few lines of code.
#+name:cognito-example
#+begin_src js -n :eval no
  // Add 'aws-amplify' library into your application

  // Configure Auth category with your Amazon Cognito credentials
  Amplify.configure({
      Auth: {
          identityPoolId: 'XX-XXXX-X:XXXXXXXX-XXXX', // Amazon Cognito Identity Pool ID
          region: 'XX-XXXX-X', // Amazon Cognito Region
      }
  });

  // Call Auth.signIn with user credentials
  Auth.signIn(username, password)
      .then(user => console.log(user))
      .catch(err => console.log(err));
#+end_src

#+name:cognito-landing-iphone
[[file:resources/Cognito_SI_IMG_landing_iphone.23469830ae7726f1f17678973733595223709d9a.png]]

{{{heading(Top Tasks)}}}

*** Add Sign-up and Sign-in with a User Pool

**** Step 1---Create a User Directory with a User Pool
  By using an Amazon Cognito user pool, you can create and maintain a user
  directory, and add sign-up and sign-in to your mobile app or web application.

  {{{heading(To create a user pool:)}}}

  1. Go to the [[https://console.aws.amazon.com/cognito/home][Amazon Cognito console]].

  2. Choose *Manage User Pools*.

  3. In the top-right corner of the page, choose *Create a user pool*

  4. Provide a name for your user pool, and choose *Review defaults* to save
     the name.

  5. In the top-left corner of the page, choose *Attributes*, choose *Email
     address or phone number* and *Allow email addresses*, and then choose
     *Next step* to save.

  6. In the top-left corner of the page, choose *Review*.

  7. Review the user pool information and make any necessary changes. When the
     information is correct, choose *Create pool*.

**** Step 2---Add an App to Enable the Hosted Web UI

  After you create a user pool, you can create an app to use the built-in
  webpages for signing up and signing in your users.

  {{{heading(To create an app in your user pool:)}}}

  1. Go to the [[https://console.aws.amazon.com/cognito/home][Amazon Cognito console]].

  2. Choose Manage your User Pools.

  3. Choose an existing user pool from the list, or create a user pool.

  4. On the navigation bar on the left-side of the page, choose *App clients*
     under *General settings*.

  5. Choose *Add an app client*.

  6. Give your app a name.

  7. Clear the option *Generate client secret* for the purposes of this getting
     started exercise, as it would not be secure to send it on the URL using
     client-side JavaScript.  The client secret is used by applications that
     have a server-side component that can secure the client secret.

  8. Choose *Create app client*.

  9. Note the App client.

     : 1cfa1mhp1prcvent4u1k0h57o1

  10. Choose *Return to pool details*.

  11. Configure the app.

      - Choose *App client settings* from the navigation bar on the left-side
        of the console page.

      - Select *Cognito User Pool* as one of the Enabled Identity
        Providers.[fn:4]

      - Type a callback URL for the Amazon Cognito authorization server to call
        after users are authenticated. For a web app, the URL should start with
        =https://=, such as =https://www.example.com=.  For an iOS or Android
        app, you can use a callback URL such as =myapp://=.

      - Select *Authorization code grant* to return an authorization code that
        is then exchanged for user pool tokens.  Because the tokens are never
        exposed directly to an end user, they are less likely to become
        compromised.  However, a custom application is required on the backend
        to exchange the authorization code for user pool tokens.  For security
        reasons, we recommend that you use the authorization code grant flow,
        together with see [[https://tools.ietf.org/html/rfc7636][Proof Key for Code Exchange (PKCE)]], for mobile apps.

        Under *Allowed OAuth Flows*, select *Implicit* grant to have user pool
        JSON web tokens (JWT) returned to you from Amazon Cognito.  You can use
        this flow when there's no backend available to exchange an
        authorization code for tokens.  It's also helpful for debugging tokens.

        You can enable both the *Authorization code grant* and the *Implicit
        code grant*, and then use each grant as needed.[fn:5]

        Unless you specifically want to exclude one, select the check boxes for
        all of the *Allowed OAuth scopes*.

  12. Configure a user pool domain.

      - On the *Domain name page*, type a domain prefix that's available.

      - Make a note of the complete domain address.

      - Choose *Save changes*.


{{{heading(To view your sign-in page)}}}

You can view the hosted UI sign-in webpage with the following URL.  Note the
=response_type=.  In this case, =response_type= = =code= for the authentication
code grant.

: https://<your_domain>/login?response_type=code&client_id=<your_app_client_id>&redirect_uri=<your_callback_url>

You can view the hosted UI sign-in webpage with the following URL for the
/implicit code grant/ where =response_type= = =token=.  After a successful
sign-in, Amazon Cognito returns user pool tokens to your web browser's address
bar.

: https://<your_domain>/login?response_type=token&client_id=<your_app_client_id>&redirect_uri=<your_callback_url>

You can find the JSON web token (JWT) identity token after the =#idtoken= =
=parameter= in the response.  Here's a sample response from an implicit grant
request.  Your identity token string will be much longer.

: https://www.example.com/#id_token=123456789tokens123456789&expires_in=3600&token_type=Bearer  

You can decode and verify user pool tokens using AWS Lambda, see [[https://github.com/awslabs/aws-support-tools/tree/master/Cognito/decode-verify-jwt][Decode and
verify Amazon Cognito JWT tokens]] on the AWS GitHub website.

Amazon Cognito user pools tokens are signed using an *RS256 algorithm*.

Your domain is shown on the *Domain name* page.  Your app client ID and
callback URL are shown on the *App client settings* page.

**** Step 3---Add Social Sign-in to a User Pool
  - https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pools-configuring-federation-with-social-idp.html


  You can enable your app users to sign in through a social identity provider
  (IdP) such as Facebook, Google, Amazon, and Apple.  Whether your users sign
  in directly or through a third party, all users have a profile in the user
  pool.  Skip this step if you don't want to add sign in through a social
  sign-in identity provider.

  1. Register with a Social IdP

  2. Add a Social IdP to Your User Pool

  3. Test Your Social IdP Configuration

**** Adding OIDC Identity Providers to a User Pool
- https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pools-oidc-idp.html


You can enable your users who already have accounts with OpenID Connect (OIDC)
identity providers (IdPs) (like Okta, Salesforce or Ping Identity) to skip the
sign-up step—and sign in to your application using an existing account.  With
the built-in hosted web UI, Amazon Cognito provides token handling and
management for all authenticated users, so your backend systems can standardize
on one set of user pool tokens.

**** Integrating Amazon Cognito With Web and Mobile Apps
- https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-integrate-apps.html


When new users discover your app, or when existing users return to it, their
first tasks are to sign up or sign in.  By integrating Amazon Cognito with your
client code, you connect your app to backend AWS functionality that aids
authentication and authorization workflows.  Your app will use the Amazon
Cognito API to, for example, create new users in you user pool, retrieve user
pool tokens, and obtain temporary credentials from your identity pool.  To
integrate Amazon Cognito with your web or mobile app, use the SDKs and
libraries that the AWS Amplify framework provides.

***** Amazon Cognito Authentication With the AWS Amplify Framework

AWS Amplify provides services and libraries for web and mobile developers.
With AWS Amplify, you can build apps that integrate with backend environments
that are composed of AWS services.  To provision your backend environment, and
to integrate AWS services with your client code, you use the AWS Amplify
framework.  The framework provides an interactive command line interface (CLI)
that helps you configure AWS resources for features that are organized into
categories, including analytics, storage, and authentication, among many
others.  The framework also provides high-level SDKs and libraries for web and
mobile platforms, including iOS, Android, and JavaScript.  Supported JavaScript
frameworks include React, React Native, Angular, Ionic, and Vue.  Each of the
SDKs and libraries include authentication operations that you can use to
implement the authentication workflows that Amazon Cognito drives.

To use the AWS Amplify framework to add authentication to your app, see the AWS
Amplify documentation for your platform:

- [[https://aws-amplify.github.io/docs/js/authentication][AWS Amplify authentication for JavaScript]]

*** Manage Users in a User Pool

**** TODO Signing Up and Confirming User Accounts

User accounts are added to your user pool in one of the following ways:

- The user signs up in your user pool's client app, which can be a mobile or
  web app.

*** Access Resources

* Amazon Certificate Manager and HTTPS

You can use ACM to manage SSL/TLS certificates for your AWS-based websites and
applications.

- [[https://docs.aws.amazon.com/acm/index.html][AWS Certificate Manager Documentation]]

  - [[https://docs.aws.amazon.com/acm/latest/userguide/acm-overview.html][AWS Certifcate Manager User Guide]]

  - [[https://docs.aws.amazon.com/acm/latest/APIReference/Welcome.html][AWS Certifcate Manager API Reference]]

  - [[https://docs.aws.amazon.com/cli/latest/reference/acm/index.html][AWS Certifcate Manager API Documentation]]

** AWS Certificate Manager User Guide
“Welcome to the AWS Certificate Manager (ACM) service.”

ACM handles the complexity of creating and managing public SSL/TLS certificates
for your AWS based websites and applications.

- https://docs.aws.amazon.com/acm/latest/userguide/acm-overview.html


You can use public [[https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-request-public.html][certificates provided by ACM]] (ACM certificates).

ACM certificates can 

- secure multiple domain names and
- multiple names within a domain.


You can also use ACM to 

- create wildcard SSL certificates that
- can protect an unlimited number of subdomains.

*** Concepts

*** Best Practices

Best practices are recommendations that can help you use AWS Certificate
Manager (AWS Certificate Manager) more effectively.

- https://docs.aws.amazon.com/acm/latest/userguide/acm-bestpractices.html

**** AWS CloudFormation

**** Certificate Pinning

**** Domain Validation

**** Adding or Deleting Domain Names

**** Opting Out of Certificate Transparency Logging

**** Turn on AWS CloudTrail
Turn on CloudTrail logging before you begin using ACM.

CloudTrail enables you to monitor your AWS deployments by retrieving a history
of AWS API calls for your account, including API calls made via the AWS
Management Console, the AWS SDKs, the AWS Command Line Interface, and
higher-level AWS services.  ou can also identify which users and accounts
called the ACM APIs, the source IP address the calls were made from, and when
the calls occurred.  You can integrate CloudTrail into applications using the
API, automate trail creation for your organization, check the status of your
trails, and control how administrators turn CloudTrail logging on and off.

- [[https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-create-and-update-a-trail.html][Creating a Trai]]

- [[https://docs.aws.amazon.com/acm/latest/userguide/cloudtrail.html][Using AWS CloudTrail]]

*** Setting Up

The following topics discuss the steps you need to perform before using ACM.

- https://docs.aws.amazon.com/acm/latest/userguide/setup.html

**** Register a Domain Name

- Fully Qualified Domain Name (FQDN) ::

     the unique name of an organization or individual on the Internet followed
     by a top-level domain extension such as ~.com~ or ~.org~.

**** Set Up Your Website or Application

You can install your website on an Amazon EC2 Linux or Windows instance.

- [[https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html][Amazon Elastic Compute Cloud User Guide for Linux]]


To get your website up and running quickly on either Windows or Linux, see:

- [[https://docs.aws.amazon.com/acm/latest/userguide/#setup-website-linux][Linux Quickstart]]
- [[https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/install-LAMP.html][Tutorial: Installing a LAMP Web Server on Amazon Linux]]

*** Getting Started
- https://docs.aws.amazon.com/acm/latest/userguide/gs.html


{{{heading(Steps)}}}

- [[https://console.aws.amazon.com/acm/home][Sign into the AWS Management Console]]

- open the [[https://console.aws.amazon.com/acm/home][ACM console]]

- choose *Certificate Manager* in the left navigation pane

**** Request a Public Certificate
- https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-request-public.html


The following sections discuss how to use the ACM console or AWS CLI to request
a public ACM certificate.

***** Requesting a Public Certificate Using the Console

{{{heading(To request an ACM public certificate (console))}}}

1. In the ACM console, choose *Request a certificate*.

2. Choose *Request a public certificate* and *Request a certificate* to
   continue.

3. On the *Add domain names* page, type your domain name.

   You can use a fully qualified domain name (FQDN), or a bare or apex domain
   name.  You can also use an asterisk (*) as a wild card in the leftmost
   position to protect several site names in the same domain.  The wild card
   name will appear in the Subject field and the Subject Alternative Name
   extension of the ACM certificate.

4. To add another name, choose *Add another name to this certificate* and type
   the name in the text box.  This is useful for protecting both a bare or apex
   domain (such as example.com) and its subdomains such as *.example.com).
   Choose *Next*.

5. On the *Select validation method* page, choose either *DNS validation* or
   *Email* validation, depending on your needs.  If you use DNS validation, you
   simply write a =CNAME= record provided by ACM to your DNS configuration.
   Choose *Next*.

   - [[https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-validate-dns.html][Use DNS to Validate Domain Ownership]]

6. On the *Add tags* page, you can optionally tag your certificate.  Choose
   *Review*.

7. If the *Review* page contains correct information about your request, choose
   *Confirm and request*.  A confirmation page shows that your request is being
   processed and that certificate domains are being validated.

***** Requesting a Public Certificate Using the CLI

Use the request-certificate command to request a new public ACM certificate on
the command line.

#+begin_src sh :eval no
  aws acm request-certificate \
  --domain-name www.example.com \
  --validation-method DNS \
  --idempotency-token 1234 \
  --options CertificateTransparencyLoggingPreference=DISABLED
#+end_src

This command outputs the *Amazon Resource Name* (ARN) of your new public
certificate.

#+begin_src js :eval no
  {
      "CertificateArn": "arn:aws:acm:region:account:certificate/12345678-1234-1234-1234-123456789012"
  }
#+end_src

**** Use DNS to Validate Domain Ownership
- https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-validate-dns.html


Before the Amazon certificate authority (CA) can issue a certificate for your
site, AWS Certificate Manager (ACM) must verify that you own or control all of
the domain names that you specified in your request.

ACM uses =CNAME= (Canonical Name) records to validate that you own or control a
domain.  When you choose DNS validation, ACM provides you one or more =CNAME=
records to insert into your DNS database.

For example, if you request a certificate for the ~example.com~ domain with
~www.example.com~ as an additional name, ACM creates two =CNAME= records for
you.  Each record, created specifically for your domain and your account,
contains a name and a value.  The value is an alias that points to a domain
that ACM owns and which ACM uses to automatically renew your certificate.  You
add the =CNAME= records to your DNS database only once.  ACM automatically
renews your certificate as long as the certificate is in use and your =CNAME=
record remains in place.  In addition, if you use Amazon Route 53 to create
your domain, ACM can write the =CNAME= records for you.

**** To use DNS validation

1. Sign into the AWS Management Console and open the ACM console at
   https://console.aws.amazon.com/acm/home

2. On the *Request a certificate* page, type your domain name.

3. To add more domain names to the ACM Certificate, type other names as text
   boxes open beneath the name you just typed.

4. Choose *Next*.

5. Choose *DNS validation*.

6. Choose *Review and request*.  Verify that the domain name and validation
   method are correct.

7. Choose *Confirm and request*.

8. On the *Validation page*, retrieve the name of the =CNAME= record that must
   be added to your DNS database.  You can do this in two ways:

   - In the *Domain* section, expand your domain information and record the
     Name of the =CNAME= record.

   - Alternatively, choose *Export DNS configuration to a file* at the bottom
     of the *Validation* page.

9. The *Create record in Route 53* button appears if the following conditions
   are true:

   - You use Route 53 as your DNS provider.

   - You have permission to write to the zone hosted by Route 53.

   - Your FQDN has not already been validated.

10. Add the record from the console or the exported file to your database.[fn:6]
    - [[https://docs.aws.amazon.com/acm/latest/userguide/#dns-add-cname][Adding a CNAME to Your Database]].

    - If you want to add the record yourself, see [[https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-editing.html][Editing Resource Record Sets]]
      in the Route 53 Developer Guide.

11. After updating your DNS configuration, choose *Continue*.

**** Install ACM Certificates
- https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-install.html


You cannot use ACM to directly install your ACM Certificate on your AWS based
website or application.  You must use one of the services integrated with ACM.

**** Services Integrated with AWS Certificate Manager
- https://docs.aws.amazon.com/acm/latest/userguide/acm-services.html


AWS Certificate Manager supports a growing number of AWS services.  You cannot
install your ACM certificate or your private ACM PCA certificate directly on
your AWS based website or application.  You must use one of the following
services.

***** Elastic Load Balancing
In general, to serve secure content over SSL/TLS, load balancers require that
SSL/TLS certificates be installed on either the load balancer or the backend
Amazon EC2 instance.  ACM is integrated with Elastic Load Balancing to deploy
ACM certificates on the load balancer.
- [[https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-application-load-balancer.html][Create an Application Load Balancer]].

***** Amazon CloudFront
Amazon CloudFront is a web service that speeds up distribution of your dynamic
and static web content to end users by delivering your content from a worldwide
network of edge locations.

When an end user requests content that you're serving through CloudFront, the
user is routed to the edge location that provides the lowest latency.  This
ensures that content is delivered with the best possible performance.  If the
content is currently at that edge location, CloudFront delivers it immediately.
If the content is not currently at that edge location, CloudFront retrieves it
from the Amazon S3 bucket or web server that you have identified as the
definitive content source.

{{{heading(Serve Secure Content over SSL/TLS)}}}

To serve secure content over SSL/TLS, CloudFront requires that SSL/TLS
certificates be installed on either the CloudFront distribution or on the
backend content source.  ACM is integrated with CloudFront to deploy ACM
certificates on the CloudFront distribution.
- [[https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cnames-and-https-procedures.html#cnames-and-https-getting-certificates][Getting an SSL/TLS Certificate.]]

- See article on [[using-cloudfront-to-serve-https-s3-buckets][Using Cloudfront to serve HTTPS for an S3 Bucket]]

***** AWS Elastic Beanstalk
To choose a certificate, you must configure the load balancer for your
application in the Elastic Beanstalk console.
- [[https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/configuring-https-elb.html][Configuring Your Elastic Beanstalk Environment's Load Balancer to Terminate HTTPS]].

***** Amazon API Gateway
After you deploy your API to API Gateway, you can set up a custom domain name
to simplify access to it. To set up a custom domain name, you must provide an
SSL/TLS certificate.  You can use ACM to generate or import the certificate.

***** AWS CloudFormation
ACM certificates are included as a template resource, which means that AWS
CloudFormation can request ACM certificates that you can use with AWS services
to enable secure connections.
- [[https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-certificatemanager-certificate.html][AWS::CertificateManager::Certificate]].
** AWS Certificate Manager API Reference
“Welcome to the AWS Certificate Manager (ACM) API Reference.”

This guide provides descriptions, syntax, and usage examples for each ACM API
operation.

- https://docs.aws.amazon.com/acm/latest/APIReference/Welcome.html


Instead of using the ACM HTTP API directly, you can use one of the AWS SDKs or
command line tools to interact with the ACM API.  These tools are available for
a variety of programming languages and platforms.

- [[https://aws.amazon.com/tools/][Tools for Amazon Web Services]]


{{{heading(Signing API Requests)}}}

You must sign your HTTP API requests to ACM.  You must calculate the signature
yourself.  ACM requires signature version 4.

- [[https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html][Signature Version 4 Signing Process]]

** AWS Certficate Manager CLI Reference

- https://docs.aws.amazon.com/cli/latest/reference/acm/index.html#
** Using HTTPS with CloudFront
- https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https.html


For web distributions, you can configure CloudFront to require that viewers use
HTTPS to request your objects, so that connections are encrypted when
CloudFront communicates with viewers.  You also can configure CloudFront to use
HTTPS to get objects from your origin, so that connections are encrypted when
CloudFront communicates with your origin.

If you configure CloudFront to require HTTPS both to communicate with viewers
and to communicate with your origin, here's what happens when CloudFront
receives a request for an object:

1. A viewer submits an HTTPS request to CloudFront. There's some SSL/TLS
   negotiation here between the viewer and CloudFront. In the end, the viewer
   submits the request in an encrypted format.

2. If the object is in the CloudFront edge cache, CloudFront encrypts the
   response and returns it to the viewer, and the viewer decrypts it.

3. If the object is not in the CloudFront cache, CloudFront performs SSL/TLS
   negotiation with your origin and, when the negotiation is complete, forwards
   the request to your origin in an encrypted format.

4. Your origin decrypts the request, encrypts the requested object, and returns
   the object to CloudFront.

5. CloudFront decrypts the response, re-encrypts it, and forwards the object to
   the viewer. CloudFront also saves the object in the edge cache so that the
   object is available the next time it's requested.

6. The viewer decrypts the response.


The process works basically the same way whether your origin is an Amazon S3
bucket, MediaStore, or a custom origin such as an HTTP/S server.

*** Using CloudFront to serve HTTPS requests for an Amazon S3 Bucket
<<using-cloudfront-to-serve-https-s3-buckets>>
https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-https-requests-s3/


This article describes how to configure an Amazon CloudFront distribution to
serve HTTPS requests for my Amazon Simple Storage Service (Amazon S3).

1. Open the [[https://console.aws.amazon.com/cloudfront/][CloudFront console]].

2. Choose *Create Distribution*.

3. Under *Web*, choose *Get Started*.

4. For *Origin Domain Name*, you can either choose your S3 bucket's REST API
   endpoint from the drop-down menu, or you can enter your S3 bucket's website
   endpoint.  For more information, see:
   - [[https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteEndpoints.html#WebsiteRestEndpointDiff][Key Differences Between the Amazon Website and the REST API Endpoint]].

5. For *Viewer Protocol Policy*, choose HTTP and HTTPS.


{{{heading(Using a Custom Domain)}}}

If you're not using a custom domain with CloudFront, choose *Create
Distribution* to complete the process.  If you are using a custom domain,
follow these additional steps before you create the distribution:

1. For *Alternate Domain Names* (CNAMEs), type your custom domain.

2. For *SSL Certificate*, choose *Custom SSL Certificate*.  Then, choose the
   custom SSL certificate to assign to the distribution.  See:
   - [[https://aws.amazon.com/premiumsupport/knowledge-center/install-ssl-cloudfront/][How do I install SSL/TLS certificates on Amazon CloudFront?]]

3. Choose *Create Distribution*


Be sure to update the DNS for your domain to a CNAME record that points to the
CloudFront distribution's provided domain.  You can find your distribution's
domain name in the CloudFront console.

If you're using Amazon Route 53 as your DNS provider, you can create an alias
record (example.com Alias d111111abcdef8.cloudfront.net) to point the record to
your CloudFront distribution. If you're using another DNS provider, you can
create only a CNAME record (www.example.com CNAME
d111111abcdef8.cloudfront.net) to point to the distribution's domain.

Important: DNS standards require that an apex domain (example.com) use an
authoritative (A) record that maps to an IP address.  You can point your apex
domain to your CloudFront distribution only if you're using Route 53.  If
you're using another DNS provider, you must use a subdomain (www.example.com).

*** Requiring HTTPS for Communication Between Viewers and CloudFront
- https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-viewers-to-cloudfront.html


You can configure one or more cache behaviors in your CloudFront distribution
to require HTTPS for communication between viewers and CloudFront.  You also
can configure one or more cache behaviors to allow both HTTP and HTTPS, so that
CloudFront requires HTTPS for some objects but not for others.  The
configuration steps depend on which domain name you're using in object URLs:

- If you're using the domain name that CloudFront assigned to your
  distribution, such as d111111abcdef8.cloudfront.net

  - you change the Viewer Protocol Policy setting for one or more cache
    behaviors to require HTTPS communication.

  - In that configuration, CloudFront provides the SSL/TLS certificate.

- If you're using your own domain name, such as example.com

  - you need to change several CloudFront settings.

  - You also need to use an SSL/TLS certificate provided by AWS Certificate
    Manager (ACM)

*** Requiring HTTPS for Communication Between CloudFront and Your Custom Origin
<<requiring-https-custom-origin>>
- https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-cloudfront-to-custom-origin.html


If you want to require HTTPS for communication between CloudFront and your
custom origin, the steps you take depend on whether you're using the domain
name that CloudFront assigned to your distribution (like
d111111abcdef8.cloudfront.net) or your own alternate domain name (like
example.com).

If you use an Amazon S3 bucket as your origin and you configure your bucket as
a website endpoint, follow the guidance in this section.  If not, to use your
Amazon S3 bucket with HTTPS.
- see article on [[requiring-https-s3-origin][Requiring HTTPS S3 Origin]]


- Use the default CloudFront domain name

  - If you're using the domain name that CloudFront assigned to your
    distribution in the URLs for your objects (for example,
    ~https://d111111abcdef8.cloudfront.net/logo.jpg~),

  - you can require HTTPS by following the procedures in this topic to do the
    following:

    - Change the Origin Protocol Policy setting for specific origins in your
      distribution

    - Install an SSL/TLS certificate on your custom origin server (this isn't
      required when you use an Amazon S3 origin)

- Use an alternate domain name

  - Instead of using the default domain name with your distribution, you can
    add an alternate domain name that's easier to work with, like example.com.

  - To require HTTPS for communication when you use an alternate domain name,
    follow the steps and guidance in [[https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-alternate-domain-names.html][Using Alternate Domain Names and HTTPS.]]

*** Requiring HTTPS for Communication Between CloudFront and Your Amazon S3 Origin
<<requiring-https-s3-origin>>
- https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-cloudfront-to-s3-origin.html


When your origin is an Amazon S3 bucket, your options for using HTTPS for
communications with CloudFront depend on how you're using the bucket.

- Website endpoint :: If your Amazon S3 bucket is configured as a website
     endpoint, you can't configure CloudFront to use HTTPS to communicate with
     your origin because Amazon S3 doesn't support HTTPS connections in that
     configuration.

- Bucket supporting HTTPS :: When your origin is an Amazon S3 bucket that
     supports HTTPS communication, CloudFront always forwards requests to S3 by
     using the protocol that viewers used to submit the requests.  The default
     setting for the Origin Protocol Policy setting is Match Viewer and can't
     be changed.

- Viewer Protocol Policy :: If you want to require HTTPS for communication
     between CloudFront and Amazon S3, you must change the value of Viewer
     Protocol Policy to Redirect HTTP to HTTPS or HTTPS Only.

- SSL/TLS Certificates :: When you use HTTPS with an Amazon S3 bucket that
     supports HTTPS communication, Amazon S3 provides the SSL/TLS certificate,
     so you don't have to.


{{{heading(Configure CloudFront to require HTTPS to your Amazon S3 origin)}}}

1. Open the CloudFront console.

2. In the top pane of the CloudFront console, choose the ID for the
   distribution that you want to update.

3. On the *Behaviors* tab, choose the cache behavior that you want to update,
   and then choose *Edit*.

4. Specify one of the following values for *Viewer Protocol Policy*:

   - Redirect HTTP to HTTPS

     Viewers can use both protocols, but HTTP requests are automatically
     redirected to HTTPS requests.  CloudFront returns HTTP status code 301
     (Moved Permanently) along with the new HTTPS URL.  The viewer then
     resubmits the request to CloudFront using the HTTPS URL.

     CloudFront doesn't redirect DELETE, OPTIONS, PATCH, POST, or PUT requests
     from HTTP to HTTPS.  If you configure a cache behavior to redirect to
     HTTPS, CloudFront responds to HTTP DELETE, OPTIONS, PATCH, POST, or PUT
     requests for that cache behavior with HTTP status code 403 (Forbidden).

     When a viewer makes an HTTP request that is redirected to an HTTPS
     request, CloudFront charges for both requests. For the HTTP request, the
     charge is only for the request and for the headers that CloudFront returns
     to the viewer. For the HTTPS request, the charge is for the request, and
     for the headers and the object returned by your origin.

   - HTTPS Only

     Viewers can access your content only if they're using HTTPS.  If a viewer
     sends an HTTP request instead of an HTTPS request, CloudFront returns HTTP
     status code 403 (Forbidden) and does not return the object.

5. Choose Yes, Edit.

6. Repeat steps 3 through 5 for each additional cache behavior that you want to
   require HTTPS for between viewers and CloudFront, and between CloudFront and
   S3.

7. Confirm the following before you use the updated configuration in a
   production environment:

   - The path pattern in each cache behavior applies only to the requests that
     you want viewers to use HTTPS for.

   - The cache behaviors are listed in the order that you want CloudFront to
     evaluate them in. For more information, see [[https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesPathPattern][Path Pattern]].

   - The cache behaviors are routing requests to the correct origins.
*** TODO Article---Continually Enhancing Domain Security on Amazon CloudFront
- https://aws.amazon.com/blogs/networking-and-content-delivery/continually-enhancing-domain-security-on-amazon-cloudfront/
*** TODO Article---Logging and Monitoring in Amazon S3
- https://docs.aws.amazon.com/AmazonS3/latest/dev/s3-incident-response.html
** TODO Amazon S3 Security
- https://docs.aws.amazon.com/AmazonS3/latest/dev/security.html
** TODO Redirecting Internet Traffic to Another Domain and Redirecting HTTP Requests to HTTPS
- https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/tutorial-redirecting-dns-queries.html

* Amazon S3 Security
- https://docs.aws.amazon.com/AmazonS3/latest/dev/security.html


{{{heading(Shared Responsibility Model)}}}

#+cindex:shared responsibility model
Security is a /shared responsibility/ between AWS and you.  The *shared
responsibility model* describes this as:

#+cindex:security of the cloud
#+cindex:security in the cloud

- security /of the cloud/ :: AWS is responsible for protecting the
     infrastructure that runs AWS services in the AWS Cloud.  AWS also provides
     you with services that you can use securely.

- security /in the cloud/ :: Your responsibility is determined by the AWS
     service that you use.  You are also responsible for other factors
     including the sensitivity of your data, your organization’s requirements,
     and applicable laws and regulations.


This documentation will help you understand how to apply the shared
responsibility model when using Amazon S3.

** Data Protection in Amazon S3
- https://docs.aws.amazon.com/AmazonS3/latest/dev/DataDurability.html


{{{heading(Durable Storage Infrastructure)}}}

Amazon S3 provides a highly durable storage infrastructure designed for
mission-critical and primary data storage.

- Objects are /redundantly stored/ on multiple devices across multiple
  facilities in an Amazon S3 Region.

- Amazon S3 PUT and PUT Object copy operations /synchronously store/ your data
  across multiple facilities.

- Amazon S3 maintains their durability by quickly /detecting and repairing/ any
  /lost redundancy/.

- Designed to provide 99.999999999% durability and 99.99% availability of
  objects

- Designed to sustain the concurrent loss of data in two facilities.


{{{heading(Data Versioning)}}}

Amazon S3 further protects your data using /versioning/.  You can use
versioning to preserve, retrieve, and restore every version of every object
that is stored in your Amazon S3 bucket.

- With versioning, you can easily recover from both unintended user actions and
  application failures.

- By default, requests retrieve the most recently written version.

- You can retrieve older versions of an object by specifying a version of the
  object in a request.

*** Internetwork Traffic Privacy
- https://docs.aws.amazon.com/AmazonS3/latest/dev/inter-network-traffic-privacy.html


This topic describes how Amazon S3 secures connections from the service to
other locations.

{{{heading(Traffic Between Service and On-Premises Clients and Applications)}}}

You have two connectivity options between your private network and AWS:

- An AWS Site-to-Site VPN connection.

- An AWS Direct Connect connection. 


Access to Amazon S3 via the network is through /AWS published APIs/.

Clients must support /Transport Layer Security (TLS)/ 1.0.  We recommend TLS
1.2 or above.

Clients must also support /cipher suites/ with Perfect Forward Secrecy (PFS),
such as Ephemeral Diffie-Hellman (DHE) or Elliptic Curve Diffie-Hellman
Ephemeral (ECDHE).

Additionally, you must /sign requests/ using an *access key ID* and a *secret
access key* that are associated with an IAM principal;

or you can use the /AWS Security Token Service (STS)/ to generate *temporary
security credentials* to sign requests.

{{{heading(Traffic Between AWS Resources in the Same Region)}}}

{{{subheading(Virtual Private Cloud Endpoint for S3)}}}

An /Amazon Virtual Private Cloud (Amazon VPC) endpoint for Amazon S3/ is a
logical entity within a VPC that allows connectivity only to Amazon S3.

- The Amazon VPC routes requests to Amazon S3 and routes responses back to the
  VPC.

- see [[https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html][VPC Endpoints]]

- see [[https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies-vpc-endpoint.html][Example Bucket Policies for VPC Endpoints for Amazon S3]]

*** Protecting Data Using Encryption
- https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html


/Data protection/ refers to:

- protecting data while in-transit (as it travels to and from Amazon S3); and

- at rest (while it is stored on disks in Amazon S3 data centers).


You can protect data in transit using

- /Secure Sockets Layer (SSL)/ or

- /client-side encryption/.


You have the following options for protecting data at rest in Amazon S3:

- Server-Side Encryption :: Request Amazon S3 to encrypt your object before
     saving it on disks in its data centers and then decrypt it when you
     download the objects.

- Client-Side Encryption :: Encrypt data client-side and upload the encrypted
     data to Amazon S3.  In this case, you manage the encryption process, the
     encryption keys, and related tools.

**** TODO Protecting Data Using Server-Side Encryption
- https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html

**** TODO Protecting Data Using Client-Side Encryption
- https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html

*** Identity and Access Management in Amazon S3
- https://docs.aws.amazon.com/AmazonS3/latest/dev/s3-access-control.html


{{{heading(Grant Permissions to Others by Writing an Access Policy)}}}

#+cindex:access policy
By default, all Amazon S3 resources—buckets, objects, and related subresources
(for example, lifecycle configuration and website configuration) are private:
only the resource owner, an AWS account that created it, can access the
resource.  The resource owner can optionally grant /access permissions/ to
others by writing an /access policy/.

Amazon S3 offers access policy options broadly categorized as:

- resource-based policies :: Access policies you attach to your resources
     (buckets and objects) are referred to as resource-based policies.  For
     example, bucket policies and access control lists (ACLs) are
     resource-based policies.

- user policies :: You can also attach access policies to users in your
                   account.


You may choose to use resource-based policies, user policies, or some
combination of these to manage permissions to your Amazon S3 resources. 

**** Introduction to Managing Access to Amazon S3 Resources

{{{heading(Overview of Managing Access)}}}

#+cindex:access
#+cindex:permissions
When granting permissions, you decide 

- who is getting permissions;
- which Amazon S3 resources they are getting permissions for; and
- specific actions you want to allow on those resources.


{{{subheading(Amazon S3 Resources: Buckets and Objects)}}}

#+cindex:resources
In Amazon Web Services (AWS), a /resource/ is an entity that you can work with.
In Amazon S3, *buckets* and *objects* are the resources, and both have
associated subresources.

{{{subheading(Subresources)}}}

#+cindex:subresources
Bucket /subresources/ include the following:

- lifecycle :: Stores lifecycle configuration information

- website :: Stores website configuration information if you configure your
             bucket for website hosting;

             see [[https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html][Hosting a Static Website on Amazon S3]]

- versioning :: Stores versioning configuration

- policy and acl :: Store access permission information for the bucket.

- cors :: Supports configuring your bucket to allow cross-origin requests

- logging :: Enables you to request Amazon S3 to save bucket access logs.


Object /subresources/ include the following:

- acl :: Stores a list of access permissions on the object

- restore :: Supports temporarily restoring an archived object


{{{subheading(Amazon S3 Bucket and Object Ownership)}}}

Buckets and objects are Amazon S3 resources.  By default, only the resource
owner can access these resources.  The resource owner refers to the AWS account
that creates the resource.

{{{subheading(Ownership and Request Authentication)}}}

All requests to a bucket are either:

#+cindex:authenticated requests
- authenticated :: Authenticated requests must include a signature value that
                   authenticates the request sender.  AWS recommends that you
                   don't use the AWS account root user credentials to make
                   authenticated requests.  Instead, create an IAM user and
                   grant that user full access.  We refer to these users as
                   administrator users.

#+cindex:unauthenticated requests
- unauthenticated :: unauthenticated requests do not include a signature value
     authenticating the request sender; a bucket owner can allow
     unauthenticated requests.  All unauthenticated requests are made by the
     anonymous user.  This user is represented in access control lists (ACLs)
     by the specific canonical user:
     : 65a011a29cdf8ec533ec3d1ccaae921c

     If an object is uploaded to a bucket through an unauthenticated request,
     the anonymous user owns the object.  The default object ACL grants
     FULL_CONTROL to the anonymous user as the object's owner.  Therefore,
     Amazon S3 allows unauthenticated requests to retrieve the object or modify
     its ACL.

     #+cindex:Block Public Access
     To prevent objects from being modified by the anonymous user, we recommend
     that you do not implement bucket policies that allow anonymous public
     writes to your bucket or use ACLs that allow the anonymous user write
     access to your bucket.  You can enforce this recommended behavior by using
     Amazon S3 Block Public Access.

     - see [[https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html][Using Amazon S3 Block Public Access]]

     - see [[https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html][Access Control List (ACL) Overview]].


{{{subheading(Resource Operations)}}}

#+cindex:resource operations
Amazon S3 provides a set of operations to work with the Amazon S3 resources.

For a list of available operations, go to:
- [[https://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketOps.html][Operations on Buckets]]

  *Amazon S3 REST API Introduction*

  It describes various API operations, related request and response structures,
  and error codes.

  Requests to Amazon S3 can be authenticated or anonymous.

  - Authenticated access :: requires credentials that AWS can use to
       authenticate your requests.  When making REST API calls directly from
       your code, you create a signature using valid credentials and include
       the signature in your request.

       - see [[https://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-authenticating-requests.html][Authenticating Requests]]

  - Use SDK's instead :: 

       Making REST API calls directly from your code can be cumbersome.  It
       requires you to write the necessary code to calculate a valid signature
       to authenticate your requests.  We recommend the following alternatives
       instead:

       - Use the AWS SDKs to send your requests.  With this option, you don't
         need to write code to calculate a signature for request authentication
         because the SDK clients authenticate your requests by using access
         keys that you provide.  Unless you have a good reason not to, you
         should always use the AWS SDKs.

         - see [[https://aws.amazon.com/code][Sample Code and Libraries]]

  - Use the CLI instead ::

       For information about setting up the AWS CLI and example Amazon S3
       commands see the following topics:

       - [[https://docs.aws.amazon.com/AmazonS3/latest/dev/setup-aws-cli.html][Set Up the AWS CLI]]

       - Using Amazon S3 with the AWS Command Line Interface

  - Use Proper Permisions ::

       You can have valid credentials to authenticate your requests, but unless
       you have /permissions/ you cannot create or access Amazon S3 resources.
       For example, you must have permissions to create an S3 bucket or get an
       object from your bucket.  If you use root credentials of your AWS
       account, you have all the permissions.  However, using root credentials
       is not recommended.  Instead, we recommend that you create IAM users in
       your account and manage user permissions.

       - see [[https://docs.aws.amazon.com/AmazonS3/latest/dev/s3-access-control.html][Managing Access Permissions to Your Amazon S3 Resources]]

- [[https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectOps.html][Operations on Objects]]


{{{subheading(Managing Access to Resources)}}}

#+cindex:manage access
#+cindex:access policy
#+cindex:permission, grant
/Managing access/ refers to granting others (AWS accounts and users) permission
to perform the resource operations by writing an *access policy*.

#+cindex:PUT object
- For example, you can grant =PUT Object= permission to a user in an AWS
  account so the user can upload objects to your bucket.


 In addition to granting permissions to individual users and accounts, you can
 grant permissions to everyone (also referred as anonymous access) or to all
 authenticated users (users with AWS credentials).

 #+cindex:GET object
- For example, if you configure your bucket as a website, you may want to make
  objects public by granting the =GET Object= permission to everyone.


{{{subheading(Access Policy Options)}}}

#+cindex:access policy
/Access policy/ describes who has access to what.  You can associate an access
policy with a *resource* (bucket and object) or a *user*.  Accordingly, you can
categorize the available Amazon S3 access policies as follows:

#+cindex:resource policies
#+cindex:access control lists (ACLs)
#+cindex:ACL's, access control lists
- Resource-based policies :: Bucket policies and access control lists (ACLs)
     are resource-based because you attach them to your Amazon S3 resources.

     - ACL :: Each bucket and object has an ACL associated with it.

              An /ACL/ is a list of grants identifying grantee and permission
              granted.  You use ACLs to grant basic read/write permissions to
              other AWS accounts.  ACLs use an Amazon S3–specific XML schema.

     - Bucket policy :: For your bucket, you can add a bucket policy to grant
                        other AWS accounts or IAM users permissions for the
                        bucket and the objects in it.

#+cindex:user policies
- User policies :: You can use IAM to manage access to your Amazon S3
                   resources.  You can create IAM /users/, /groups/, and
                   /roles/ in your account and attach /access policies/ to them
                   granting them access to AWS resources, including Amazon S3.

                   The following is an example of a user policy.  The example
                   policy allows the associated user that it's attached to
                   perform six different Amazon S3 actions on a bucket and the
                   objects in it. You can attach this policy to a specific IAM
                   user, group, or role.

  #+begin_src js :eval never
    {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Sid": "ExampleStatement1",
                "Effect": "Allow",
                "Action": [
                    "s3:PutObject",
                    "s3:GetObject",
                    "s3:ListBucket",
                    "s3:DeleteObject",
                    "s3:GetBucketLocation"
                ],
                "Resource": [
                     "arn:aws:s3:::examplebucket/*",
                     "arn:aws:s3:::examplebucket"
                ]
            },
            {
                "Sid": "ExampleStatement2",
                "Effect": "Allow",
                "Action": "s3:ListAllMyBuckets",
                "Resource": "*"
            }
        ]
    }
  #+end_src

  When Amazon S3 receives a request, it must evaluate all the access policies
                   to determine whether to authorize or deny the request.

  - see [[https://docs.aws.amazon.com/AmazonS3/latest/dev/how-s3-evaluates-access-control.html][How Amazon S3 Authorizes a Request]].

{{{heading(Access Analyzer for S3)}}}

#+cindex:Access Analyzer for S3
On the Amazon S3 console, you can use *Access Analyzer for S3* to review all
buckets that have bucket access control lists (ACLs) or bucket policies that
grant public or shared access.  Access Analyzer for S3 alerts you to buckets
that are configured to allow access to anyone on the internet or other AWS
accounts, including AWS accounts outside of your organization.  For each public
or shared bucket, you receive findings that report the source and level of
public or shared access.

Access Analyzer for S3 is available at no extra cost on the Amazon S3
console. Access Analyzer for S3 is powered by AWS Identity and Access
Management (IAM) Access Analyzer.  To use Access Analyzer for S3 on the Amazon
S3 console, you must visit the IAM console and enable IAM Access Analyzer on a
per-Region basis.

- see [[https://docs.aws.amazon.com/AmazonS3/latest/user-guide/access-analyzer.html][Using Access Analyzer for S3]]


{{{heading(Which Access Control Method Should I Use?)}}}

With the options available to write an access policy, the following questions
arise:

- When should I use which access control method?  For example, to grant bucket
  permissions, should I use a bucket policy or bucket ACL?  I own a bucket and
  the objects in the bucket.  Should I use a resource-based access policy or an
  IAM user policy?  If I use a resource-based access policy, should I use a
  bucket policy or an object ACL to manage object permissions?

- If I grant access by using a combination of these access policy options, how
  does Amazon S3 determine if a user has permission to perform a requested
  operation?

{{{heading(How Amazon S3 Authorizes a Request)}}}

When Amazon S3 receives a request---for example, a bucket or an object
operation:

*NOTE:* To perform a specific operation on a resource, an IAM principal needs
permission from /both/ the *parent AWS account* to which it belongs and the
*AWS account that owns* the resource.  In addition, a bucket owner (who pays
the bill) can /explicitly deny access/ to objects in the bucket regardless of
who owns it.  The bucket owner can also delete any object in the bucket.

- Permissions :: it first verifies that the requester has the necessary
                 permissions.  Amazon S3 evaluates all the relevant access
                 policies, user policies, and resource-based policies (bucket
                 policy, bucket ACL, object ACL) in deciding whether to
                 authorize the request.

  - IAM principal and Parent Permissions :: If the requester is an IAM
       principal, Amazon S3 must determine if the *parent AWS account* to which
       the principal belongs has granted the principal necessary permission to
       perform the operation.

  - Bucket operation and Resource Owner permissions :: if the request is for a
       bucket operation, such as a request to list the bucket content, Amazon
       S3 must verify that the *bucket owner* has granted permission for the
       requester to perform the operation.

  - Non-owner permissions :: If the request is for an operation on an object
       that the bucket owner does not own, in addition to making sure the
       requester has permissions from the object owner, Amazon S3 must also
       check the bucket policy to ensure the bucket owner has not set explicit
       deny on the object.


{{{subheading(Specific Steps to Determine Permissions)}}}

In order to determine whether the requester has permission to perform the
specific operation, Amazon S3 does the following, in order, when it receives a
request:

1. Converts all the /relevant access policies/ (*user policy*, *bucket policy*,
   *ACLs*) at run time into a set of policies for evaluation.

2. Evaluates the resulting set of policies in the following steps.  In each
   step, Amazon S3 evaluates a subset of policies in a /specific context/,
   based on the /context authority/.

   - User context ::

                     In the /user context/, the parent account to which the
                     user belongs is the *context authority*.  Amazon S3
                     evaluates a subset of policies owned by the parent
                     account.  This subset includes the *user policy* that the
                     parent attaches to the user.

                     If the parent also owns the resource in the request
                     (bucket, object), Amazon S3 also evaluates the
                     corresponding *resource policies* (bucket policy, bucket
                     ACL, and object ACL) at the same time.

                     A user must have permission from the parent account to
                     perform the operation.

                     This step applies only if the request is made by a user in
                     an AWS account.  If the request is made using root
                     credentials of an AWS account, Amazon S3 skips this step.

   - Bucket context ::

                       In the /bucket context/, Amazon S3 evaluates policies
                       owned by the AWS account that owns the bucket.

                       If the request is for a bucket operation, the requester
                       must have permission from the bucket owner.

                       If the request is for an object, Amazon S3 evaluates all
                       the policies owned by the bucket owner to check if the
                       bucket owner has not explicitly denied access to the
                       object.  If there is an explicit deny set, Amazon S3
                       does not authorize the request.

   - Object context ::

                       If the request is for an object, Amazon S3 evaluates the
                       subset of policies owned by the object owner.

{{{heading(How Amazon S3 Authorizes a Request for a Bucket Operation)}}}

- https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-auth-workflow-bucket-operation.html


#+caption:A graphical illustration of the Context-Based Evaluation for bucket operation
#+name:context-based-evaluation
[[file:resources/AccessControlAuthorizationFlowBucketResource.png]]

- https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-auth-workflow-bucket-operation.html

  The foregoing link contains numerous other graphical illustrations of example
  permision evaluations for bucket operations.

- https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-auth-workflow-object-operation.html

  The foregoing link contains numerous other graphical illustrations of example
  permission evaluations for object operations.

{{{heading(Guidelines for Using the Available Access Policy Options)}}}

- https://docs.aws.amazon.com/AmazonS3/latest/dev/access-policy-alternatives-guidelines.html


Amazon S3 supports:

- resource-based policies :: 
  - bucket policies
  - bucket ACLs
  - object ACLs

- user policies ::


{{{noindent}}}to manage access to your Amazon S3 resources.


{{{subheading(When to Use an ACL-based Access Policy (Bucket and Object ACLs))}}}

Both buckets and objects have associated /ACLs/ that you can use to grant
permissions.  The following sections describe scenarios for using object ACLs
and bucket ACLs.

{{{subheading(When to Use an Object ACL)}}}

In addition to an object ACL, there are other ways an object owner can manage
object permissions. For example:

- If the AWS account that owns the object also owns the bucket, then it can
  write a /bucket policy/ to manage the object permissions.

- If the AWS account that owns the object wants to grant permission to a user
  in its account, it can use a /user policy/.


So when do you use object ACLs to manage object permissions?  The following are
the scenarios when you use object ACLs to manage object permissions.

- An object ACL is the only way to manage access to objects not owned by the
  bucket owner.

  An AWS account that owns the bucket can grant another AWS account permission
  to upload objects.  The bucket owner does not own these objects.  The AWS
  account that created the object must grant permissions using object ACLs.

  *NOTE*: A bucket owner cannot grant permissions on objects it does not own.
  For example, a bucket policy granting object permissions applies only to
  objects owned by the bucket owner.  However, the bucket owner, who pays the
  bills, can write a bucket policy to *deny access* to any objects in the
  bucket, regardless of who owns it.  The bucket owner can also *delete* any
  objects in the bucket.

- Permissions vary by object and you need to manage permissions at the object
  level.

  You can write a single policy statement granting an AWS account read
  permission on millions of objects with a specific key name prefix.  For
  example, grant read permission on objects starting with key name prefix
  "logs".

  However, if your access permissions vary by object, granting permissions to
  individual objects using a bucket policy may not be practical. Also the
  bucket policies are limited to 20 KB in size.  In this case, you may find
  using object ACLs a suitable alternative.

- Object ACLs control only object-level permissions.

  There is a single bucket policy for the entire bucket, but object ACLs are
  specified per object.

  An AWS account that owns a bucket can grant another AWS account permission to
  manage access policy.  It allows that account to change anything in the
  policy.  To better manage permissions, you may choose not to give such a
  broad permission, and instead grant only the READ-ACP and WRITE-ACP
  permissions on a subset of objects.  This limits the account to manage
  permissions only on specific objects by updating individual object ACLs.


{{{subheading(When to Use a Bucket ACL)}}}

The only recommended use case for the bucket ACL is to grant write permission
to the Amazon S3 Log Delivery group to write access log objects to your bucket.
If you want Amazon S3 to deliver access logs to your bucket, you will need to
grant write permission on the bucket to the Log Delivery group.  The only way
you can grant necessary permissions to the Log Delivery group is via a bucket
ACL.

{{{subheading(When to Use a Bucket Policy)}}}

If an AWS account that owns a bucket wants to grant permission to users in its
account, it can use either a bucket policy or a user policy.  But in the
following scenarios, you will need to use a bucket policy.

- *You want to manage cross-account permissions for all Amazon S3 permissions*

  You can use ACLs to grant cross-account permissions to other accounts, but
  ACLs support only a finite set of permission ([[https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#permissions][What Permissions Can I Grant?]]);
  these don't include all Amazon S3 permissions.

  - For example, you cannot grant permissions on bucket subresources using an
    ACL.

  Although both bucket and user policies support granting permission for all
  Amazon S3 operations, the user policies are for managing permissions for
  users in your account.  For cross-account permissions to other AWS accounts
  or users in another account, you must use a bucket policy.


{{{subheading(When to Use a User Policy)}}}

In general, you can use either a user policy or a bucket policy to manage
permissions.  You may choose to manage permissions by creating users and
managing permissions individually by attaching policies to users (or user
groups), or you may find that resource-based policies, such as a bucket policy,
work better for your scenario.

AWS Identity and Access Management (IAM) enables you to create multiple users
within your AWS account and manage their permissions via user policies.  An IAM
user must have permissions from the parent account to which it belongs, and
from the AWS account that owns the resource the user wants to access. The
permissions can be granted as follows:

- Permission from the parent account ::

     The parent account can grant permissions to its user by attaching a /user
     policy/.

- Permission from the resource owner ::

     The resource owner can grant permission to either:

     - the IAM user (using a bucket policy); or

     - the parent account (using a bucket policy, bucket ACL, or object ACL).

{{{heading(Example Walkthroughs: Managing Access to Your Amazon S3 Resources)}}}

- https://docs.aws.amazon.com/AmazonS3/latest/dev/example-walkthroughs-managing-access.html


This topic provides the following introductory walkthrough examples for
granting access to Amazon S3 resources.  These examples use the AWS Management
Console to create resources (buckets, objects, users) and grant them
permissions.  The examples then show you how to verify permissions using the
command line tools, so you don't have to write any code.  We provide commands
using both the AWS Command Line Interface (CLI) and the AWS Tools for Windows
PowerShell.

{{{subheading(Example 1: Bucket Owner Granting Its Users Bucket Permissions)}}}

- [[https://docs.aws.amazon.com/AmazonS3/latest/dev/example-walkthroughs-managing-access-example1.html][Example 1]]

The IAM users you create in your account have no permissions by default.  In
this exercise, you grant a user permission to perform bucket and object
operations.

{{{subheading(Example 2: Bucket Owner Granting Cross-Account Bucket
Permissions)}}}

In this exercise, a bucket owner, Account A, grants cross-account permissions
to another AWS account, Account B. Account B then delegates those permissions
to users in its account.

- [[https://docs.aws.amazon.com/AmazonS3/latest/dev/example-walkthroughs-managing-access-example2.html][Example 2]]

{{{subheading(Managing object permissions when the object and bucket owners are
not the same)}}}

The example scenarios in this case are about a bucket owner granting object
permissions to others, but not all objects in the bucket are owned by the
bucket owner.  What permissions does the bucket owner need, and how can it
delegate those permissions?

{{{subheading(Example 3: Bucket Owner Granting Its Users Permissions to Objects
It Does Not Own)}}}

In this exercise, the bucket owner first gets permissions from the object
owner.  The bucket owner then delegates those permissions to users in its own
account.

{{{subheading(Example 4: Bucket Owner Granting Cross-account Permission to
Objects It Does Not Own)}}}

After receiving permissions from the object owner, the bucket owner cannot
delegate permission to other AWS accounts because cross-account delegation is
not supported (see Permission Delegation).  Instead, the bucket owner can
create an IAM role with permissions to perform specific operations (such as get
object) and allow another AWS account to assume that role.  Anyone who assumes
the role can then access objects.  This example shows how a bucket owner can
use an IAM role to enable this cross-account delegation.

{{{heading(Security Best Practices)}}}

{{{subheading(Ensure Amazon S3 buckets are not publicly accessible)}}}

{{{subheading(Implement least privilege access)}}}

{{{subheading(Use IAM roles)}}}

{{{subheading(Enable MFA (Multi-Factor Authentication) Delete)}}}

{{{subheading(Identify and audit all your Amazon S3 buckets)}}}

{{{subheading(Monitor AWS security advisories)}}}

**** Amazon S3 Resource Access Options
You can use the following topics to get more information about specific access
policy options:

{{{heading(Using Bucket Policies and User Policies)}}}

{{{heading(Managing Access with ACLs)}}}

{{{heading(Using Amazon S3 Block Public Access)}}}

** Identity and Access Management in Amazon S3

** Logging and Monitoring in Amazon S3

** Compliance and Validation for Amazon S3

** Resilience in Amazon S3

** Infrastructure Security in Amazon S3

** Configuration and Vulnerability Analysis in Amazon S3

** Security Best Practices for Amazon S3

The following security best practices also address data protection in Amazon
S3:

*** Implement server-side encryption

*** Enforce encryption of data in transit

*** Consider using Amazon Macie with Amazon S3

*** Identify and audit all your Amazon S3 buckets

* Security in Amazon Virtual Private Cloud
- https://docs.aws.amazon.com/vpc/latest/userguide/security.html


This documentation helps you understand how to apply the shared responsibility
model when using Amazon VPC.

- The following topics show you how to configure Amazon VPC to meet your
  security and compliance objectives.

- You also learn how to use other AWS services that help you to monitor and
  secure your Amazon VPC resources.

** Data Protection in Amazon Virtual Private Cloud

** Identity and Access Management for Amazon VPC

** Logging and Monitoring for Amazon VPC

** Resilience in Amazon Virtual Private Cloud

** Compliance Validation for Amazon Virtual Private Cloud

* Amazon S3 Server Access Logging
- [[https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html]]


Server access logging provides detailed records for the requests that are made
to a bucket.  Access log information can be useful in security and access
audits.

Each access log record provides details about a single access request, such as
the requester, bucket name, request time, request action, response status, and
an error code, if relevant.

{{{heading(Pricing for Server Access Logging)}}}

There is no extra charge for enabling server access logging on an Amazon S3
bucket.

However, any log files that the system delivers to you accrue the usual charges
for storage. (You can delete the log files at any time.)

No data transfer charges are assessed for log file delivery, but access to the
delivered log files is charged the same as any other data transfer.

** Enable Server Access Logging

By default, logging is disabled.  When logging is enabled, logs are saved to a
bucket in the same AWS Region as the source bucket.

{{{heading(Source Bucket and Target Bucket)}}}

- Turn on the log delivery by adding *logging configuration* on the bucket for
  which you want Amazon S3 to deliver access logs.  We refer to this bucket as
  the /source bucket/.

- Grant the *Amazon S3 Log Delivery group write permission* on the bucket where
  you want the access logs saved.  We refer to this bucket as the /target
  bucket/.

- Both the source and target buckets must be owned by the same AWS account, and
  the buckets must both be in the same Region.


To turn on log delivery, you provide the following logging configuration
information:

- The name of the /target bucket/ where you want Amazon S3 to save the access
  logs as objects.  You can have logs delivered to any bucket that you own that
  is in the same Region as the source bucket, including the source bucket
  itself.

  We recommend that you save access logs in a different bucket so that you can
  easily manage the logs.  If you choose to save access logs in the source
  bucket, we recommend that you specify a prefix for all log object keys so
  that the object names begin with a common string and the log objects are
  easier to identify.

  When your source bucket and target bucket are the same bucket, additional
  logs are created for the logs that are written to the bucket.  This behavior
  might not be ideal for your use case because it could result in a small
  increase in your storage billing.  In addition, the extra logs about logs
  might make it harder to find the log that you're looking for.

- (Optional) A /prefix/ for Amazon S3 to assign to all log object keys.  The
  prefix makes it simpler for you to locate the log objects.

  For example, if you specify the prefix value ~logs/~, each log object that
  Amazon S3 creates begins with the logs/ prefix in its key, as in this
  example:

  : logs/2013-11-01-21-32-16-E568B2907131C0C0

  The key prefix can help when you delete the logs.  For example, you can set a
  lifecycle configuration rule for Amazon S3 to delete objects with a specific
  key prefix.
  - see [[https://docs.aws.amazon.com/AmazonS3/latest/dev/deleting-log-files-lifecycle.html][Deleting Amazon S3 Log Files]].

- (Optional) /Permissions/ so that others can access the generated logs.  By
  default, the bucket owner always has full access to the log objects.  You can
  optionally grant access to other users.

** Log Object Key Format

Amazon S3 uses the following object key format for the log objects it uploads
in the target bucket:

: TargetPrefixYYYY-mm-DD-HH-MM-SS-UniqueString 

The =UniqueString= component of the key is there to prevent overwriting of
files.  It has no meaning, and log processing software should ignore it.

** How Logs Are Delivered

Amazon S3 periodically collects access log records, consolidates the records in
log files, and then uploads log files to your target bucket as log objects.  If
you enable logging on multiple source buckets that identify the same target
bucket, the target bucket will have access logs for all those source buckets.
However, each log object reports access log records for a specific source
bucket.

{{{heading(Log Delivery Group Write Permission)}}}

Amazon S3 uses a special log delivery account, called the Log Delivery group,
to write access logs. These writes are subject to the usual access control
restrictions. You must grant the Log Delivery group write permission on the
target bucket by adding a /grant entry/ in the bucket's *access control list
(ACL)*.  If you use the Amazon S3 console to enable logging on a bucket, the
console both enables logging on the source bucket and updates the ACL on the
target bucket to grant write permission to the Log Delivery group.

** Best Effort Server Log Delivery

Server access log records are delivered on a best effort basis.  The
completeness and timeliness of server logging is not guaranteed.  The log
record for a particular request might be delivered long after the request was
actually processed, or it might not be delivered at all.  The purpose of server
logs is to give you an idea of the nature of traffic against your bucket.  It is
rare to lose log records, but server logging is not meant to be a complete
accounting of all requests.

* Essentials of Cybersecurity
:PROPERTIES:
:source:   UWashingtonX
:uri:      https://www.edx.org/professional-certificate/uwashingtonx-essentials-cybersecurity
:END:
Professional Certificate Program

A series of career-oriented courses to develop in-demand skills.

An introduction to the expanding world of cybersecurity and the opportunity to
find your niche in this exciting, in-demand field.
** About Essentials of Cybersecurity Program
Are you  interested in working  in cybersecurity but  unsure if it's  the right
career choice for you?

This  professional certificate  program  will  introduce you  to  the field  of
cybersecurity, as you  learn about its landscape, numerous  sectors and various
roles, competencies and career pathways.

You will learn  about the role of the Chief  Information Security Office (CISO)
as you study the policies, procedures,  practices and technologies put in place
to mitigate organizational and systems vulnerabilities to cyberattack.

You  will also  learn about  the  type of  skills needed  from a  cybersecurity
professional, outside of  technical proficiency. And lastly, you  will be given
the opportunity to complete a self-assessment to determine which career path in
cybersecurity is right for you.

The goal of this program is to help you better understand cybersecurity and the
opportunities within this  field as they apply to you.  The program is intended
for learners  who wish to  identify their specific  optimal niche and  create a
plan for entry into this exciting field.

{{{heading(Job Outlook)}}}

- Between 2014 and  2016, Information Security as  a skill has grown  to be the
  top  most  in-demand skill  in  job  openings  where “Cybersecurity”  is  the
  keyword.
- Employment of information  security analysts is projected to  grow 18 percent
  from 2014 to 2024, much faster than the average for all occupations. (Source:
  Bureau of Labor and Statistics)
- The mean real-time salary is $108,335. (Source: Burning Glass)


#+attr_texinfo: :author David Shaw , Founder and CEO, Cybersecurity and Information Assurance Solutions (CBA)
#+begin_quote
"Our accomplished senior career military  veterans transitioning to the private
sector are facing  significant challenges as they compete  for technology, high
impact   jobs  with   institutionally   trained   and  educated   multinational
resources.  Cyber  Business Analytics  (CBA  Inc.)  envisions EdX  programs  to
produce the advanced skills and competitive  edge for the veteran heroes we are
onboarding to successfully  engage a wide range of  cybersecurity solutions for
critical infrastructure domains."
#+end_quote

{{{heading(What You'll Learn:)}}}

- Describe  the  vast array  of  roles  and  sectors within  the  Cybersecurity
  industry;
- Explain the  relationship between management and  technology in cybersecurity
  protection;
- Identify appropriate types  of security controls to the  actions of different
  and evolving threat actors;
- Apply terminology and basic concepts of cybersecurity;
- Assess own knowledge,  skill, and abilities toward identifying  a career path
  in cybersecurity.
** Courses in the Professional Certificate Program
:PROPERTIES:
:length:   Average 4 weeks per course
:number-of-courses: 4
:subject:  Computer Science
:price:    $349
:END:
- [[https://www.edx.org/course/introduction-to-cybersecurity][Introduction to Cybersecurity]]

- [[https://www.edx.org/course/cybersecurity-the-cisos-view][Cybersecurity---The CISO's View]]

- [[https://www.edx.org/course/building-a-cybersecurity-toolkit][Building a Cybersecurity Toolkit]]

- [[https://www.edx.org/course/finding-your-cybersecurity-career-path][Finding Your Cybersecurity Career Path]]
** Instructors in the Essentials of Cybersecurity Program
*** Barbara Endicott-Popovsky
- Director, Center  for Information  Assurance and Cybersecurity  University of
  Washington

Barbara  Endicott-Popovsky  is  the  director of  the  Center  for  Information
Assurance  and  Cybersecurity.  She   also  teaches  cybersecurity  in  several
University of  Washington programs.  Endicott-Popovsky is  a member  of several
national committees  shaping cybersecurity  education. She earned  her doctoral
degree from the  Center for Secure and Dependable Systems  in the Department of
Computer Science at the University of Idaho.

*** David Aucsmith
- Senior  Principal  Research  Scientist,  Applied Physics  Lab  University  of
  Washington

David Aucsmith is  a Senior Principal Research Scientist -  Applied Physics Lab
at  the University  of  Washington. He  has  worked in  a  variety of  security
technology  areas  including  secure computer  systems,  secure  communications
systems,  security architecture,  random  number  generation, cryptography  and
cryptographic systems, steganography and  network intrusion detection. Aucsmith
is a former officer in the U.S. Navy and has written extensively on cybercrime,
cyber espionage  and cyber warfare.  He has  been a representative  to numerous
international,  government and  academic organizations  including the  National
Academy  advisory  board  on  Survivability  and  Lethality  Analysis  and  the
Directorate Advisory Council  for the National Security  Directorate of Pacific
Northwest National Labs. He is  co-chairman of the FBI's Information Technology
Study Group,  a member of  the President's Task  Force on National  Defense and
Computer  Technology  and  a  member  of the  Department  of  Defense's  Global
Information Grid Senior Industry Review  Group. Aucsmith was also U.S. industry
representative   to  the   G8  Committee   on  Organized,   Transnational,  and
Technological Crime where he participated directly  in the G8 summits in Paris,
Berlin and Tokyo.

** Cybersecurity---The CISO's View
:PROPERTIES:
:source:   UWashingtonX
:course:   CYB002x
:uri:      https://courses.edx.org/courses/course-v1:UWashingtonX+CYB002x+2T2019/course/
:start-date: May 8, 2018
:series:   Essentials of Cybersecurity
:END:
*** Welcome---CYB002X-The CISO'S View
**** About the Course---The CISO'S VIEW
We are pleased to  welcome you to The CISO's View.  This is  the second of four
self-paced courses that make up our certificate series on {{{cite(Essentials of
Cybersecurity).  The  other courses  in this  series open  in the  next several
months.  Course  3 will open Sept.  10.  Course 4  will open Oct. 30.   You may
take the courses in any order.
**** Earn a Verified Certificate
If you  have chosen  to become  a [[https://www.edx.org/course/cybersecurity-cisos-view-uwashingtonx-cyb002x][Verified Certificate  student]], and  achieve a
passing grade  of at least  70%, you will  earn a Verified  Certificate.  These
verified certificates indicate that you have successfully completed the course,
but will not include a specific grade.  Many students add their certificates to
their resumé, CV, or LinkedIn profile to demonstrate mastery of a given subject
area to  potential employers.  Certificates  are delivered online  through your
dashboard  on  edx.org.  We  urge  you  to  consider the  Verified  Certificate
option - you  have limited time to become a  Verified Certificate student.  See
the edX FAQ for more details on certificates.  If you are not yet enrolled as a
verified learned, we encourage  you to sign up.  As a  verified learner you are
issued  a   certificate  of   completion  after  successfully   fulfilling  the
coursework.
*** Syllabus for CYB002X The CISO'S View
                            CYB002X The CISO’s View
                                   Syllabus

                 {{{heading(Course Description)}}}

                 This course focuses on operationalizing cybersecurity in an
                 organization, taking the view from the leadership perspective
                 through the lenses of four prominent Chief (or Corporate)
                 Internet Security Officers, or CISOs. Throughout, you will be
                 asked to consider a systems thinking approach - a process that
                 involves inductive rather than deductive (linear) reasoning
                 and which considers interdependence and unintended
                 consequences. You'll be asked to take this approach in some
                 thinking problems throughout the course.  In one-one
                 interviews with CISOs in this course, you will take a look at
                 what experienced leaders consider their indispensable
                 resources; and the role of the CISO in four main sectors -
                 Industry, Government, Military, and Academia. Readings and
                 viewings will augment your knowledge of systems approaches in
                 relationship to sector-specific threats and challenges.
                 Cybersecurity must be seen in context! Systems thinking and
                 the advice of those with long experience in positions of
                 leadership can help you gain this important perspective as you
                 think about a career in this complicated field.

                 {{{heading(Course Objectives)}}}

                 After successfully completing this course, the learner will be
                 able to:
                     -   Compare and contrast the four sectors of cybersecurity
                       with a focus on their rules, regulations, tools
                       (technologies), and primary cybersecurity concerns;
                     -   Analyze the role of the CISO across all sectors, and
                       the differences among their tool kits.
                     -   Apply systems thinking approach to cybersecurity
                       scenarios.
                     -   Align growing awareness of sector differences and
                       similarities to personal experience, talents, and
                       interests,
                     -   Build a matrix of reflections on sectors as a
                       decision-making tool.

                                       2

                 {{{heading(Prerequisites)}}}

                 There are no required prerequisites other than curiosity and
                 interest in Cybersecurity. However, CYB001x Introduction to
                 Cybersecurity provides a good foundation and is Course 1 in
                 the certificate series. This is an introductory-level course.

                 {{{heading(Earning a Verified Certificate)}}}

                 If you have chosen to become a Verified certificate student,
                 and achieve a passing grade of at least 70%, you will earn a
                 Verified Certificate. These verified certificates indicate
                 that you have successfully completed the course, but will not
                 include a specific grade. Many students add their certificates
                 to their resumé, CV, or LinkedIn profile to demonstrate
                 mastery of a given subject area to potential employers.
                 Certificates are delivered online through your dashboard on
                 edx.org.

                 We urge you to consider the Verified Certificate option - you
                 have limited time to become a Verified Certificate
                 student. See the edX FAQ for more details on certificates.

                 {{{heading(Time Commitment and Due Dates)}}}

                 This course is self-paced; learners can expect to spend about
                 2 to 5 hours per weekly topic or lesson engaging with the
                 course materials.  For Verified Learners, this course is
                 self-paced. There are no due dates. However, all work must be
                 completed by the course end date.

                 {{{heading(Certification)}}}

                 This course is the second of four courses in the edX
                 certificate series on Essentials of Cybersecurity. The other
                 courses are:
                     -   CYB001X: Introduction to Cybersecurity
                     -   CYB003X: Building a Cybersecurity Toolkit
                     -   CYB004X: Finding your Cybersecurity Career Path

                                       3

       Learners may take these courses in any sequence. A verified learner
       receives a certificate for successful completion of each course
       taken. An additional certificate in Essentials of Cybersecurity is
       issued to learners who successfully complete all four courses in the
       series.  See edX’s Verified Certificates for more information.

       {{{heading(Course Materials)}}}

       All required materials are included in the weekly or lesson course
       pages.

       {{{heading(Academic Policies)}}}

       {{{subheading(Grading Policy)}}}

       To pass this course with a verified certificate, all learners must earn
       a minimum of 70% total for the graded course activities.

       {{{subheading(Academic Honesty)}}}

       edX expect students to participate with academic integrity. Honesty and
       original work is expected. Full citations for information shared that is
       not student-generated is also expected.

       {{{heading(Course Activities)}}}

       {{{subheading(Discussion Forums)}}}

       Etiquette

       All learners are expected to engage in respectful dialogue in the public
       discussion forums.

       Participation Expectation

       The discussion forums in this course provide an additional learning
       space to practice relevant discourse on the course topics.

                                       4

       {{{subheading(Knowledge Checks)}}}

       Following course content, brief auto-graded questions (some with
       feedback) may appear that focus the learner on specific concepts or
       terminology. These knowledge checks are part of the graded course
       activities.

       {{{subheading(Peer Interaction)}}}

       Peer Assessment

       Other learners in the course score peer-graded activities with a rubric
       based on understanding of the course content.

       {{{heading(About the Course Developer)}}}

       {{{subheading(Barbara Endicott-Popovsky)}}}

       Barbara Endicott-Popovsky is the director of the Center for Information
       Assurance and Cybersecurity. She also teaches cybersecurity in several
       University of Washington programs.

       Endicott-Popovsky is a member of several national committees shaping
       cybersecurity education. She earned her doctoral degree from the Center
       for Secure and Dependable Systems in the Department of Computer Science
       at the University of Idaho.
* Systems Security Certified Practitioner---SSCP
:PROPERTIES:
:Instructor: (ISC)^2
:URL:      https://www.coursera.org/specializations/sscp-training
:END:
** About the Specialization "Systems Security Certified Practitioner"---SSCP
- https://www.coursera.org/specializations/sscp-training

Advance Your IT Career with Cybersecurity Skills.  Gain Flexibility with
Self-Paced Learning.

Pursue better IT security job opportunities and prove knowledge with
confidence. The SSCP Professional Training Certificate shows employers you have
the IT security foundation to defend against cyber attacks – and puts you on a
clear path to earning SSCP certification.

Learn on your own schedule with 120-day access to content aligned with the
latest (ISC)2 SSCP exam domains. We’re offering the complete online self-paced
program for only $1,000 – a $200 savings when you get all domains bundled
together.
*** Outline of Courses in the Specialization
Upon completing the SSCP Professional Certificate, you will:

1. Complete six courses of preparing you to sit for the [[https://www.isc2.org/en/Certifications/SSCP][Systems Security
   Certified Practitioner (SSCP) certification exam]] as outlined below.

   - Course 1 - Access Controls

     Welcome to Access Controls! The Access Controls Course provides
     information pertaining to specify what users are permitted to do, the
     resources they are allowed to access, and what operations they are able to
     perform on a system. Access Controls help managers limit and monitor
     systems use at a user level or group membership. You will understand the
     different access control systems and how they should be implemented to
     protect the system and data using the different levels of confidentiality,
     integrity, and availability. The Access Controls course provides
     information pertaining to specifying what users are permitted to do, the
     resources they are allowed to access, and what operations they are able to
     perform on a system. Access Controls help managers limit and monitor
     systems use at a user level, and is usually predefined based on authority
     level or group membership. You will understand the different access
     control systems and how they should be implemented to protect the system
     and data using the different levels of confidentiality, integrity, and
     availability. Objectives 1. Describe how to implement Authentication
     mechanisms 2. Identify and operate internetwork trust
     architectures 3. Describe the process of administering identity management
     life cycle 4. Implement the different types of access controls
     (Subject/Object based)

   - Course 2 - Security Operations and Administration

     Security operations and administration is the task of identifying an
     organization's information assets and the documentation needed for policy
     implementation, standards, procedures, and guidelines to ensure
     confidentiality, integrity, and availability. You will understand the
     process necessary for working with management and information owners,
     custodians, and users so that proper data classifications are
     defined. This will ensure the proper handling of all hard copy and
     electronic information. The Security operations and Administration course
     addresses basic security concepts and the application of those concepts in
     the day to day operation and administration of enterprise computer systems
     and the information that they host.Ethical considerations in general, and
     the (ISC)2 Code of Ethics in particular, provide the backdrop for any
     discussion of information security and SSCP candidates will be tested on
     both. Information security professionals often find themselves in
     positions of trust and must be beyond reproach in every way.Several core
     principles of information security stand above all others and this domain
     covers these principles in some depth. It can be said that the CIA triad
     of confidentiality, integrity and availability forms the basis for almost
     everything that we do in information security and the SSCP candidate must
     not only fully understand these principles but be able to apply them in
     all situations. additional security concepts covered in this domain
     include privacy, least privilege, non-repudiation and the separation of
     duties. Course Objectives 1. Define Code of Ethics 2. Describe the
     security concepts 3. Document and operate security controls 4. Describe
     the asset management process 5. Implement compliance controls 6. Assess
     compliance controls 7. Describe the change management
     process 8. Contribute to the security awareness training
     program 9. Contribute to physical security operations

   - Course 3 - Risk Identification, Monitoring, and Analysis/Incident Response
     and Recovery

     Risk Identification, Monitoring, and Analysis: In the Risk Identification,
     Monitoring, and Analysis session, you will learn how to identify, measure,
     and control losses associated with adverse events. You will review,
     analyze, select, and evaluate safeguards for mitigating risk.You will
     learn processes for collecting information, providing methods of
     identifying security events, assigning priority levels, taking the
     appropriate actions, and reporting the findings to the correct
     individuals. After collection of the details from monitoring, we can
     analyze to determine if the system is being operated in accordance with
     accepted industry practices, and in compliance with organization policies
     and procedures. Incident Response and Recovery: In the Incident Response
     and Recovery Session, you will gain an understanding of how to handle
     incidents using consistent, applied approaches in order to resolve. Once
     an incident is identified, action will be necessary in order to
     resolve. We will examine processes such as damage recovery, data integrity
     and preservation, and the collection, handling, reporting, and
     prevention. You will be introduced to the Business Continuity Plan (BCP)
     and Disaster Recovery Plan (DRP) concepts and how they can be utilized in
     order to mitigate damages, recover business operations, and avoid critical
     business interruption. Through the use of the DRP, you will understand the
     procedures for emergency response and post-disaster recovery. Course
     Objectives 1. Describe the risk management process 2. Perform security
     assessment activities 3. Describe processes for operating and maintaining
     monitoring systems 4. Identify events of interest 5. Describe the various
     source systems 6. Interpret reporting findings from monitoring
     results 7. Describe the incident handling process 8. Contribute to the
     incident handling process based upon role within the
     organization 9. Describe the supporting role in forensics investigation
     processes 10. Describe the supporting role in the business continuity
     planning process 11. Describe the supporting role in the disaster recovery
     planning process

   - Course 4 - Cryptography

     Welcome to Cryptography! Cryptography is the practice and study of
     techniques for securing communications in the presence of third
     parties. You will learn how to protect information in order to ensure its
     integrity, confidentiality, authenticity, and non-repudiation. You will
     come out with a basic understanding of cryptographic concepts and how to
     apply them, implement secure protocols, key management concepts, key
     administration and validation, and Public Key Infrastructure. Course
     Objectives 1. Apply the fundamental concepts of cryptography 2. Describe
     the difference between symmetric and asymmetric cryptography 3. Define the
     basic requirements for cryptography 4. Identify processes to support
     secure protocols 5. Describe the process for implementing cryptographic
     systems 6. Define key management concepts 7. Define Public Key
     Infrastructure 8. Identify processes for key administration and
     validation 9. Describe the implementation of secure protocols

   - Course 5 - Network and Communication Security

     Welcome to Networks and Communications Security Course! In the Networks
     and Communications Security Course, you will learn about the network
     structure, data transmission methods, transport formats, and the security
     measures used to maintain integrity, availability, authentication, and
     confidentiality of the information being transmitted. Concepts for both
     public and private communication networks will be discussed. Course
     Objectives 1. Describe network-related security issues 2. Identify
     protective measures for telecommunication technologies 3. Define processes
     for controlling network access 4. Identify processes for managing
     LAN-based security 5. Describe procedures for operating and configuring
     networked-based security devices 6. Define procedures to implement and
     operate wireless technologies

   - Course 6 - Systems and Application Security

     Welcome to Systems and Application Security Course! In the Systems and
     Application Security Course, you will gain an understanding of computer
     code that can be described as harmful or malicious. Both technical and
     non-technical attacks will be discussed. You will learn how an
     organization can protect itself from these attacks. You will learn
     concepts in endpoint device security, cloud infrastructure security,
     securing big data systems, and securing virtual
     environments. Objectives 1. Identify malicious code activity 2. Describe
     malicious code and the various countermeasures 3. Describe the processes
     for operating endpoint device security 4. Define mobile device management
     processes 5. Describe the process for configuring cloud
     security 6. Explain the process for securing big data systems 7. Summarize
     the process for securing virtual environments

2. Receive a certificate of program completion.

3. Understand how to implement, monitor and administer an organization’s IT
   infrastructure in accordance with security policies and procedures that
   ensure data confidentiality, integrity and availability.

*** About the Instructor
(ISC)^2 s an international nonprofit membership association focused on inspiring
a safe and secure cyber world. Best known for the acclaimed Certified
Information Systems Security Professional (CISSP (R)) certification, (ISC)^2
offers a portfolio of credentials that are part of a holistic, programmatic
approach to security. [[https:www.isc2.org][www.isc2.org]].
** Course on Access Controls
:PROPERTIES:
:Specialization: (ISC)² Systems Security Certified Practitioner (SSCP) Specialization
:Course:   1
:Length:   16 hours
:END:
*** About Access Controls Course
The Access Controls course provides information pertaining to specifying what
users are permitted to do, the resources they are allowed to access, and what
operations they are able to perform on a system.  Access Controls help managers
limit and monitor systems use at a user level, and is usually predefined based
on authority level or group membership.  You will understand the different
access control systems and how they should be implemented to protect the system
and data using the different levels of confidentiality, integrity, and
availability.
**** Objectives
1. Describe how to implement Authentication mechanisms
2. Identify and operate internetwork trust architectures
3. Describe the process of administering identity management life cycle
4. Implement the different types of access controls (Subject/Object based)
*** Syllabus
**** Single Factor/Multifactor Authentication---Biometrics.
In Single Factor/ Multifactor Authentication, you will learn about
- identity,
- methods,
- registration of new users,
- periodic review of access levels,
- clearance,
- authentication,
- knowledge,
- password reset,
- mass lockouts,
- ownership, and
- characteristics.


In Biometrics, you will learn about
- biometrics,
- behavioral biometrics,
- physiological biometrics,
- biometric implementation issues,
- biometric accuracy,
- physiological use as identification,
- next-generation identification (NGI) database,
- department of defense (DoD) electronic biometric transmission specification
  (EBTS), and
- biometric standards development.

***** Videos
- Welcome to Access Controls1m
- Authentication Mechanisms: Identity4m
- Authentication Mechanisms: Methods7m
- Authentication Mechanisms: Registration of New Users7m
- Authentication Mechanisms: Clearance6m
- Authentication Mechanisms: Proof of Identity6m
- Authentication Mechanisms: Password Reset6m
- Authentication Mechanisms: Mass Lockouts6m
- Authentication Mechanisms: Biometrics9m
- Authentication Mechanisms: Biometric Implementation Issues7m
- Authentication Mechanisms: Biometric Accuracy6m
- Authentication Mechanisms: Biometric Standards Development4m

***** Readings
- Authentication Mechanisms: Identity10m
- Authentication Mechanisms: Methods10m
- Authentication Mechanisms: Registration of New Users10m
- Authentication Mechanisms: Clearance10m
- Authentication Mechanisms: Proof of Identity10m
- Authentication Mechanisms: Password Reset10m
- Authentication Mechanisms: Mass Lockouts10m
- Authentication Mechanisms: Biometrics10m
- Authentication Mechanisms: Biometric Implementation Issues10m
- Authentication Mechanisms: Biometric Accuracy10m
- Authentication Mechanisms: Biometric Standards Development10m

**** Tokens---Single Sign-On---Offline and Device Authentication
In Tokens, you will learn about uses of
- token information,
- time-synchronized one-time passwords,
- mathematical-algorithm based one time passwords,
- physical types,
- disconnected tokens,
- connected tokens,
- contactless tokens,
- bluetooth and mobile device tokens,
- smart cards,
- types of smart card technology,
- smart card applications,
- multifactor authentication,
- two-factor vs. three-factor authentication,
- dual control,
- continuous authentication,
- periodic authentication,
- time outs,
- reverse authentication,
- certificate-based authentication,
- authorization,
- access to systems vs. data,
- network,
- access control lists/matrix, and
- directories.


In Single Sign-On, you will learn about
- SSO risks,
- SSO implementation:
  - kerberos,
  - Kerberos applications,
  - Kerberos process,
  - Kerberos considerations,
  - Kerberos tools,
  - Klist purge,
  - Server 2012/(R2) and
  - Windows 8/8.1 features, and
  - network ports used during Kerberos authentication.


In Offline and Device Authentication, you will learn about
- types of authentication.

***** Videos
- Authentication Mechanisms: Uses of Token Information7m
- Authentication Mechanisms: Types of Tokens6m
- Authentication Mechanisms: Multifactor Authentication7m
- Authentication Mechanisms: Multifactor Authentication5m
- Authentication Mechanisms: Access to systems vs. data, Network5m
- Authentication Mechanisms: Access Control Lists/Matrix7m
- Authentication Mechanisms: Single Sign-On Risks4m
- Authentication Mechanisms: Kerberos6m
- Authentication Mechanisms: Kerberos Applications and Process5m
- Authentication Mechanisms: Kerberos Considerations and Tools4m
- Authentication Mechanisms: Types of Authentication5m

***** Readings
- Authentication Mechanisms: Uses of Token Information10m
- Authentication Mechanisms: Types of Tokens10m
- Authentication Mechanisms: Multifactor Authentication10m
- Authentication Mechanisms: Multifactor Authentication10m
- Authentication Mechanisms: Access to systems vs. data, Network10m
- Authentication Mechanisms: Access Control Lists/ Matrix10m
- Authentication Mechanisms: Single Sign-On Risks10m
- Authentication Mechanisms: Kerberos10m
- Authentication Mechanisms: Kerberos Applications and Process10m
- Authentication Mechanisms: Kerberos Considerations and Tools10m
- Authentication Mechanisms: Types of Authentication10m

**** Comparing Internetwork Architectures---One-way Trust--Two-way Trust---Transitive Trust
In Comparing Internetwork Architectures, you will learn about typical DMZ
design, trust path.

In Trust, you will learn about one-way trust, two-way trust, and transitive
trust.

***** Videos
- Internetwork Trust Architecture: Comparing Architectures7m
- Internetwork Trust Architecture: Trust Path7m
- Internetwork Trust Architectures: Two-Way Trust2m
- Internetwork Trust Architecture: Transitive Trust8m

***** Readings
- Internetwork Trust Architecture: Comparing Architectures10m
- Internetwork Trust Architecture: Trust Path10m
- Internetwork Trust Architecture: Two-Way Trust10m
- Internetwork Trust Architecture: Transitive Trust10m

**** Identity Management---Authorization--Proofing--Provisioning--Maintenance---Entitlement.
In Identity management, you will learn about identity management cycle. You will
also learn about, authorization, proofing, provisioning, and maintenance.

In Entitlement, you will learn about entities, entitlement defined.

***** Videos
- Identity Management Life Cycle: Identity Management5m
- Identity Management Life Cycle: Provisioning5m
- Identity Management Life Cycle: Entitlement Defined4m

***** Readings
- Identity Management Life Cycle: Identity Management10m
- Identity Management Life Cycle: Provisioning10m
- Identity Management Life Cycle: Entitlement Defined10m

**** Implement Access Controls
- Mandatory Access Control (MAC), Non-Discretionary Access Control,

- Discretionary Access Control (DAC)

  you will learn about Rule Set-Based Access Controls (RSBAC), RSBAC GFAC logic
  for data access request.

- Role-Based Access Control (RBAC), Content Dependent, Context-Based, Temporal
  Isolation (Time Based)

  In Role -Based Access Control (RBAC), you will learn about role hierarchies,
  constrained user interface (CUI), types of restricted interfaces, view-based
  access control (VBAC), and VBAC examples.

  You will also learn about Content-Dependent Access Control (CDAC), and
  Temperoal isolation (Time-Based) Access Control.

- Attribute-Based, Separation of Duties

  In Attribute-based Access Control (ABAC), you will learn about key terms.

- Security Architecture and Models

  In Security Architecture and Models, you will learn about Bell-LaPadula
  confidentiality Model, Biba integrity model, BLP and Biba model comparison,
  Clark-Wilson integrity model, and additional models

***** Videos
- Implement Access Controls: Mandatory Access Control5m
- Implement Access Controls: Discretionary and Non-Discretionary Access Controls3m
- Implement Access Controls: Rule-Set Based and Role-Based Access Control7m
- Implement Access Controls: Role Hierarchies6m
- Implement Access Controls: Restricted Interfaces6m
- Implement Access Controls: key Terms4m
- Implement Access Controls: Security Architecture and Models6m
- Implement Access Controls: BLP and Biba Model Comparison5m
- Implement Access Controls: BLP and Biba Model Comparison6m

***** Readings
- Implement Access Controls: Mandatory Access Control10m
- Implement Access Controls: Discretionary and Non-Discretionary Access Controls10m
- Implement Access Controls: Rule-Set Based and Role-Based Access Control10m
- Implement Access Controls: Role Hierarchies10m
- Implement Access Controls: Restricted Interfaces10m
- Implement Access Controls: Key Terms10m
- Implement Access Controls: Security Architecture and Models10m
- Implement Access Controls: BLP and Biba Model Comparison10m
- Implement Access Controls: BLP and Biba Model Comparison10m

**** Case Study
This assignment is based on a case study that will require the student to put
into practice the knowledge they have gained through the course.  It requires
the basic understanding of the topics and the ability to relate those topics to
the real world.  The objective of review is to determine whether the student
has understood the concepts and has performed the necessary analysis to ensure
a complete and thorough answer.

**** Exam

***** Reading
- SSCP Exam Information10m

***** Practice Exercice
- Access Controls Course Assessment30m
** Course on Cryptography
:PROPERTIES:
:Specialization: (ISC)² Systems Security Certified Practitioner (SSCP)
:Course:   4
:END:
- https://www.coursera.org/learn/cryptography-sscp?specialization=sscp-training
*** About Cryptography Course
Cryptography is the practice and study of techniques for securing
communications in the presence of third parties.  You will learn how to protect
information in order to ensure its integrity, confidentiality, authenticity,
and non-repudiation.  You will come out with a basic understanding of
cryptographic concepts and how to apply them, implement secure protocols, key
management concepts, key administration and validation, and Public Key
Infrastructure.
**** Course Objectives
1. Apply the fundamental concepts of cryptography
2. Describe the difference between symmetric and asymmetric cryptography
3. Define the basic requirements for cryptography
4. Identify processes to support secure protocols
5. Describe the process for implementing cryptographic systems
6. Define key management concepts
7. Define Public Key Infrastructure
8. Identify processes for key administration and validation
9. Describe the implementation of secure protocols

*** Syllabus

**** Understand and Apply Fundamental Concepts of Cryptography
- Encryption Concepts---Methods of Cryptography---Specific Hashing.

  In Encryption Concepts you will learn about key concepts and definitions and
  high work factor.

  In Methods of Cryptography you will learn about
  - stream-based ciphers,
  - stream-based cipher rules,
  - block ciphers,
  - Initialization Vectors (IV) – Why are they needed?
  - basic block cipher modes,
  - evaluation of algorithms,
  - common encryption techniques,
  - encryption algorithm characteristics, and
  - hashing.

  In Specific Hashing you will learn about
  - message digest (MD) 2, 4, and 5,
  - secure hash algorithm (SHA) 0, 1, and 2,
  - hAVAL,
  - RIPEMD-160,
  - attacks on hashing algorithms and message authentication codes, and
  - the birthday paradox.

***** Videos
Welcome to Cryptography5m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions6m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions6m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions3m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions5m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions3m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions6m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions4m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions8m
- Fundamental Concepts of Cryptography: High Work Factor5m
- Fundamental Concepts of Cryptography: Block Ciphers4m
- Fundamental Concepts of Cryptography: Basic Block Cipher Modes5m
- Fundamental Concepts of Cryptography: Evaluation of Algorithms7m
- Fundamental Concepts of Cryptography: Algorithm Characteristics6m
- Fundamental Concepts of Cryptography: Attacks7m
- Fundamental Concepts of Cryptography: The Birthday Paradox4m

***** Readings
- Fundamental Concepts of Cryptography: Key Concepts and Definitions10m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions10m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions10m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions10m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions10m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions10m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions10m
- Fundamental Concepts of Cryptography: Key Concepts and Definitions10m
- Fundamental Concepts of Cryptography: High Work Factor10m
- Fundamental Concepts of Cryptography: Block Ciphers10m
- Fundamental Concepts of Cryptography: Basic Block Cipher Modes10m
- Fundamental Concepts of Cryptography: Evaluation of Algorithms10m
- Fundamental Concepts of Cryptography: Algorithm Characteristics10m
- Fundamental Concepts of Cryptography: Attacks10m
- Fundamental Concepts of Cryptography: The Birthday Paradox10m

**** Understand Requirements for Cryptography
- Salting, Symmetric/Asymmetric Cryptography

  In Symmetric/Asymmetric Cryptography you will learn about
  - encryption and decryption,
  - symmetric cryptography,
  - out-of-band key distribution,
  - advantages and disadvantages of DES,
  - double DES,
  - meet-in-the-middle,
  - triple DES (3DES),
  - advanced encryption standard (AES),
  - Counter Mode with Cipher Block Chaining Message Authentication Code
    Protocol (CCMP), and
  - how CCMP works,
  - Rijndael.

- Additional algorithms

  In Additional algorithms you will learn about
  - International Data Encryption Algorithm (IDEA),
  - CAST,
  - Secure and Fast Encryption Routine (SAFER),
  - Blowfish,
  - Twofish,
  - RC5,
  - RC4,
  - advantages and disadvantages of
    - symmetric algorithms,
    - asymmetric cryptography,
    - asymmetric algorithms,
    - confidential messages, open message,
    - confidential messages with proof of origin,
    - RSA,
    - attacking RSA,
    - Diffie–Hellmann Algorithm,
    - El Gamal,
    - Elliptic Curve Cryptography (ECC),
  - advantages and disadvantages of
    - asymmetric key algorithms,
    - hybrid cryptography,
    - message digests,
    - message authentication code (MAC),
    - HMAC,
    - digital signatures, and

- Non-Repudiation

- Methods of Cryptanalytic Attack

  In methods of Cryptanalytic Attack you will learn about
  - chosen plain-text,
  - Social engineering for key discovery,
  - brute force,
  - differential cryptanalysis,
  - linear cryptanalysis,
  - Algebraic,
  - rainbow table,
  - ciphertext-only attack,
  - known plaintext,
  - frequency analysis,
  - chosen cipher-text,
  - birthday attack,
  - dictionary attack,
  - replay attack,
  - reverse engineering, and
  - temporary files.

- Data Sensitivity and Regulatory Requirements

  In Data Sensitivity and Regulatory Requirements you will learn about
  - data classification examples,
  - protected data examples,
  - non-sensitive data examples,
  - legislative and regulatory compliance,
  - United States example,
  - privacy requirements compliance, and
  - European Data Protection Directive.

- End-User Training

  In End-User Training you will learn about security awareness training topics.

***** Videos
- Fundamental Concepts of Cryptography: Salting8m
- Fundamental Concepts of Cryptography: Symmetric Cryptography5m
- Fundamental Concepts of Cryptography: Key Distribution6m
- Fundamental Concepts of Cryptography: Additional Algorithms5m
- Fundamental Concepts of Cryptography: Asymmetric Cryptography7m
- Fundamental Concepts of Cryptography: Using Public Key Cryptography7m
- Fundamental Concepts of Cryptography: Attacking RSA7m
- Fundamental Concepts of Cryptography: Message Digests5m
- Fundamental Concepts of Cryptography: Chosen Plain-Text7m
- Fundamental Concepts of Cryptography: Known Plaintext6m
- Fundamental Concepts of Cryptography: Dictionary Attack4m
- Fundamental Concepts of Cryptography: Factoring Attack5m
- Understand Requirements For Cryptography: Data Sensitivity2m
- Understand Requirements For Cryptography: Data Protection Directive7m

***** Readings
- Fundamental Concepts of Cryptography: Salting10m
- Fundamental Concepts of Cryptography: Symmetric Cryptography10m
- Fundamental Concepts of Cryptography: Key Distribution10m
- Fundamental Concepts of Cryptography: Additional Algorithms10m
- Fundamental Concepts of Cryptography: Asymmetric Cryptography10m
- Fundamental Concepts of Cryptography: Using Public Key Cryptography10m
- Fundamental Concepts of Cryptography: Attacking RSA10m
- Fundamental Concepts of Cryptography: Message Digests10m
- Fundamental Concepts of Cryptography: Chosen Plain-Text10m
- Fundamental Concepts of Cryptography: Known Plaintext10m
- Fundamental Concepts of Cryptography: Dictionary Attack10m
- Fundamental Concepts of Cryptography: Factoring Attack10m
- Understand Requirements For Cryptography: Data Sensitivity10m
- Understand Requirements For Cryptography: Data Protection Directive10m

**** Operate and Implement Cryptographic System
- Public Key Infrastructure (PKI)

  In PKI you will learn about

  - functions of CA,
  - establishing trust, and
  - X.509v3 certification issued by VeriSign.

- Fundamental Key Management concepts

  In Fundamental Key Management Concepts you will learn about

  - standards for financial institutions,
  - segregation of duties, and
  - examples

- Creation and Distribution of Keys

  In Creation and Distribution of Keys you will learn about

  - truly random,
  - random,
  - generating a two-key encryption key set,
  - key length,
  - Asymmetric key length,
  - key wrapping and key encryption keys,
  - key distribution,
  - key distribution centers,
  - key storage and destruction,
  - factors affecting risk exposure,
  - cost of certificate replacement/revocation,
  - key recovery,
  - key escrow.

- Web of Trust

- Secure Protocols

  In Secure Protocols you will learn about

  - Authentication Header (AH),
  - Encapsulating Security Payload (ESP),
  - security associations,
  - transport mode and tunnel mode,
  - Internet Key Exchange (IKE),
  - Secure/Multipurpose Internet Mail Extensions (S/MIME),
  - S/MIME provides two security services,
  - digital signatures,
  - process for verifying a digital signature of an E-Mail message,
  - message encryption,
  - process for encryption of an E-Mail message,
  - process for decrypting an E-Mail message,
  - process of digitally signing and encrypting an E-mail message,
  - process of decrypting an E-Mail message and verifying a digital signature,
    and
  - triple-wrapped messages.

***** Videos
- Operate and Implement Cryptographic System: PKI4m
- Operate and Implement Cryptographic System: X.509 Certification8m
- Operate and Implement Cryptographic System: PKI Activity4m
- Operate and Implement Cryptographic System: Standards5m
- Operate and Implement Cryptographic System: Truly Random7m
- Operate and Implement Cryptographic System: Key Storage and Destruction3m
- Operate and Implement Cryptographic System: Factors Affecting Risk6m
- Operate and Implement Cryptographic System: Secure Protocols7m
- Operate and Implement Cryptographic System: Digital Signatures7m

***** Readings
- Operate and Implement Cryptographic System: PKI10m
- Operate and Implement Cryptographic System: X.509 Certification10m
- Operate and Implement Cryptographic System: PKI Activity10m
- Operate and Implement Cryptographic System: Standards10m
- Operate and Implement Cryptographic System: Truly Random10m
- Operate and Implement Cryptographic System: Key Storage and Destruction10m
- Operate and Implement Cryptographic System: Factors Affecting Risk10m
- Operate and Implement Cryptographic System: Secure Protocols10m
- Operate and Implement Cryptographic System: Digital Signatures10m

**** Cryptography Case Study
This assignment is based on a case study that will require the student to put
into practice the knowledge they have gained through the course.  It requires
the basic understanding of the topics and the ability to relate those topics to
the real world.  The objective of review is to determine whether the student has
understood the concepts and has performed the necessary analysis to ensure a
complete and thorough answer.

**** End-of-Course Assessment
* Cryptography I
:PROPERTIES:
:Instructor: Dan Boneh, Stanford University
:URL:      https://www.coursera.org/learn/crypto
:Length:   28 hours
:END:
** About Cryptogphy I
Cryptography is an indispensable tool for protecting information in computer
systems. In this course you will learn the inner workings of cryptographic
systems and how to correctly use them in real-world applications. The course
begins with a detailed discussion of how two parties who have a shared secret
key can communicate securely when a powerful adversary eavesdrops and tampers
with traffic. We will examine many deployed protocols and analyze mistakes in
existing systems. The second half of the course discusses public-key techniques
that let two parties generate a shared secret key. Throughout the course
participants will be exposed to many exciting open problems in the field and
work on fun (optional) programming projects. In a second course (Crypto II) we
will cover more advanced cryptographic tasks such as zero-knowledge, privacy
mechanisms, and other forms of encryption.
** Syllabus for Cryptography I
*** Course overview and stream ciphers
This week's topic is an overview of what cryptography is about as well as our
first example ciphers. You will learn about pseudo-randomness and how to use it
for encryption. We will also look at a few basic definitions of secure
encryption.

**** Videos
- Course Overview10m
- What is Cryptography?15m
- History of Cryptography18m
- Discrete Probability (Crash Course)18m
- Discrete Probability (Crash Course, Cont.)13m
- Information Theoretic Security and The One Time Pad18m
- Stream Ciphers and Pseudo Random Generators19m
- Attacks on Stream Ciphers and The One Time Pad23m
- Real-World Stream Ciphers19m
- PRG Security Definitions24m
- Semantic Security15m
- Stream Ciphers are Semantically Secure [optional]10m

**** Readings
- Lecture slides for all six weeks10m
- Course overview and additional reading resources10m

*** Block Ciphers
We introduce a new primitive called a block cipher that will let us build more
powerful forms of encryption. We will look at a few classic block-cipher
constructions (AES and 3DES) and see how to use them for encryption. Block
ciphers are the work horse of cryptography and have many applications. Next
week we will see how to use block ciphers to provide data integrity. The
optional programming assignment this week asks students to build an
encryption/decryption system using AES.

**** Videos
- What are Block Ciphers?16m
- The Data Encryption Standard21m
- Exhaustive Search Attacks19m
- More Attacks on Block Ciphers 16m
- The AES Block Cipher13m
- Block Ciphers From PRGs11m
- Review: PRPs and PRFs11m
- Modes of Operation: One Time Key7m
- Security for Many-Time Key (CPA security)22m
- Modes of Operation: Many Time Key (CBC)16m
- Modes of Operation: Many Time Key (CTR) 9m

*** Message Integrity
This week's topic is data integrity. We will discuss a number of classic
constructions for MAC systems that are used to ensure data integrity. For now
we only discuss how to prevent modification of non-secret data. Next week we
will come back to encryption and show how to provide both confidentiality and
integrity. This week's programming project shows how to authenticate large
video files. Even if you don't do the project, please read the project
description --- it teaches an important concept called a hash chain.

**** Videos
- Message Authentication Codes15m
- MACs Based On PRFs9m
- CBC-MAC and NMAC19m
- MAC Padding8m
- PMAC and the Carter-Wegman MAC15m
- Introduction 10m
- Generic Birthday Attack14m
- The Merkle-Damgard Paradigm 11m
- Constructing Compression Functions8m
- HMAC7m
- Timing attacks on MAC verification8m

*** Authenticated Encryption
This week's topic is authenticated encryption: encryption methods that ensure
both confidentiality and integrity. We will also discuss a few odds and ends
such as how to search on encrypted data. This is our last week studying
symmetric encryption. Next week we start with key management and public-key
cryptography. As usual there is also an extra credit programming project. This
week's project involves a bit of networking to experiment with a chosen
ciphertext attack on a toy web site.

**** Videos
- Active Attacks on CPA-Secure Encryption12m
- Definitions 5m
- Chosen Ciphertext Attacks12m
- Constructions From Ciphers and MACs20m
- Case Study: TLS 1.217m
- CBC Padding Attacks14m
- Attacking Non-Atomic Decryption 9m
- Key Derivation13m
- Deterministic Encryption14m
- Deterministic Encryption: SIV and Wide PRP20m
- Tweakable Encryption14m
- Format Preserving Encryption12m

*** Basic Key Exchange
This week's topic is basic key exchange: how to setup a secret key between two
parties. For now we only consider protocols secure against eavesdropping. This
question motivates the main concepts of public key cryptography, but before we
build public-key systems we need to take a brief detour and cover a few basic
concepts from computational number theory. We will start with algorithms dating
back to antiquity (Euclid) and work our way up to Fermat, Euler, and
Legendre. We will also mention in passing a few useful concepts from 20th
century math. Next week we will put our hard work from this week to good use
and construct several public key encryption systems.

**** Videos
- Trusted 3rd Parties 11m
- Merkle Puzzles11m
- The Diffie-Hellman Protocol19m
- Public-Key Encryption10m
- Notation14m
- Fermat and Euler18m
- Modular e'th Roots17m
- Arithmetic algorithms12m
- Intractable Problems18m

**** Reading
- More background on number theory10m

*** Public-Key Encryption
This week's topic is public key encryption: how to encrypt using a public key
and decrypt using a secret key. Public key encryption is used for key
management in encrypted file systems, in encrypted messaging systems, and for
many other tasks. The videos cover two families of public key encryption
systems: one based on trapdoor functions (RSA in particular) and the other
based on the Diffie-Hellman protocol. We construct systems that are secure
against tampering, also known as chosen ciphertext security (CCA
security). There has been a ton of research on CCA security over the past
decade and given the allotted time we can only summarize the main results from
the last few years. The lectures contain suggestions for further readings for
those interested in learning more about CCA secure public-key systems. The
problem set this week involves a bit more math than usual, but should expand
your understanding of public-key encryption. Please don't be shy about posting
questions in the forum. This is the last week of this Crypto I course. I hope
everyone learned a lot and enjoyed the material. Crypto is a beautiful topic
with lots of open problems and room for further research. I look forward to
seeing you in Crypto II where we will cover additional core topics and a few
more advanced topics.

**** Videos
- Definitions and Security 15m
- Constructions10m
- The RSA Trapdoor Permutation17m
- PKCS 121m
- Is RSA a One-Way Function?16m
- RSA in Practice13m
- The ElGamal Public-key System19m
- ElGamal Security13m
- ElGamal Variants With Better Security10m
- A Unifying Theme11m
- Farewell (For Now)5m

*** Final exam
Congratulations! We are at the end of the course. This module contains only the
final exam which covers the entire course. I hope everyone learned a lot during
these 6 weeks. Good luck on the final exam and I look forward to seeing you at
a future course!
* SECURITY Articles
** [[https://www.jscape.com/blog/what-is-hmac-and-how-does-it-secure-file-transfers][What Is HMAC And How Does It Secure File Transfers?]]

  #+CINDEX:integrity
  #+CINDEX:authenticity
  #+CINDEX:HMAC
Data integrity checks are vital to secure communications.  They enable
communicating parties to verify the integrity and authenticity of the messages
they receive.  In secure file transfer protocols like FTPS, SFTP, and HTTPS,
data integrity/message authentication is usually achieved through a mechanism
known as HMAC.  In this post, we explain what HMAC is, its basic inner
workings, and how it secures data transfers.

*** Importance of data integrity checks in secure file transfers
Business decisions and processes are highly dependent on accurate and reliable
data. If data gets tampered and the alterations go unnoticed, it could affect
decisions and processes down the line. So if your data has to be transmitted
over a network, especially one as perilous as the Internet, you have to take
precautionary measures to preserve its integrity or at least know if it
underwent unauthorized alterations.

This is precisely the reason why secure file transfer protocols like FTPS,
SFTP, and HTTPS are equipped with mechanisms for countering threats to data
integrity. The most commonly used mechanism today is HMAC. Let me explain what
it is.

*** What is HMAC?
HMAC stands for Keyed-Hashing for Message Authentication. It's a message
authentication code obtained by running a cryptographic hash function (like
MD5, SHA1, and SHA256) over the data (to be authenticated) and a shared secret
key. HMAC is specified in RFC 2104.

HMACs are almost similar to digital signatures. They both enforce integrity and
authenticity. They both use cryptographic keys. And they both employ hash
functions. The main difference is that digital signatures use asymmetric keys,
while HMACs use symmetric keys.

*** How HMAC works
To understand how HMAC works, let's first examine how a hash function (on its
own) could be used for conducting a data integrity check on a file
transfer. Let's say a client application downloads a file from a remote
server. It's assumed that the client and server have already agreed on a common
hash function, say SHA2.

Before the server sends out the file, it first obtains a hash of that file
using the SHA2 hash function. It then sends that hash (a.k.a. message digest)
along with the file itself. Upon receiving the two items (i.e. the downloaded
file and the hash), the client obtains the SHA2 hash of the downloaded file and
then compares it with the downloaded hash. If the two match, then that would
mean the file was not tampered along the way.

If an attacker manages to intercept the downloaded file, alter the file's
contents, and then forward the tampered file to the recipient, that malicious
act won't go unnoticed. That's because, once the client runs the tampered file
through the agreed hash algorithm, the resulting hash won't match the
downloaded hash. This will let the receiver know the file was tampered along he
way.

So a hash function should do the trick then? Not so fast. While a hash function
can establish *data integrity*, i.e. that the file or message wasn't altered
along the way, it can't establish *authenticity*. How would the client know the
message it received came from the legitimate source?

That's why secure file transfer protocols like FTPS, SFTP, and HTTPS use HMACs
instead of just hash functions.  When two parties exchange messages through
those secure file transfer protocols, those messages will be accompanied by
HMACs instead of plain hashes. An HMAC employs both a hash function and a
shared secret key.

A shared secret key provides exchanging parties a way to establish the
authenticity of the message. That is, it provides the two parties a way of
verifying whether both the message and MAC (more specifically, an HMAC) they
receive really came from the party they're supposed to be transacting with.

The secret key enables this capability because it's generated during key
exchange, a preliminary process that requires the participation of the two
parties. Only those two parties who participated in the key exchange would know
what the shared secret key is. In turn, they would be the only ones who would
be able to arrive at the same result if they compute the message's
corresponding MAC using the shared secret key.

*** Why is HMAC suitable for file transfers?
Aside from its ability to enable data integrity and message authentication,
another reason why HMAC is an excellent file transfer data integrity-checking
mechanism is its efficiency. As discussed in the article Understanding Hashing,
hash functions can take a message of arbitrary length and transform it into a
fixed-length digest. That means, even if you have relatively long messages,
their corresponding message digests can remain short, thereby allowing you to
maximize bandwidth.

** [[https://www.jscape.com/blog/bid/84422/Symmetric-vs-Asymmetric-Encryption][Symmetric vs Asymmetric Encryption]]

Secure file transfer protocols generally employ a combination of symmetric and
asymmetric encryption to preserve the confidentiality of data while in
transit. So why the need for two kinds of encryption? In this post, we take a
closer look at the main functions of symmetric and asymmetric encryption, their
strengths, their weaknesses, and why we'd prefer having both.

*** Symmetric key encryption
Symmetric key encryption is a type of encryption that makes use of a single key
for both the encryption and decryption process. Some of the encryption
algorithms that use symmetric keys include: AES (Advanced Encryption Standard),
Blowfish, DES (Data Encryption Standard), Triple DES, Serpent, and Twofish.

If you want to apply symmetric key encryption to a file transfer environment,
both the sender and receiver should have a copy of the same key. The sender
will use his copy of the key for encrypting the file, while the receiver will
use his copy for decrypting it.

So if you manage a secure file transfer server that only supports symmetric
encryption and one of your users wants to encrypt a file first before uploading
it, one of you (either the user or you, the server admin) should first generate
a key and then send the other person a copy of that key.

*** Asymmetric key encryption
Asymmetric key encryption, on the other hand, makes use of two keys. A private
key and a public key. The public key is used for encrypting, while the private
key is used for decrypting. Two of the most widely used asymmetric key
algorithms are: RSA and DSA.

If you're going to use asymmetric key encryption in a file transfer
environment, the sender would need to hold the public key, while the receiver
would need to hold the corresponding private key.

So, going back to the scenario given in the previous section, if you manage a
file transfer server and one of your users wants to encrypt a file first before
uploading it, it would typically be your duty to generate the key pair. You
should then send the public key to your user and leave the private key on the
server.

*** Which is stronger?
Actually, it's difficult to compare the cryptographic strengths of symmetric
and asymmetric key encryptions. Even though asymmetric key lengths are
generally much longer (e.g. 1024 and 2048) than symmetric key lengths (e.g. 128
and 256), it doesn't, for example, necessarily follow that a file encrypted
with a 2048-bit RSA key (an asymmetric key) is already tougher to crack than a
file encrypted with a 256-bit AES key (a symmetric key).

Instead, it would be more appropriate to compare asymmetric and symmetric
encryptions on the basis of two properties:
- Their computational requirements, and
- Their ease of distribution


Symmetric key encryption doesn't require as many CPU cycles as asymmetric key
encryption, so you can say it's generally faster. Thus, when it comes to speed,
symmetric trumps asymmetric. However, symmetric keys have a major disadvantage
especially if you're going to use them for securing file transfers.

Because the same key has to be used for encryption and decryption, you will
need to find a way to get the key to your recipient if he doesn't have it
yet. Otherwise, your recipient won't be able to decrypt the files you send
him. However way you do it, it has to be done in a secure manner or else anyone
who gets a hold of that key can simply intercept your encrypted file and
decrypt it with the key.

The issue of key distribution becomes even more pronounced in a file transfer
environment, which can involve a large number of users and likely distributed
over a vast geographical area. Some users, most of whom you may never have met,
might even be located halfway around the world. Distributing a symmetric key in
a secure manner to each of these users would be nearly impossible.

Asymmetric key encryption doesn't have this problem. For as long as you keep
your private key secret, no one would be able to decrypt your encrypted
file. So you can easily distribute the corresponding public key without
worrying about who gets a hold of it (well, actually, there are spoofing
attacks on public keys but that's for another story). Anyone who holds a copy
of that public key can encrypt a file prior to uploading to your server. Then
once the file gets uploaded, you can decrypt it with your private key.

*** Getting the best of both worlds with hybrid cryptosystems
Because both symmetric and asymmetric key cryptography have their own
advantages, modern file transfer systems typically employ a hybrid of the
two. Some hybrid cryptosystems are:
- SSL (used in FTPS and HTTPS)
- SSH (used in SFTP)
- OpenPGP


Hybrid cryptosystems employed in an SFTP or FTPS server use asymmetric keys to
initially encrypt symmetric keys known as session keys. The session keys are
then the ones used to encrypt the actual data. As its name implies, a session
key is only used in one session. After the session, the key is simply
discarded. That's a good thing because even if a session key is compromised,
only data sent within that particular session will be at risk.

Here's a simplified outline of the steps taken by a typical hybrid cryptosystem
used in secure file transfer protocols like SFTP and FTPS.

1. File transfer server sends its public key to an end user's file transfer
   client.

2. Client generates a session key, encrypts a copy of the session key using the
   public key, and sends that copy to the server.

3. Server receives its copy of the session key and both of them use that
   session key to encrypt/decrypt files exchanged within that session.


[[file:./resources/hybrid_cryptosystem.png]]

*** Summary
File transfer systems normally use hybrid cryptosystems, i.e. a combination of
symmetric and asymmetric key encryption, to provide secure file
transfers. Symmetric keys facilitate faster file encryptions, while asymmetric
keys simplify the key distribution process.

** [[https://www.jscape.com/blog/understanding-hashing][Understanding Hashing]]
Hashes are essential to secure file transfers. You can find them in operations
involving passwords, file integrity checks, digital signatures, digital
certificate thumbprints or fingerprints, and others. But what are hashes? In
this post, we'll introduce you to hashes, the concept of hashing, and its
applications in various areas of security.

*** What is hashing?
Hashing is an operation that takes any string of text, regardless of length or
size, as input and then provides a fixed-length string of characters as output.

*** Encryption vs Hashing
A hash looks pretty much like the output of an encryption operation
(a.k.a. ciphertext) does it? Well, encryption and hashing operations do have
similarities. However, they also have a couple of differences. First of all,
unlike encryption, hashing is always one way. In fact, hashing is often called
"one way encryption". So, while you can decrypt an encrypted text, you cannot
"de-hash" a hashed text. We'll see why this can be a useful feature when we
explain how hashes are used, e.g. in password authentication systems.

*** Properties of secure cryptographic hash functions
When hash functions (the underlying functions responsible for mapping the
original text into a hash) are used in information security, they must adhere
to certain properties. These three are the most important:

1. *They must be efficient.* The cryptographic hash function must not consume a
   lot of CPU cycles even if it's made to operate on a huge file.

2. *They must be one way functions.* Meaning, it should be virtually impossible
   to obtain the original text (a.k.a. the pre-image of the hash) from the
   hash.

3. *They must have collision resistance.* This means that it should be
   virtually impossible to find two different text or documents that would
   yield the same hash.


*** Commonly used hash algorithms
Some of the commonly used hashing algorithms include:

- MD5 ::

         Message Digest 5 or MD5 was developed by Ron Rivest, whose name is
         immortalised as the R in RSA (a public key cryptosystem common in
         various secure FTP protocols ). MD5 uses multiples of 512 bits as
         input and produces a 128-bit message digest (or the hash) as
         output. It is one of the older hashing algorithms but is now known to
         have certain vulnerabilities in its collision resistance properties.

- SHA1 ::

          Like the MD5 hash, SHA1 (secure hash algorithm) also takes 512 bits
          of input at a time. However, its output is 160 bits. SHA-1 was the
          result of a joint project between the NSA and the NIST. Like MD5,
          this cryptographic hash function has been proven to be relatively
          vulnerable to certain collision attacks.

- CRC ::

         CRC or Cyclic Redundancy Check is an example of a non-cryptographic
         hash function. Compared to cryptographic hash functions, CRC hash
         functions can be easily reversed. Hence, it isn't ideal for
         applications (e.g. digital signatures) that require functions with
         strong irreversibility properties. It's more suitable for detecting
         accidental changes in stored or transmitted files. In other words,
         it's used for data integrity checks.

- SHA-2 ::

           Once the SHA1 hash function was found to have potential
           vulnerabilities, the NSA decided to design a set of stronger hash
           functions. The resulting product was SHA-2, a family of hash
           functions that had 224, 256 and 384, and 512 bits. These were known
           respectively as SHA224, SHA256, SHA384, and SHA512.


*** Hashing passwords
Secure systems never store passwords in the clear. That is, if you look at a
password file, the list of usernames and their corresponding passwords wouldn't
look like this:

#+begin_example
peter: password1234

james: mac@pRoS

sharon: shadowfax
#+end_example

Instead, it would likely look like this:

#+begin_example
peter: uclQZA4bN0DpisuT5mnGV2b2Zw3RYJupH/QQUrpIxvM=

james: xw5UIGACzaNtYyZZjkaRY4a6uoVKhriy7NGLlW+COeM=

sharon: VgGAZRvmCKHoedevnDP2fUHMfuUNTcTL2XqFJGK7/qg=
#+end_example

The strings of characters you see after the equal signs are actually hashes
(actually, base-64 equivalents of hashes if you want to be more accurate) of
each password. When a user logs in, the system first grabs whatever is entered
into the password field and converts that into a password hash. It's that hash
that's used when looking up the username/password pair in the password file. If
a match is found, the user is allowed entry.

That way, even if an attacker gets a hold of the password hash file, he
wouldn't be able to use that file to login to the system.

Hashing is better than encryption in this case because it eliminates the
possibility of the hashed password being converted back to its plaintext
equivalent. If you use encryption, it would be possible for an attacker to
acquire all passwords (in plaintext) if he were somehow able to acquire the
decryption key.

*** Integrity checking
Remember the second characteristic we were able to observe in the section "What
is hashing?"? If you recall, we noticed that even the slightest change in the
original text can result in an entirely different hash. This characteristic can
be put to good use in data integrity checks. Let me give you a simple example.

Let's say a user wants to download an important electronic document from a
server. Because the integrity of the data in that document is important to him,
he would like to know if the document is altered along the way. One way to do
achieve this is by using a client and a server that supports the same hash
function.

Before sending the file, the server must first obtain a hash value of the file
using that hash function. Once the client receives the file, it too must use
the same hash function to generate a hash value. The two hash values must then
be compared. If the two values are equal, then it would be safe to conclude
that the file has been unchanged.

*** Digital signatures
Most data integrity checks are only carried out by the client. When a file is
downloaded, it's usually already accompanied by the file's hash a.k.a. message
digest. The client then generates its own hash from the file it downloaded and
compares it with the message digest that came along with the download. This
method has a flaw.

What's to stop an attacker from intercepting the file, altering it, generating
its own message digest using the same hash function, and then forwarding the
altered file (along with the new message digest) to the client? Once the client
receives the downloaded file and compares its locally-generated hash with the
downloaded hash, they will naturally appear equal. No way will this qualify for
a HIPAA compliant file transfer. It's therefore important for the client to
*make sure that both the downloaded file and the downloaded hash came from the
original source*.

This can be done using *asymmetric encryption keys*. Assuming the client has
the corresponding public key, the server can generate a "digital signature"
using its private key and the message digest. Its this digital signature that
will then be sent together with the file. So, when the client receives them, it
can then use the public key to verify the authenticity of the signature and
retrieve the message digest. Only then can the client compare the message
digest with its locally-generated hash of the file.

[[file:./resources/hashing-digital-signature.png]]

A failure to authenticate could only mean that the private key that was used to
generate the digital signature is not the pair of the public key used by the
client. Digital signatures are common in SSL-secured protocols like FTPS.

** [[https://www.jscape.com/blog/what-is-a-digital-signature][What is a Digital Signature?]]
Digital signatures help enforce security during data transfers. They're mainly
responsible for establishing authentication, data integrity, and
non-repudiation. Today, we'll be talking about the basic concepts behind
digital signatures, where they're used, how they work, and why they're always
an integral part of highly secure file transfers.

*** Uses of digital signatures
#+CINDEX:digital signatures
Digital signatures are used to meet three important goals of information
security: integrity, authentication, and non-repudiation.

**** Data integrity
#+CINDEX:integrity, data
#+CINDEX:data integrity
Message or Data integrity is particularly crucial during data transfers. Data
integrity ensures that the message received by the recipient is exactly the
same message sent by the sender. In wide area networks like the Internet, where
messages have to hop from one node or network device to another before arriving
at their intended final destination, there's always that risk of messages
getting altered along the way whether deliberately or accidentally. Data
integrity mechanisms help mitigate those risks. Through a data integrity check,
you'll know if the message you received has been tampered.

**** Authentication
#+CINDEX:authentication
When you receive a sensitive file, it's sometimes not enough to know that the
information in that file has been unaltered. You would also want to be sure
whether it really came from the person who you think sent it. In other words,
you would need a mechanism that would enable you to authenticate the source.

**** Non-repudiation
#+CINDEX:non-repudiation
Lastly, there may be data exchanges where you wouldn't want senders to disown
transmissions they actually sent some time in the past. For example, if someone
submits a report and the report is later found to be fraudulent, you wouldn't
want the sender to deny the fact that he sent it.

*** How digital signatures work
So how do digital signatures help you achieve these information security goals?
Perhaps it would be best to start by explaining how they work.

#+CINDEX:asymmetric encryption keys
#+CINDEX:public, private keys
#+CINDEX:private, public keys
#+CINDEX:secret keys
#+CINDEX:verify digital signature
#+CINDEX:key pair
Cryptographic digital signatures make use of asymmetric encryption keys,
i.e. public keys and their corresponding private keys (a.k.a. secret keys). The
private key is used to create a digital signature (in other words, for
"signing"), while the public encryption key is used for verifying the digital
signature. What makes this work is the fact that a pair of public and private
keys are so closely linked with one another that it would be virtually
impossible for a public key to authenticate a signature generated by a private
key that it isn't associated with.

#+CINDEX:digital signature, create
#+CINDEX:create digital signature
So how does one create a digital signature?

#+CINDEX:signing algorithm
#+CINDEX:RSA, DSA, signing algorithms
#+CINDEX:DSA, RSA, signing algorithms
#+CINDEX:hash function, digital signature
#+CINDEX:message digest, digital signature
To create a digital signature, you would take the message or file you would
like to sign and run it through a hash function. After that, you take the
resulting message digest or hash, combine it with your private key, and then
run them through a signing algorithm like RSA or DSA. The final result is that
message's digital signature. Of course, in applications like a secure file
transfer server, these things happen behind the scenes.

Theoretically, you could skip that hash function part and simply run the file
and the private key through some "signing algorithm" and still produce a
"digital signature". However, if the file is so large, this would take a great
deal of time. Besides, the resulting "signature" would also consume an
impractically huge amount of space.

#+CINDEX:verification process, digital signature
#+CINDEX:digital signature verification process
How about the digital signature verification process? This process now involves
the secret key's public key pair. While the secret key is used to sign
documents, its corresponding public key is used for verifying their
authenticity. Remember when I told you that the public key is tightly linked to
its private key?

If you have a public key and the key fails to authenticate a document you just
received, that would mean the secret key used for signing wasn't this public
key's pair. Consequently, it would also mean that the document's source isn't
who you expected it to be. That's how digital signatures are used for
authentication.

#+CINDEX:message digest, verification process
During the same verification process, the public key is also used to extract
the message digest that was originally combined with the private key to produce
the digital signature. The retrieved message digest is then compared with the
recipient's own locally-generated hash value of the received message. The
recipient must know what hash function was used by the sender. If the
locally-generated hash value and the extracted message digest are equal, then
it would mean that integrity of the message has been preserved.

Here's a simplified illustration of what we just discussed:

[[file:./resources/hashing-digital-signature.png]]

*** Summary of Digital Signature Creation

#+CINDEX:hash function, SHA2 hashing algorithm
#+CINDEX:SHA2 hashing algorithm
#+CINDEX:message digest (hash)
#+CINDEX:private key, digital signature
1. At the source (in this case, a server), the document is run through a hash
   function (e.g. SHA2 hashing algorithm) to produce a hash a.k.a. message
   digest. The message digest is combined with the source's private key to
   produce the document's digital signature.

2. The digital signature is affixed to the document and both are sent to the
   recipient (in this case, a client application).

   #+CINDEX:public key, digital signature
   #+CINDEX:message digest, decrypting
3. At the client side, the message digest is extracted from the digital
   signature using a copy of the server's public key that's in the client's
   possession. Note that the client wouldn't be able to extract the message
   digest if the public key in its possession doesn't match the private key
   used to generate the digital signature.

   #+CINDEX:hash function, identical to sender
   #+CINDEX:locally-generated hash
4. The client runs the document through the same hash function used by the
   sender to produce its own locally-generated hash.

5. The two hashes are compared.


*** Goals of Digital Signatures
If the two hashes are equal, it would prove two things:

{{{subheading(Data Integrity and Authenticity)}}}

#+CINDEX:integrity
#+CINDEX:authenticity
1. that the document was unaltered (thereby achieving *integrity*) and
2. that the source is who the recipient expected it to be (thereby achieving
   *authentication*).


{{{subheading(Non-Repudiation)}}}

#+CINDEX:non-repudiation
If both are achieved, then there is no way the sender can later on deny that he
sent the document. That's because none of these would be achieved if the wrong
private key was used in step 1. Since only the source could (theoretically)
have a hold of the private key, only the source could have initiated this
particular transaction. And that is how digital signatures help establish
*non-repudiation*.

Its ability to help enforce *authentication*, *data integrity*, and
*non-repudiation* can be very useful in automated business transactions and is
the reason why digital signatures are integral to secure data transfer
protocols like SFTP, FTPS, OFTP, and AS2.

*** When digital signatures alone are not enough
Notice how digital signatures are very dependent on the integrity of the
encryption keys. What if the public key in your possession actually belongs to
an impostor? It's possible for an attacker to pose as someone else and then
dupe you into obtaining his (the attacker's) public key. Once that happens, the
entire process illustrated earlier (from step 1 through 5) will proceed as
normal even if (in actuality) it has already been compromised.

In our next post, you'll learn how to mitigate this particular risk by using
- digital certificates,
- certificate authorities, and
- other trust models.
** [[https://www.jscape.com/blog/what-is-a-digital-certificate][What Is A Digital Certificate?]]
When users come to your website, they have a way of telling whether your site
is safe to connect with or not. It comes in the form of something called a
digital certificate. Today, we'll help you understand what a digital
certificate is, its key components, the role it plays in Web security, and
other concepts associated with it.
*** What a digital certificate is in a nutshell
#+CINDEX:digital certificate
#+CINDEX:cert
A digital certificate primarily acts like an identification card; something
like a driver's license, a passport, a company ID, or a school ID. It basically
tells other people who you are. So that, for example, when a user arrives at
your site looking for =yourdomain.com=, your site's digital certificate
(a.k.a. "cert") will help that user confirm whether he actually landed at
=yourdomain.com=.

#+CINDEX:public key, digital certificate
In addition, a cert also holds a copy of your site's public key, which is used
in encrypting data transmitted between your site and the user's web client (in
most cases, a web browser).

Not all websites offer digital certificates. In the past, the use of digital
certificates were mostly limited to sites with whom users had to engage in
secure transactions or share sensitive information. For instance, you normally
encountered certs on online banking websites, secure file transfer servers,
major e-commerce sites, or EDI servers. But because users are now becoming more
conscious about web security, more and more sites are employing digital
certificates to gain users' trust.

You won't actually see the entire digital certificate as you connect to a
site. However, you'll easily know it's there. Websites protected by certs
usually display a lock icon followed by "https" on the leftmost part of that
site's URL when viewed on your browser's URL bar. To view the contents of the
cert, just click on the lock icon.

#+CINDEX:X.509 standard, digital certificates
Most digital certificates in use today follow what is known as the X.509
standard. X.509 is used in SSL (Secure Sockets Layer) and TLS (Transport Layer
Security), so yes, it's what's being used in HTTPS, FTPS, WebDAVS and other
secure data transfer protocols. Let's now take a look at the kind of
information you'll find in this kind of certificate.

*** Contents of a X.509 certificate
The contents of a digital certificate typically include the following:

- Information about the subject a.k.a. Subject Name ::

     "subject" refers to the site represented by the cert.

- Information about the certificate issuer/certificate authority (CA) ::

     The CA is the body that issued and signed the certificate. More about this
     shortly

- Serial number ::

                   This is the serial number assigned by the issuer to this
                   certificate. Each issuer must make sure each certificate it
                   issues has a unique serial number.

- Version ::

             The X.509 version used by a given certificate. These days, you'll
             usually find version 3.

- Validity period ::

     Certs aren't meant to last forever. The validity period defines the period
     over which the cert can still be deemed trustworthy.

- Signature ::

               This is the digital signature of the entire digital certificate,
               generated using the certificate issuer's private key.

- Signature algorithm ::

     The cryptographic signature algorithm used to generate the digital
     signature (e.g. SHA-1 with RSA Encryption)

- Public key information ::

     Information about the subject's public key. This includes:
  - the algorithm (e.g. Elliptic Curve Public Key),
  - the key size (e.g. 256 bits),
  - the key usage (e.g. can encrypt, verify, derive), and
  - the public key itself

*** Certificate Key
#+CINDEX:public key, digital certificates
While most of the contents of a digital certificate are there for providing
information regarding the subject, the issuer, or the certificate itself, the
certificate key or public key has a special purpose. It's a vital component in
the encryption of data exchanged between the server and the client.

*** Certificate Authorities
#+CINDEX:certificate authorities
Another element of a digital certificate that does more than provide
information is the certificate's digital signature. As mentioned earlier, the
certificate's digital signature is generated using the certificate issuer's
private key. If you've read the article on digital signatures, you know that a
cert's digital signature can be used in authentication. But in order for a web
client to verify/authenticate a digital signature, it will need a copy of the
issuer's public key.

If the issuer happens to be a widely recognized certificate authority (CA),
that won't be a problem. A copy of that CA's public key will likely be
pre-installed in the user's web browser. Popular Web browser's like Chrome,
Firefox, Safari, and Internet Explorer all come with the certificates of
recognized CAs. That means, they already contain copies of those certificate
authorities' public keys and can therefore be used for verifying certificates
issued/signed by them.

#+CINDEX:signed certificates
#+CINDEX:self-signed certificate
Certificates signed by widely recognized CAs are called {{{dfn(signed
certificates)}}}. There are also certificates that are simply signed by issuers
who aren't widely recognized certificate authorities. For example, when you
create your own digital certificate using JSCAPE MFT Server but don't bother
processing a Certificate Signing Request (CSR), you will end up with what is
known as a {{{dfn(self-signed certificate)}}}.

If you want to see how a digital certificate is created, read the article [[HTTPS File Transfer][How
To Set Up A HTTPS File Transfer]], especially the section entitled Preparing
Server Keys.

*** Signed vs Self-signed certificates
#+CINDEX:certificate authorities
#+CINDEX:due diligence
In theory, certificate authorities are supposed to exercise due diligence
before signing digital certificates submitted to them through CSRs. They need
to verify first whether the information placed on the digital certificates are
in fact true. This is important because their attestation would later on serve
as the sole basis that certain websites who are able to present certs signed by
them can really be trusted.

So, assuming due diligence is really exercised, it would be safe to assume that
signed certificates are more reliable and trustworthy than self-signed
certificates. In fact, when a user attempts to connect to your site and your
site only has a self-signed certificate, the user's browser will display
a warning message.

#+CINDEX:self-signed certificates, when safe
Self-signed certificates are relatively safe to use internally, i.e., within
your organization, where you have more control over the servers that operate in
the network. So, for instance, you can use it to add security to a web file
transfer that takes place behind your corporate firewall.

** [[https://www.jscape.com/blog/an-overview-of-how-digital-certificates-work][An Overview of How Digital Certificates Work]]
In our previous post, we discussed what a digital certificate is. Today, we're
going to give you an overview of the basic process involving the creation,
signing, deployment, and use of digital certificates.

*** Server Certificates
#+CINDEX:server certificates
There are different types of digital certificates but we'll be focusing on the
server certificates used in secure web servers since they're the most
common. You come across these kinds of certificates on the Web everyday,
particularly when you connect to sites that support HTTPS. A CA-signed server
certificate is the kind of certificate you would need to deploy if you don't
want Web browsers to display a warning when users attempt to connect to your
secure file transfer server.

*** CA Certificates - the certificates in your browser
#+CINDEX:CA certificates
#+CINDEX:Certificate Authority certificates
Before any major Web browser like Chrome, Firefox, Safari or Internet Explorer
connects to your server via HTTPS, it already has in its possession a set of
certificates that can be used to verify the digital signature that will be
found on your server certificate. These certificates are called {{{dfn(CA
(Certificate Authority) certificates)}}}. On these certificates is a copy of
the public key of the CA who might issue (sign) your server certificate.

CA certificates of widely accepted certificate authorities are already
pre-installed on popular Web browsers, so we don't worry about installing them
anymore. This explains how CA certificates can verify the digital signature on
server certificates (more about this process later). The private keys that are
used for signing the server certificates already have their corresponding
public key pairs on our users' Web browsers.

*** Generating CSRs and having your cert signed by a CA
You can create your own digital certificate if you want. You can use free tools
like OpenSSL. Alternatively, you can also use built-in tools that come with
secure file transfer software like JSCAPE MFT Server.

#+CINDEX:CSR
#+CINDEX:Certificate Signing Request (CSR)
#+CINDEX:generate key pair
You usually start by generating a private key / public key pair, followed by a
CSR (Certificate Signing Request). The CSR would contain a copy of the public
key and some basic information about the subject. Once you've generated a CSR,
you would then submit that CSR to a CA.

Once the CA is done signing the cert, the CA would then return the cert to you
and you would then import that signed certificate to your server.

If we recall our discussion on digital certificates, the signed cert would
contain some basic information regarding the subject (your site), the issuer,
the validity period, the public key (of your site), and a digital signature of
the cert signed using the CA's private key.

In summary,

1. You generate a private key / public key pair and submit a CSR to a
   Certificate Authority. The contents of the CSR will form part of the final
   server certificate.

2. The CA verifies whether the information on the certificate is correct and
   then signs it using its (the CA's) private key. It then returns the signed
   server certificate to you.

3. You import the signed server certificate unto your server.

*** Sending of server certificate during SSL Handshake
Before a browser and an HTTPS server can exchange data over an encrypted
connection, they first engage in a process known as the SSL handshake. One
important part in the SSL handshake is the sending of the server certificate to
the web browser. It's here when the Web browser is able to authenticate the
identity of the server it's connecting to.

As soon as the browser receives a copy of the server certificate, it checks
which CA signed the server cert and then retrieves the CA certificate of that
particular Certificate Authority. It then uses the public key on that CA
certificate to verify the digital signature on the server cert.

Once the digital signature has been authenticated, the browser and server can
proceed with the rest of the SSL process.

** [[https://www.jscape.com/blog/how-to-set-up-https-file-transfer][How To Set Up A HTTPS File Transfer]] (on JSCAPE MFT Server)
#+CINDEX:HTTPS file transfer
<<HTTPS File Transfer>> In this post, you'll learn how to set up a HTTPS file
transfer. We'll begin with a "quickstart", where you'll use the default
settings in order to get a HTTPS file transfer service up and running with just
a few clicks. After that, we'll tackle some of the more advanced settings so
you can choose your desired set of SSL/TLS cipher suites and server key. Your
choice of cipher suites and keys will have an effect on the security of your
HTTPS service and its compatibility with your users' web browsers.

#+CINDEX:RFC 2818
*Note*: The HTTPS or HTTP Secure protocol is defined in [[https://tools.ietf.org/html/rfc2818][RFC 2818]], so if you
want a really technical discussion on HTTPS alone, feel free to read that.

[[https://youtu.be/PeN4mhFSbjc][Video of Article]]

** [[https://www.jscape.com/blog/bid/105104/how-to-set-up-a-web-file-transfer][How to Set Up a Web File Transfer]] (on JSCAPE MFT Server)
In this post, you'll learn how to set up a web-based file transfer service
using JSCAPE MFT Server. A web file transfer will allow your users to perform
file transfers without having to install a file transfer client. To upload or
download files, they'll just need to fire up their favorite Web browser like
Firefox, Chrome, Safari, Internet Explorer, or Edge, enter the web server's
URL, and login to the interface.
** [[https://www.jscape.com/blog/bid/82339/What-is-an-SSL-File-Transfer][What is an SSL File Transfer?]]
#+CINDEX:FTPS
#+CINDEX:FTP-SSL
#+CINDEX:SSL file transfer
SSL file transfer is a term sometimes used in referring to a secure file
transfer protocol known as FTPS or FTP-SSL. FTP is a network protocol used for
transferring files, while SSL is a protocol for encrypting information sent
over a network. This post is meant to help users understand what FTPS is and
what it is capable of doing, particularly in terms of enhancing the security of
your file transfers.

The term "SSL file transfer" is also used to refer to file transfers using
HTTPS, another secure network protocol. However, to keep this post concise,
we'll just focus on FTPS.

*** SSL Certificates
#+CINDEX:SSL certificates
At the heart of SSL (Secure Sockets Layer) file transfers are special files
called SSL certificates. These files contain information that is vital to
achieving security during file transfers. The two most common security
functions of an SSL certificate is to help in authenticating the identity of a
server and in facilitating encryption.

#+CINDEX:digital certificate, SSL
#+CINDEX:SSL certificate
Some of the information found in an SSL certificate (a.k.a. digital
certificate) include:

- The dates over which the certificate could be considered valid;

- Information regarding the subject (usually the organization/company who owns
  the server or the server itself);

- The subject's public key (this is what is used for encryption);

- Information regarding the issuer of the certificate; and

- The digital signature of the issuer


#+CINDEX:X.509 standard
All the information that should go into an SSL certificate is outlined by what
is known as the X.509 standard.

#+CINDEX:digital signature, SSL
The digital signature (which is virtually impossible to forge) is an
attestation of the issuer that the public key belongs to the "subject" whose
identity is being described in the certificate.

When used internally in an organization, SSL certificates are mostly
self-signed. The person in charge of generating the certificates would use the
company's certificate-generating program to issue the certificates. The program
would then automatically affix the company's signature to each generated
certificate.

#+CINDEX:Certificate Signing Request (CSR)
#+CINDEX:CSR
#+CINDEX:Certificate Authority (CA)
#+CINDEX:CA
In the case of companies who offer file transfer services to a large number of
external users, these companies normally issue what is known as a Certificate
Signing Request (CSR) and submit it to a Certificate Authority or CA. The CA
then puts the company under a vetting process to verify the company's true
identity before issuing the requested digital certificate.

Certificate Authorities are independent, trusted bodies whose digital signature
on a certificate is meant to assure end users that the bearer of the
certificate is really who he claims to be.

*** How authentication is done in SSL File Transfers
When a user attempts to connect to your managed file transfer server via FTPS,
the server will send the user an SSL certificate. The user (or the user's file
transfer client) should then review the contents of that certificate to verify
whether the server he is about to establish a connection with is in fact the
server he wants to connect to.

You see, it is possible for an attacker to go between a user and your managed
file transfer server and then pretend to be your server. If that attacker
succeeds in impersonating your server, the user can be duped into sending vital
information to him instead. SSL certificates can prevent that from happening.

When a user does not recognize the SSL certificate coming from a server, that
user can opt to cancel the connection. This would prevent any confidential
information from falling into the wrong hands.

But how can you be sure a certificate itself is legit? Can't an attacker simply
issue a fake certificate and use that to trick your users?

#+CINDEX:AnyClient service
If your file transfer client is designed to identify certificates signed by
CAs, it would prompt the user the moment it receives a certificate that hasn't
been signed by one. If a CA's signature is found, the session will be allowed
to proceed. The client ([[https://www.jscape.com/products/file-transfer-clients/anyclient/][AnyClient]] is used in figure below) would also prompt
the user if it receives a self-signed certificate. In this case, the user may
contact the server admin to verify the certificate.

Prompting is mostly only done at the start of the first session. After
verifying the certificate, the user can opt to save the certificate details
into the client to avoid getting prompted again in future sessions.

*** How SSL certificates facilitate encryption
As mentioned earlier, one of the items in an SSL certificate is the server's
public key. This public key has a corresponding private key, which is stored on
the server. This pair of keys is responsible for encrypting the session key,
which in turn is responsible for encrypting data exchanged over the FTPS
connection.

Because encryption renders information unreadable, any attacker who manages to
get hold of data during transmission would not be able to read, tamper with, or
make unauthorized alterations to the contents. Therefore, even if files have to
go through highly insecure networks like the Internet, their contents can be
kept safe when sent through an SSL file transfer.

** [[https://www.jscape.com/blog/ssl-vs-tls-know-the-difference][SSL vs. TLS | Knowing the Difference Between SSL and TLS]]
#+CINDEX:SSL
#+CINDEX:TLS
#+CINDEX:SSL/TLS
SSL and TLS have many similarities. That's why, in most software applications,
they're configured together as "SSL/TLS". However, there are several
differences between SSL and TLS well, which is what we're going to talk about
now.

*** A brief discussion on the similarities
#+CINDEX:Secure Socket Layer (SSL)
#+CINDEX:Transport Layer Security (TLS)
SSL (Secure Socket Layer) and TLS (Transport Layer Security) are very similar
in many aspects. They both:

- protect data privacy through data-in-motion encryption;
- provide server and (optionally) client authentication;
- check for message integrity using message authentication codes; and
- perform a preliminary handshake process wherein the two communicating parties
  negotiate for a common cipher suite.


The similarities are closest between the first version of TLS (TLS 1.0) and the
last version of SSL (SSL 3.0). In fact, TLS v 1.0 is often considered SSL v
3.1. The former even had the ability to downgrade an ongoing connection to
SSL 3.

So how does TLS differ from SSL? What we have below is by no means an
exhaustive list but here are some of the key differences:

*Note*: All of our comparisons will be between TLS and SSLv3.0 because version
3 is the only SSL version that's still (relatively) widely used.

*** Absence of a =no_certificate= error alert in TLS
In SSLv3.0 (refer to RFC 6101), a client would typically respond with a
=no_certificate= alert message whenever the server requested a certificate for
authentication but it (the client) had none to give. In TLS, this alert is no
longer necessary. However, the client must (especially in TLS 1.2 - RFC 5246)
send a certificate message containing no certificates.

*** TLS has more Alert descriptions
Whenever a problem is encountered during the course of a SSL or TLS connection,
the party who discovers the problem would send out an alert message.

SSLv3 had 12 of these messages.

{{{subheading(SSL Alert Descriptions)}}}

- Close Notify,
- Unexpected Message,
- Bad Record MAC,
- Decompression Failure,
- Handshake Failure,
- No Certificate,
- Bad Certificate,
- Unsupported Certificate,
- Certificate Revoked,
- Certificate Expired,
- Certificate Unknown, and
- Illegal Parameter.


TLS added 19 more to that (although "No Certificate" was removed). 

{{{subheading(Additional Alert Descriptions only found in TLS)}}}

- Decryption Failed,
- Record Overflow,
- Unknown CA (Certificate Authority),
- Access Denied,
- Decode Error,
- Decrypt Error,
- Export Restriction,
- Protocol Version,
- Insufficient Security,
- Internal Error,
- User Canceled,
- No Renegotiation,
- Unsupported Extension,
- Certificate Unobtainable,
- Unrecognized Name,
- Bad Certificate Status Response,
- Bad Certificate Hash Value,
- Unkown PSK, and
- No Application Protocol.

*** TLS uses HMAC for message authentication
#+CINDEX:integrity checks
#+CINDEX:MAC
#+CINDEX:HMAC
SSL performs message integrity checks (to determine whether a message has been
altered) through Message Authentication Codes (MACs) that use either MD5 or
SHA. TLS, on the other hand, uses HMAC, allowing it to work with a wider
variety of hash functions; not just MD5 and SHA.

*** TLS uses a pseudorandom function to generate the key material
#+CINDEX:pseudorandom function
To generate the key material, TLS uses an HMAC-based pseudorandom function
(PRF). SSL doesn't.

*** TLS has a simpler way of arriving at the CertificateVerify message
In cases wherein the server requests for a client certificate (to authenticate
the client), the client is supposed to send a follow-up message some time after
sending the Certificate message (the message that contains the client
certificate). In TLSv1.2, this message must be sent right after the
ClientKeyExchange message.

This follow-up message, known as the CertificateVerify message, would enable
the server to verify that the client certificate in fact originated from the
actual client and not an impostor.

This CertificateVerify message is actually a signature of the previous
handhsake messages signed using the client certificate's corresponding private
key. Because the server would have already had the corresponding public key
(which accompanied the client certificate sent earlier) in its possession, it
would be able to verify the signature.

In TLS, everything that's needed to construct the CertificateVerify message can
be found in the previous handshake messages. It wasn't the same in SSL, which,
in addition to the handshake messages, also required the master secret and a
couple of other values known as =pad_1= and =pad_2= (see RFC 6101, section
5.6.8)

*** Different set of cipher suites
Another difference between TLS and SSL are their collection of cipher
suites. SSL cipher suites typically begin with SSL_, while TLS cipher suites
begin with TLS_. Notably missing in TLS are the FORTEZZA cipher suites, which
are supported in SSLv3. On the other hand, notably present in the later
versions of TLS (more specifically, starting at TLSv1.1) are the AES cipher
suites. The Advanced Encryption Standard (AES) ciphersuites were integrated
into TLS by virtue of RFC 3268.

** [[https://www.jscape.com/blog/bid/81215/Roles-of-Server-and-Client-Keys-in-Secure-File-Transfers-Part-1][Roles of Server and Client Keys in Secure File Transfers - Part 1]]
[Last updated on Feb 2019] Secure file transfers typically employ public key
cryptography. This cryptographic system involves the use of two different keys:
a public key and a private key. In JSCAPE MFT Server, such keys can be easily
generated, imported, and exported in the Key Manager. But some first-time users
find it hard to even start using the Key Manager. One reason for that is
because they fail to see the difference between server keys and client keys.

You see, both of them deal with public keys and private keys. Also, whether you
generate server keys or client keys, the user interface and the fields you're
asked to complete are quite identical.

So what exactly is the difference between these two?

Actually, server keys are primarily used for preserving the confidentiality of
information contained in your file transfers and for authenticating a server's
identity, while client keys are used for authenticating a client's identity.

Perhaps we should start by defining what authentication and confidentiality
exactly are.

*** Authentication and Confidentiality
Authentication and confidentiality are both vital ingredients for achieving
information security; in our case, the security of our file transfers. But
they're two different things.

{{{subheading(Authentication)}}}

Authentication allows you to verify the identity of anyone or even anything (as
in the case of servers, workstations, and other machines) trying to gain access
to your system. For instance, let's say you only want your trusted assistant,
George, to download files from a certain directory in your managed file
transfer server.

If someone logs in to that directory as George, you would want to make sure
that guy is really George and not someone just trying to impersonate him. The
most common way of applying authentication is by requiring the person to login
using George's username and password. This is known as {{{dfn(password
authentication)}}}. Ideally, George's username and password are things only
George would know.

Another way to authenticate a user would be to require the user to submit
something that only he should *have*. One example of this "something" is a
/private key/, which is used in public key authentication. This is what we're
interested in here.

Here's a file transfer client ([[https://www.jscape.com/products/file-transfer-clients/anyclient/][AnyClient]]) requiring both password
authentication and public key authentication:

[[file:./resources/password_and_public_key_authentication-resized-600.png]]

Once you are able to authenticate the identity of a person or machine, you
would then be able to enforce other vital elements of information security such
as authorization, accountability, and non-repudiation. But these terms are for
another post. The next term we would like to define now is "confidentiality".

{{{subheading(Confidentiality)}}}

Authentication is usually applied at the start of a secure file transfer. Once
identities have been verified, file transfers can be allowed to proceed. The
next security objective would then be to preserve the confidentiality of
whatever information is being transferred. That is, to keep the information
private between the sender and the recipient.

In most IT systems, confidentiality is enforced through encryption. Encryption
renders normal text (known as plaintext) into something unreadable (known as
ciphertext). This can be very useful especially if your file transfers go
through highly unprotected networks like the Internet. Once the ciphertext
reaches its intended recipient, it can then be transformed back to plaintext by
'decrypting' it.

Encryption and decryption are usually done through the use of keys. Some
cryptographic systems use just one key for both encryption and
decryption. Other systems use two; one key for encrypting and another key for
decrypting.

The most widely accepted kind of strong encryption is public key encryption and
it uses two keys - a private key and a public key.

*** How public key cryptography implements authentication and confidentiality
Having learned about authentication and confidentiality, you're probably now in
the position to understand how JSCAPE MFT Server uses public key cryptography
(a.k.a. asymmetric key cryptography) to implement these two important elements
of information security. Let's start by discussing how public key cryptography
is able to uphold file transfer confidentiality.

{{{subheading(Public keys and private keys for encryption)}}}

Public key cryptography makes use of a pair of keys. One key in the key pair is
called a private key, while the other one is called a public key. Public keys
are used for encrypting files, while private keys are used for decrypting them.

A private key is kept by the key's owner and, as its name implies, is supposed
to be kept private. Meaning, only the owner should know what it is or where it
is. A public key, on the other hand, is generally shared with others
(sometimes, even to the general public).

Proceed to [[Server-Client-Keys-Part 2][Part 2]].

** [[https://www.jscape.com/blog/bid/82332/Roles-of-Server-and-Client-Keys-in-Secure-File-Transfers-Part-2][Roles of Server and Client Keys in Secure File Transfers - Part 2]]
<<Server-Client-Keys-Part 2>>This is a continuation of Part 1. To preserve
confidentiality in secure file transfers, public keys are given to end users
while the private key is kept inside the managed file transfer server.

When a user wants to do a secure file transfer, he simply encrypts his
plaintext file using the public key in his possession. Because the file is
encrypted, it is kept safe from prying eyes during transmission and the
confidentiality of its contents is preserved. As soon as the encrypted file
reaches the managed file transfer server, the server decrypts it using the
public key's corresponding private key.

So how does a user get a hold of the public key? Sometimes, a public key is
sent by the server to the user's file transfer client at the start of a secure
file transfer. For example, at the start of an FTPS session, the server sends a
digital certificate that already contains a public key.

{{{subheading(Public keys and private keys for authentication)}}}

Public keys and private keys aren't only used for encryption. Because a
particular private key and its corresponding public key are related, the public
key can be used to verify that a certain private key is in fact its
partner. This explains why they are also often used in authenticating clients
at the start of a secure file transfer session.

For example, in setting up SFTP, private keys are generated and then are each
assigned to authorized end users. If the system is applied correctly, no two
end users would have the same private key and each user would keep his/her own
private key private. Also, the private keys' corresponding public keys would be
kept in the server.

So when a user logs in by submitting his private key to the server for
verification, the server can verify the user's identity by using the private
key's corresponding public key.

*** Nailing down the difference between server keys and client keys
After all that discussion about private keys, public keys, confidentiality and
authentication, we're finally ready to differentiate server keys and client
keys.

{{{subheading(How server keys are used)}}}

Whenever you generate a server key via the JSCAPE MFT Server's Key Manager,
you're actually creating a public/private key pair that would later on be used
primarily for encrypting files in secure file transfer protocols like SFTP,
FTPS, or HTTPS. In other words, they would be used by your server to preserve
the confidentiality of your file transfers.

As mentioned earlier, the public key of this particular key pair is normally
sent (sometimes as part of a digital certificate) to the client at the start of
a secure file transfer session. The client then uses that public key to encrypt
whatever file it sends to the server.

*Note*: In some cases, server keys can also be used for server authentication
(as in the case of HTTPS) or both server authentication and client
authentication (as in the case of AS2).

{{{subheading(How client keys are used)}}}

On the other hand, whenever you generate a client key via the JSCAPE MFT
Server's Key Manager, the resulting public/private key pairs would be used for
authentication purposes.

In the course of generating a client key, you would be asked to export that
client key's private key.  It is that private key which you would send to an
end user and, in turn, which the end user would load up to his file transfer
client to do say [[SFTP public key authentication][SFTP public key authentication]] (see screenshot in Part 1).

*** Summary
Whenever you generate either a server key or a client key, you are actually
creating a key pair consisting of a private key and a public key. However, the
pair that's created when you generate a server key is mainly used for
encrypting the session (with a few instances wherein they're used for
authentication), while the pair that's created when you generate a client key
is used for authenticating clients.

** [[https://www.jscape.com/blog/setting-up-sftp-public-key-authentication-command-line][Setting Up SFTP Public Key Authentication On The Command Line]]
<<SFTP public key authentication>> SFTP provides an alternative method for
client authentication. It's called SFTP public key authentication. This method
allows users to login to your SFTP service without entering a password and is
often employed for automated file transfers. In this post, we'll walk you
through the process of setting up this kind of authentication on the command
line. It's really easier to do this on a GUI-based interface but if you simply
love doing things on the terminal, this post is for you.

*Note*: SFTP (through SSH) is usually installed on Linux distros, so we'll be
using Linux for both the (SFTP) server and client machines in this tutorial.

** [[https://www.jscape.com/blog/bid/104856/5-Big-Business-Benefits-of-Using-SSO-Single-Sign-On][Single Sign On]]
Although it's been around for quite a while, Single Sign-On or SSO has just
started gaining widespread adoption. But it's spreading real fast. In fact, if
you surf the Web everyday, I bet you've seen many websites inviting you to
login using one of these ...

[[file:./resources/sso-examples.png]]

Never tried clicking any of those buttons? There's really nothing to it. If you
have absolutely no idea what SSO is, here's a good introductory article that
should get you warmed up on this awesome technology:
- [[https://www.jscape.com/blog/bid/104558/SSO-Single-Sign-On-Simplified][SSO (Single Sign-On) Simplified]]


So why are organizations adopting SSO? And more importantly, why would you want
to implement it in your business? Here are five reasons:

** [[https://www.jscape.com/blog/bid/104558/SSO-Single-Sign-On-Simplified][SSO (Single Sign-On) Simplified]]
There was a time when the average computer user had to enter login credentials
only once per day - likely to simply gain access into the Windows
environment. But in this cloud-computing/mobile device age, unless you've
activated the "stay signed in" option (assuming it's available), you'd probably
have to login to 5 or even 20 different Web sites or online applications per
day.

Many people already find it hard to remember a single username/password pair,
let alone five or more. To work around this difficulty, some individuals use
the same login credentials for all the sites or applications they need access
to. But in doing so, they create a serious vulnerability. If a malicious
individual gets hold of those credentials, he could potentially gain access to
multiple applications.

That's why some organizations have started implementing SSO or Single Sign-On.

[[file:./resources/sso-google.png]]

* LEGAL---Electronic Signatures
** [[https://www.govinfo.gov/content/pkg/PLAW-106publ229/pdf/PLAW-106publ229.pdf][ELECTRONIC SIGNATURES IN GLOBAL AND NATIONAL COMMERCE ACT]]
- PUBLIC LAW 106–229—JUNE 30, 2000
- 114 STAT. 464
- To facilitate the use of electronic records and signatures in interstate or
  foreign commerce.

* Node Security

** Article---Simple Node Authentication
:PROPERTIES:
:author:   Braden Kelley
:date:     2018-04-24
:END:
- https://developer.okta.com/blog/2018/04/24/simple-node-authentication


Authenticating users for Node.js/Express.js web apps can be difficult.  You
have to set up a database, define a user schema (or use something more flexible
like NoSQL), write code to handle password hashing, etc.  It’s annoying.

#+cindex:OIDC, Node integration
Using Okta’s API service, however, you can easily register and log in users to
your Node website using our OpenID Connect integration.

** Node Express Application With Security
A simple sample application built using Node and Express that contains user
login, registration, and password reset functionality.

- [[https://github.com/oktadeveloper/okta-node-express-example][okta-node-express-example]]


This example shows how to create a website in Node and Express that uses Okta
for authentication.  The application was bootstrapped with Express Generator.
You can see it online at:

- https://okta-node-express-example.herokuapp.com.


Please read [[https://developer.okta.com/blog/2018/04/24/simple-node-authentication][Simple Node Authentication]] to see how this application was created,
and [[https://developer.okta.com/blog/2018/06/26/securely-manage-users-node-app][How to Securely Manage Users in Your Node App]] to see how the user profile
page was created.
* Cheat Sheet on Implementing HTML 5 In a Secure Fashion
- https://cheatsheetseries.owasp.org/cheatsheets/HTML5_Security_Cheat_Sheet.html


** Introduction to Implementing Secure HTML 5
The following cheat sheet serves as a guide for implementing HTML 5 in a secure
fashion.

** Communication APIs

*** Web Messaging

*** Cross Origin Resource Sharing

*** WebSockets

**** WebSocket implementation hints

***** Access filtering

***** Authentication and Input/Output validation

***** Authorization and access token explicit invalidation

***** Confidentiality and Integrity

*** Server-Sent Events

** Storage APIs

*** Local Storage

*** Client-Side Databases

** Geolocation

** Web Workers

** Tabnabbing

** Sandboxed Frames

** Credential and Personally Identifiable Information Input Hints

** Offline Applications

** Progressive Enhancements and Graceful Degradation Risks

** HTTP Headers to enhance security
* Listings
:PROPERTIES:
:unnumbered: t
:END:
#+texinfo:@listoffloats Listing

* Concept Index
:PROPERTIES:
:index:    cp
:unnumbered: t
:END:
* Export Settings                                                  :noexport:
** Options
#+options: H:4 ':t
** Texinfo Export Settings
#+texinfo_filename:security.info
#+texinfo_class: info
#+texinfo_header:
#+texinfo_post_header:
#+subauthor:
#+texinfo_dir_category:WebDev
#+texinfo_dir_title:Security
#+texinfo_dir_desc:Security information
#+texinfo_printed_title:Security Information
#+subtitle:For WebDev
** Macro Definitions
#+macro:heading @@texinfo:@heading @@$1
#+macro:subheading @@texinfo:@subheading @@$1
#+macro:dfn @@texinfo:@dfn{@@$1@@texinfo:}@@
#+macro:noindent @@texinfo:@noindent @@
#+macro:cite @@texinfo:@cite{@@$1@@texinfo:}@@
#+macro:option @@texinfo:@option{@@$1@@texinfo:}@@
** Local Variable Definitions

* Footnotes

[fn:6] *Note*: If your FQDN was validated when you requested a previous
certificate and you are requesting another certificate for the same FQDN, you
do not need to add another DNS record. 

[fn:5] *NOTE*: Select Client credentials only if your app needs to request
access tokens on its own behalf, not on behalf of a user. 

[fn:4] *NOTE:* To sign in with external identity providers (IdPs) such as
Facebook, Amazon, Google, and Apple, as well as through OpenID Connect (OIDC)
or SAML IdPs, first configure them as described next, and then return to the
App client settings page to enable them. 

[fn:3] Note that this will not work just opening the page from your filesystem
due to cross-domain restrictions that browser have with =file://= URIs.

[fn:2] Aaron Parecki discusses common security threats when building
microservices using OAuth and how to protect yourself. 

[fn:1] 
# Local Variables:
# fill-column: 79
# End:
